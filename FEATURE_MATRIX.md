# Feature-to-Pain-Point Matrix

This document maps each code module to the specific faculty pain points it addresses.

---

## ðŸ“Š Module Coverage Matrix

| Pain Point | Quiz Gen | FAQ Gen | Proj Org | Rubric | Announce | Verify |
|-----------|:--------:|:-------:|:--------:|:------:|:--------:|:------:|
| 1. Update content with current examples | | | | | | |
| 2. Keep materials synchronized | | | ðŸŸ¢ | | | |
| 3. Design fair, AI-resistant assessments | ðŸŸ¡ | | | ðŸŸ¡ | | ðŸŸ¢ |
| 4. Develop diverse examples | | | | | | |
| 5. Accessibility adjustments | | | | | | |
| 6. Individualized learning support | | ðŸŸ¡ | | | | |
| 7. Track participation/engagement | | | | | | |
| 8. Revise rubrics | | | | ðŸŸ¢ | | ðŸŸ¢ |
| 9. Ensure alignment of outcomes | ðŸŸ¢ | | ðŸŸ¢ | | | |
| 10. Create multimedia materials | | | | | | |
| 11. Balance innovation with integrity | | | | | | ðŸŸ¢ |
| 12. Write exams efficiently | ðŸŸ¢ | | | | | ðŸŸ¢ |
| 13. Implement course updates | | | ðŸŸ¢ | | ðŸŸ¢ | |
| 14. Provide support beyond office hours | | ðŸŸ¢ | | | | |
| 15. Handle routine communication | | ðŸŸ¢ | | | ðŸŸ¢ | |
| 16. Respond to repetitive emails | | ðŸŸ¢ | | | | |
| 17. Manage one-on-one demands | | ðŸŸ¡ | | | | |
| 18. Grade written reports/projects | | | | | | |
| 19. Provide detailed feedback | | | | | | |
| 20. Grade non-MC exams | | | | | | |
| 21. Maintain AI consistency | | | | | | ðŸŸ¢ |

**Legend**: ðŸŸ¢ = Fully Addresses | ðŸŸ¡ = Partially Addresses | (blank) = Not Addressed

---

## ðŸ”§ Detailed Module Breakdown

### 1. `automatic_quiz_generator.py` (644 lines)

**Primary Functions**:
- Parse lecture transcripts (VTT, TXT, PDF, DOCX)
- Generate N multiple-choice questions via LLM
- Create Canvas quiz with questions
- Schedule quiz (unlock/due/lock dates)
- Verify question quality

**Pain Points Addressed**:
- âœ… #12: Write exams efficiently **(PRIMARY)**
- âœ… #9: Ensure alignment of outcomes **(SECONDARY)**
- ðŸŸ¡ #3: Design fair assessments (can enhance for AI-resistance)

**Key Features**:
```python
generate_quiz_from_transcripts(
    course_id, transcripts_folder, quiz_title,
    num_questions=10, points_per_question=1,
    unlock_at=None, due_at=None, lock_at=None,
    hide_correct_answers=True, publish=False, dry_run=False
)
```

**Verification Integration**: âœ… Yes
- Structural checks (format, options, correct_index)
- LLM-based correctness verification
- Confidence scoring

**Canvas Integration**: âœ… Full
- Creates quiz via Canvas API
- Uploads questions
- Sets scheduling and visibility

---

### 2. `faq_generator.py` (788 lines)

**Primary Functions**:
- Read student questions from files
- Extract course context from syllabus
- Identify common/important questions
- Generate comprehensive answers
- Post FAQ as Canvas announcement
- Verify FAQ quality

**Pain Points Addressed**:
- âœ… #16: Respond to repetitive emails **(PRIMARY)**
- âœ… #15: Handle routine communication **(PRIMARY)**
- âœ… #14: Support beyond office hours **(SECONDARY)**
- ðŸŸ¡ #6: Individualized support (FAQs help all students)
- ðŸŸ¡ #17: Manage one-on-one demands (reduces volume)

**Key Features**:
```python
generate_faq_document(
    questions_folder, output_path="course_faq.md",
    max_faqs=20, format="markdown",
    syllabus_folder="syllabus",
    post_to_canvas=False, course_id=None,
    announcement_title="Course FAQ"
)
```

**Verification Integration**: âœ… Yes
- Checks question/answer quality
- Flags placeholder text
- Verifies category appropriateness

**Canvas Integration**: âœ… Full
- Posts FAQ as announcement
- HTML formatting support

**Unique Strength**: Syllabus context extraction for accurate answers

---

### 3. `organize_project.py` (767 lines)

**Primary Functions**:
- Read project materials (PDF, DOCX, PPTX)
- Extract text from documents
- Generate project overview via LLM
- Create assignment description
- Upload files to Canvas
- Create Canvas assignment with rubric

**Pain Points Addressed**:
- âœ… #2: Keep materials synchronized **(PRIMARY)**
- âœ… #13: Implement course updates **(PRIMARY)**
- âœ… #9: Ensure alignment of outcomes **(SECONDARY)**

**Key Features**:
```python
organize_and_upload(
    course_id, local_folder="final_project",
    canvas_folder_name="Final Project Materials",
    assignment_name="Final Project",
    points=100, dry_run=False
)
```

**Verification Integration**: ðŸŸ¡ Partial
- Uses LLM for content generation
- No explicit verification layer (could add)

**Canvas Integration**: âœ… Full
- Creates/updates folders
- Uploads files
- Creates assignments with rubrics

**Unique Strength**: Multi-format document parsing (PDF, DOCX, PPTX)

---

### 4. `rubric_templates.py` (module exists)

**Primary Functions**:
- Pre-built rubric templates (essay, presentation, lab, etc.)
- Customize point distribution
- Export to multiple formats (Markdown, HTML, JSON)

**Pain Points Addressed**:
- âœ… #8: Revise rubrics **(PRIMARY)**
- ðŸŸ¡ #3: Fair assessments (templates can include AI-work criteria)

**Key Features**:
```python
RUBRIC_TEMPLATES = {
    "essay": {...},
    "presentation": {...},
    "lab_report": {...},
    "programming_assignment": {...},
    "group_project": {...},
    "participation": {...}
}

customize_rubric(template_name, total_points=100)
save_rubric(rubric, output_path, format="markdown")
```

**Verification Integration**: âœ… Yes
- `verify_rubric()` checks point distribution
- Validates criterion completeness

**Canvas Integration**: ðŸŸ¡ Partial
- Exports to Canvas-compatible formats
- Manual import to Canvas needed

**Templates Include**:
1. Essay Writing
2. Presentation
3. Lab Report
4. Programming Assignment
5. Group Project
6. Class Participation

---

### 5. `announcement_generator.py` (439 lines)

**Primary Functions**:
- Parse course schedule file
- Extract week-specific topics
- Generate engaging announcements
- Post to Canvas

**Pain Points Addressed**:
- âœ… #15: Handle routine communication **(PRIMARY)**
- âœ… #13: Implement course updates **(SECONDARY)**

**Key Features**:
```python
generate_weekly_announcement(
    course_id, schedule_file="schedule.txt",
    week_number=1, post_to_canvas=False,
    dry_run=True
)
```

**Verification Integration**: ðŸŸ¡ Could Add
- Currently no verification
- Could add tone/appropriateness checking

**Canvas Integration**: âœ… Full
- Posts as Canvas announcement
- HTML formatting

**Unique Strength**: Schedule-aware context for timely announcements

---

### 6. `verification_system.py` (626 lines)

**Primary Functions**:
- Verify quiz questions (structure + facts)
- Verify FAQ entries
- Verify rubrics
- LLM-based correctness checking
- Generate review reports

**Pain Points Addressed**:
- âœ… #11: Balance innovation with integrity **(PRIMARY)**
- âœ… #21: Maintain AI consistency **(PRIMARY)**
- âœ… #3: Design fair assessments **(SUPPORTING)**

**Key Features**:
```python
# Structural verification (no LLM)
verify_quiz_question(question) -> VerificationResult
verify_quiz_batch(questions) -> (results, overall_confidence)
verify_faq_entry(faq) -> VerificationResult
verify_rubric(rubric) -> VerificationResult

# LLM-based verification
verify_quiz_answer_correctness(question) -> VerificationResult
verify_with_llm(content, content_type, verification_prompt)

# Reporting
create_review_report(verifications, output_path)
```

**Verification Checks**:

**Quiz Questions**:
- âœ“ Question length (10-300 chars)
- âœ“ Has question mark
- âœ“ Exactly 4 options
- âœ“ No duplicate options
- âœ“ Valid correct_index (0-3)
- âœ“ Balanced option lengths
- âœ“ LLM factual correctness

**FAQ Entries**:
- âœ“ Question length (>5 chars)
- âœ“ Has question mark
- âœ“ Answer length (10-1000 chars)
- âœ“ No placeholder text (TODO, TBD)
- âœ“ Valid category

**Rubrics**:
- âœ“ Has criteria (3-10)
- âœ“ Point distribution matches total
- âœ“ Each criterion has name, description, points
- âœ“ No single criterion >50% of total

**VerificationResult Object**:
```python
{
    "content_type": str,
    "confidence": float (0.0-1.0),
    "confidence_label": str (HIGH/GOOD/MODERATE/LOW/VERY LOW),
    "issues": List[str],        # Critical problems
    "warnings": List[str],      # Minor concerns
    "needs_review": bool,       # True if confidence < 0.75
    "timestamp": datetime
}
```

**Canvas Integration**: âŒ None (verification layer only)

**Unique Strength**: Multi-layer safety system (structural + LLM)

---

### 7. `app.py` (1309 lines)

**Primary Function**: User-friendly GUI for all tools

**Components**:
- API configuration (Canvas token, OpenAI key, Course ID)
- 5 tabs (Quiz, FAQ, Rubric, Project, Announcement)
- Output console with live updates
- Preview modes (dry-run)
- Help documentation

**Pain Points Addressed**:
- Makes ALL features accessible to non-technical faculty
- Reduces learning curve
- Provides safety (preview before posting)

**Key UX Features**:
- Token visibility toggle (show/hide)
- Browse buttons for file/folder selection
- Real-time output console
- Clear instructions in each tab
- Comprehensive help dialog

**Canvas Integration**: Coordinates all modules

---

## ðŸ“ˆ Impact Score by Module

| Module | Lines | Pain Points Addressed | Impact Score | Complexity |
|--------|-------|----------------------|--------------|------------|
| `faq_generator.py` | 788 | 5 (3 full, 2 partial) | â­â­â­â­â­ | Medium |
| `automatic_quiz_generator.py` | 644 | 3 (2 full, 1 partial) | â­â­â­â­â­ | Medium |
| `verification_system.py` | 626 | 3 (all full) | â­â­â­â­â­ | High |
| `organize_project.py` | 767 | 3 (all full) | â­â­â­â­ | Medium |
| `announcement_generator.py` | 439 | 2 (all full) | â­â­â­ | Low |
| `rubric_templates.py` | ~200 | 2 (1 full, 1 partial) | â­â­â­ | Low |
| `app.py` | 1309 | All (UI layer) | â­â­â­â­â­ | Medium |

**Total**: ~4,773 lines of Python code

---

## ðŸš€ Expansion Opportunities

### Easy Wins (1-2 weeks):
1. **AI-Resistant Question Types** - Enhance quiz generator prompts
2. **Caption Generator** - Use Whisper API for video captions
3. **Alt-Text Generator** - Use GPT-4 Vision for images

### Medium Effort (2-4 weeks):
4. **Feedback Generator** - Rubric + submission â†’ feedback
5. **Engagement Dashboard** - Canvas Analytics integration
6. **Content Updater** - Web search for current examples

### High Effort (1-2 months):
7. **Essay Auto-Grader** - LLM-based with rubric
8. **Student Chatbot** - Q&A system with course context
9. **Personalized Learning Paths** - Adaptive recommendations

---

## ðŸ’¡ Architecture Insights

### Shared Dependencies:
All modules use:
- `organize_project.call_llm()` for OpenAI API calls
- `verification_system` for quality checks
- Canvas API wrappers (`canvas_get`, `canvas_post`)
- Common file parsing utilities

### Data Flow:
```
User Input (app.py)
    â†“
Module-specific processing
    â†“
LLM generation (organize_project.call_llm)
    â†“
Verification (verification_system)
    â†“
Canvas upload (Canvas API)
    â†“
Output console (app.py)
```

### Safety Layers:
1. **Dry-run mode** - Preview before posting
2. **Verification system** - Structural + LLM checks
3. **Confidence scoring** - Flag low-quality outputs
4. **Human review prompts** - For low-confidence items

---

## ðŸ“‹ Conclusion

The codebase has **6 major functional modules** + **1 GUI layer**, totaling ~4,800 lines. Each module is well-scoped and addresses specific pain points:

- **Best Coverage**: Communication & assessment creation (5/5 pain points)
- **Good Coverage**: Content organization (3/5 pain points)
- **Opportunity**: Grading & feedback (0/3 pain points) â† Future expansion

The verification system is the **differentiator** - it's what makes this safe for faculty use vs. raw ChatGPT.

