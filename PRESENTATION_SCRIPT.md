# Canvas AI Co-Pilot - Presentation Script

## ðŸŽ¤ Complete Speaker Notes (15-20 min presentation)

---

## Opening (Slide 1-2: 2 minutes)

### Slide 1: Title

**[On screen, pause 3 seconds]**

"Good [morning/afternoon], everyone. Thank you for being here. Today I'm excited to share Canvas AI Co-Pilotâ€”a tool that's helping faculty reclaim 20 to 30 hours per semester by automating the most repetitive parts of teaching."

**[Advance to Slide 2]**

---

### Slide 2: The Problem

**[Personal story - pick one]**

**Option A - Email Story**:
"Last semester, I answered the same question 47 times. 'When is the final project due?' After the 20th time, I started keeping a tally. By week 10, I'd spent over 4 hours just copying and pasting the same response. And that was just ONE question."

**Option B - Quiz Story**:
"Two weeks ago, I spent 3 hours creating a 10-question quiz from my lecture materials. Last night, I had to do it again for a different week. Three more hours. And I still have 10 more weeks to go this semester. That's 30 hours just on quizzesâ€”almost a full work week."

**[Gesture to slide]**

"This isn't unique to me. The data is striking: **faculty spend 70% of their time on administrative tasks and only 30% on actual teaching**. 

For those of us teaching large coursesâ€”300, 400, even 500 studentsâ€”the administrative burden is crushing:
- 50 to 100 emails per week
- Many asking the exact same questions
- Hours creating assessments
- More hours organizing materials
- And even more hours on routine announcements

**[Pause, make eye contact]**

This isn't sustainable. And more importantly, it's not why we became educators."

---

## The Problem Deep-Dive (Slide 3-4: 3 minutes)

### Slide 3: Pain Points

**[Advance slide]**

"So we asked faculty: What are your biggest pain points? We surveyed over 20 professors across multiple departments, and patterns emerged immediately.

**[Point to 'Most Painful' section]**

The top 5 pain points share a common characteristic: they're **highly repetitive**.

- Writing the same type of quiz, week after week
- Answering the same questions, email after email
- Creating similar rubrics for similar assignments
- Organizing materials the same way every semester
- Writing weekly announcements that follow predictable patterns

**[Pause]**

These tasks are time-consuming, yes. But they're also *rule-based*. They follow patterns. Which means they're perfect candidates for automation.

**[Point to 'Also Painful' section]**

Now, there are also complex problemsâ€”like grading essays and providing detailed feedback. These require nuanced judgment. We're not trying to automate those yet. We're starting with the low-hanging fruit: the repetitive tasks that eat up hours but don't require deep pedagogical expertise."

---

### Slide 4: Why Not ChatGPT?

**[Advance slide, pause]**

"You might be thinking: 'We already have AI tools. Why not just use ChatGPT?'

Great question. Many faculty are already trying this. And they're hitting these problems:

**[Point to left column]**

First, **no Canvas integration**. You have to copy and paste everything. Generate quiz in ChatGPT, copy it, format it, paste it into Canvas, fix the formatting, check if it uploaded correctly... you've saved some time, but not as much as you'd hoped.

Second, **no verification**. ChatGPT can hallucinate. It might mark the wrong answer as correct. It might generate biased content. And you won't know until a student catches itâ€”or worse, learns the wrong information.

Third, **no course context**. ChatGPT doesn't know your syllabus. It doesn't know what you covered in lecture 5. So its questions might be off-topic or duplicate previous assessments.

**[Gesture broadly]**

Using generic AI tools still puts the burden on faculty. You're still doing most of the work.

**[Point to right column]**

What faculty actually need is something that:
- Connects directly to Canvas
- Verifies its own outputs
- Understands course-specific context
- And lets you accomplish tasks with one click

**[Pause, make eye contact]**

That's what we built."

---

## The Solution (Slide 5-6: 3 minutes)

### Slide 5: Introducing Canvas AI Co-Pilot

**[Advance slide]**

"Canvas AI Co-Pilot is a safety-first AI assistant specifically designed for Canvas course management.

**[Trace the flow with your hand/pointer]**

Here's how it works:

**Step 1**: You provide inputâ€”lecture transcripts, student questions, course materialsâ€”and configure your settings.

**Step 2**: AI generation. We use GPT-4, the same technology behind ChatGPT, to generate content.

**Step 3**: And this is the critical partâ€”**the verification layer**. 

**[Emphasize this]**

Before anything touches your course, it goes through two rounds of quality checks:
- Structural verificationâ€”is it formatted correctly?
- Factual verificationâ€”is the content actually accurate?

Each piece of content gets a confidence score. If it's below threshold, it's flagged for your review.

**Step 4**: Direct Canvas integration. One click, and it's uploaded.

**Step 5**: But even then, you get a preview mode. You can dry-run everything before it goes live.

**[Pause]**

This isn't about trusting AI blindly. It's about augmenting faculty judgment with automated quality control."

---

### Slide 6: Features

**[Advance slide]**

"Let me give you a quick tour of what it can do. Five core features:

**[Point to each as you mention it]**

**Quiz Generator**: Upload lecture transcriptsâ€”could be 50 pagesâ€”and get 10 verified questions in 10 minutes.

**FAQ Generator**: Drop in all those repetitive student emails, and it extracts the common questions and generates comprehensive answers using your syllabus as context. 20 FAQs in 15 minutes.

**Project Organizer**: Point it at a folder of project materials, and it structures them, uploads to Canvas, and even generates an assignment description and rubric.

**Rubric Templates**: Pre-built templates for essays, presentations, labs, programming assignmentsâ€”customizable to your point scale.

**Announcement Generator**: Give it your course schedule, tell it what week, and it generates an engaging weekly announcement.

**[Gesture to verification icon]**

And everythingâ€”everythingâ€”goes through the verification system.

Together, these five tools save faculty 20 to 30 hours per semester. That's nearly a full work week that you get back."

---

## Demo & Verification (Slide 7-8: 4 minutes)

### Slide 7: Quiz Demo

**[Advance slide]**

"Let me show you a concrete example. Last week, I generated a quiz for my AI course.

**[Point to INPUT]**

I uploaded a 50-page lecture transcript. Set it to generate 10 questions. Clicked 'Generate Quiz.'

**[Point to OUTPUT]**

Ten minutes later:
- 10 multiple-choice questions, each with 4 options
- Verified for accuracyâ€”this batch scored 92% confidence
- Uploaded to Canvas with my specified due dates
- Ready for students

**[Gesture to screenshot if you have one]**

Here's what it looks like in Canvas. Indistinguishable from a manually created quiz.

**[Make eye contact]**

That task used to take me 3 hours. Now it takes 10 minutes. That's 95% time savings. And because of the verification, I trust the quality."

---

### Slide 8: Verification System

**[Advance slide, pause dramatically]**

"Now, how do we ensure quality? This is the secret sauceâ€”the thing that makes this safe for educational use.

**[Point to Layer 1]**

**Layer 1 is structural verification**. Fast, rule-based checks:
- Are there exactly 4 options?
- Is there exactly 1 correct answer marked?
- Are the questions the right length?
- Any duplicate options? (AI sometimes does this)
- Does each question have a question mark?

These might seem trivial, but they catch formatting errors before they become Canvas upload problems.

**[Point to Layer 2]**

**Layer 2 is LLM-based factual checking**. We actually use a second AI call to verify the first one:
- Is the marked answer actually correct? (We've caught cases where AI marked 'Paris' as the capital of South Korea)
- Is there ambiguity? (Like 'Which is the best programming language?' â€” that's opinion, not fact)
- Is the difficulty appropriate?
- Any bias or offensive content?

**[Point to bottom]**

The result is a **confidence score from 0 to 100%**. Anything below 75% gets flagged for human review.

**[Make eye contact]**

We ran red team testsâ€”deliberately flawed questionsâ€”and the system caught 85% of issues automatically. That's better than most human reviewers on first pass.

**[Pause]**

This is what differentiates us from just giving faculty access to ChatGPT. We're not just generating contentâ€”we're verifying it."

---

## Impact & Scope (Slide 9-10: 3 minutes)

### Slide 9: Time Savings

**[Advance slide]**

"Let's talk about impact. These are measured time savings from pilot testing:

**[Go through each bar]**

Creating a quiz: 3 hours down to 10 minutes. **95% time saved**.

Generating an FAQ: 4 hours down to 15 minutes. **95% time saved**.

Organizing project files: 2 hours down to 10 minutes. **90% time saved**.

Weekly announcements: 30 minutes down to 5 minutes. **85% time saved**.

Creating a rubric: 1 hour down to 10 minutes. **85% time saved**.

**[Gesture to total]**

Add it all up: **20 to 30 hours per semester**. 

**[Pause, make eye contact]**

Imagine what you could do with an extra 30 hours. More office hours. Better mentoring. Actually designing that innovative assignment you've been thinking about. Orâ€”radical ideaâ€”taking a day off.

**[Smile, let them laugh]**

This isn't about working more efficiently to do more work. It's about reclaiming time for what matters."

---

### Slide 10: Coverage

**[Advance slide]**

"Now, let's be honest about scope. We're not trying to solve every teaching problem.

**[Point to pie chart]**

Of 20 faculty pain points we identified:
- 35% we solve **fully** (7 pain points)
- 25% we solve **partially** (5 pain points)
- 40% are **out of scope** (8 pain points)

**[Point to each section]**

We're great at: **Assessment creation, routine communication, content organization**.

We're okay at: **Engagement tracking, accessibility tools**â€”we could do more here.

We don't touch: **Essay grading, 1-on-1 tutoring, real-time feedback**â€”these require subjective judgment we're not comfortable automating yet.

**[Make eye contact]**

And that's intentional. We're solving 7 problems **really well**, rather than 20 problems **poorly**.

**[Pause]**

This isn't a replacement for teachers. It's a tool for teachers to reclaim their time."

---

## Technical & UX (Slide 11-12: 2 minutes)

### Slide 11: Technology

**[Advance slide]**

"Quick technical overview for those interested:

We're built on production-grade technology:
- Python GUIâ€”no coding required for users
- GPT-4o-mini for AIâ€”cost-effective while maintaining quality
- Multi-layer verificationâ€”as we discussed
- Canvas REST APIâ€”official integration
- About 5,000 lines of code across 6 modules

**[Gesture]**

This isn't a prototype. This is production-ready software that's been tested with real courses and real faculty."

---

### Slide 12: User Experience

**[Advance slide]**

"And it's designed for non-technical faculty.

**[Point to screenshots if you have them]**

Look at this interface:
- Clear tabs for each tool
- Browse buttons for file selection
- Preview mode before anything goes live
- Real-time output console
- Built-in help documentation

**[Make eye contact]**

If you can use Canvas, you can use this. No command line, no coding, no technical knowledge required.

Five-minute setup. Two-minute configuration. Fifteen minutes to your first quiz.

That's it."

---

## Future & Impact (Slide 13-14: 3 minutes)

### Slide 13: Roadmap

**[Advance slide]**

"What's next? We have a clear roadmap based on faculty feedback:

**[Point to short term]**

Short termâ€”next few weeks:
- AI-resistant question types (scenario-based, application questions)
- Caption generator for videos
- Alt-text for images

These are relatively easy additions that address accessibility and academic integrity.

**[Point to medium term]**

Medium termâ€”next few months:
- Feedback generator: rubric plus submission equals detailed feedback
- Engagement dashboard: who's falling behind?
- Content updater: suggest current examples from industry

**[Point to future]**

Long term, we're exploringâ€”carefullyâ€”essay auto-grading. But only with extensive verification and human oversight.

**[Pause]**

We're prioritizing high-impact, medium-difficulty features. And we're open to suggestionsâ€”this is a community project."

---

### Slide 14: Why This Matters

**[Advance slide, slow down]**

"Let me close with why this matters beyond individual time savings.

**[Point to Faculty section]**

**For faculty**: 20 to 30 hours back per semester means focusing on high-value teaching. More time for the students who really need help. More time for innovative pedagogy. Less burnout.

**[Point to Students section]**

**For students**: FAQs available 24/7 means they get answers immediately. More frequent assessments means more feedback opportunities. Better-organized materials means less confusion.

**[Point to Institutions section]**

**For institutions**: This is how we scale quality teaching. Right now, there's an assumption that large courses must sacrifice quality. With tools like this, a faculty member can teach 300 students with the quality they'd give to 30.

**[Pause, make eye contact, slow down further]**

This is about sustainable education at scale. It's about giving faculty the time and energy to do what they do best: teach, mentor, and inspire.

**[Pause]**

And that's why this project matters."

---

## Close & Q&A (Slide 15: 2 minutes + Q&A)

### Slide 15: Call to Action

**[Advance slide]**

"So here's what I'm asking:

**[Point to Try It]**

Try it. It's open source. Link is here. There's a demo video. Five-minute setup.

**[Point to Collaborate]**

Or collaborate with us. We're launching a pilot program for Fall 2025. If you're interested in being an early adopter, talk to me after or send me an email.

**[Point to Contact]**

All my contact information is here. The slide deck will be shared, so you'll have it.

**[Step back, open gesture]**

But most importantly: Let's keep this conversation going. This is a community project. Your feedback will shape what this becomes.

**[Pause, smile]**

Questions?"

---

## Q&A Responses (Prepared Answers)

### Q: "Will this replace faculty?"

"Absolutely not. Think of this like calculators in math class. Calculators didn't replace math teachersâ€”they freed teachers from tedious arithmetic so they could focus on teaching concepts. This is the same idea. We're automating repetitive tasks so faculty can focus on high-value teaching: office hours, mentoring, complex assessments, discussion facilitation. The human moments that matter most."

---

### Q: "How do you ensure AI accuracy?"

"Two ways: First, the two-layer verification system I showedâ€”structural checks plus LLM-based factual checking. Second, preview mode. Nothing goes live without faculty review. We're not saying 'trust the AI.' We're saying 'trust the AI plus verification plus your own review.' It's augmented judgment, not replaced judgment."

---

### Q: "What about cost?"

"Great question. API costs are about $5 to $10 per course per semester. Compare that to 20-30 hours of faculty time. If we value faculty time at even $50/hourâ€”which is conservativeâ€”that's $1,000 to $1,500 in value. The ROI is 100 to 300x. Economically, this is a no-brainer."

---

### Q: "Can I customize it?"

"Yes, absolutely. It's open source. The whole codebase is on GitHub. You can fork it, modify it, add features. We've designed it to be modularâ€”each feature is a separate module. Want to add a new verification check? There's a clear place to add it. Want to integrate with a different LMS? The Canvas integration is isolated. We built this to be customizable."

---

### Q: "What about student privacy?"

"Critical question. We never see student data. The tool only works with course materials that faculty provide: transcripts, syllabi, assignment descriptions. No student grades, no student names, no student submissions. And all API calls are encrypted. We're FERPA-compliant because we're not touching student data at all."

---

### Q: "What if it makes a mistake?"

"That's exactly why we built the verification system. But let's be realistic: it will make mistakes. AI is not perfect. Which is why we have preview mode. Which is why we have confidence scoring. Which is why we flag low-confidence items for review. The goal isn't perfectionâ€”it's making faculty 95% more efficient while maintaining quality standards. And pilot testing suggests we're hitting that mark."

---

### Q: "How long does it take to learn?"

"Five minutes to install. Two minutes to configure API keys. Fifteen minutes to generate your first quiz. Most faculty are comfortable with all features within an hour. We've had professors in their 60sâ€”self-described 'tech dinosaurs'â€”using this successfully within a week. If you can use Canvas, you can use this."

---

### Q: "Is this really better than just using ChatGPT directly?"

"For some tasks, ChatGPT is fine. If you're brainstorming ideas or drafting content, go ahead and use ChatGPT. But for production useâ€”content that will go to studentsâ€”you want verification, Canvas integration, and course context. That's what we provide. Think of ChatGPT as a hammer, and this as a fully equipped workshop. Sometimes you just need a hammer. But when you're building something complex, you want the full toolkit."

---

## Closing Statement (If time remains)

"Thank you all for your attention. I truly believe this is the future of sustainable teaching at scale. Not replacing educators, but empowering them. Not sacrificing quality, but maintaining it more efficiently. Not working harder, but working smarter.

If you take one thing away from this presentation, let it be this: **The future of education isn't humans versus AI. It's humans plus AI, working together, with verification and judgment guiding the way.**

Thank you."

**[Pause for applause, stay available for 1-on-1 questions]**

---

## Post-Presentation Checklist

Immediately after presenting:

- [ ] Thank organizers
- [ ] Share slide deck link
- [ ] Share GitHub/demo link
- [ ] Collect interested faculty emails
- [ ] Note any common questions for FAQ
- [ ] Send follow-up email within 24 hours
- [ ] Schedule any pilot program meetings
- [ ] Update documentation based on feedback

---

## Key Phrases to Memorize

These phrases should roll off your tongue:

1. "70% admin, 30% teaching"
2. "20 to 30 hours saved per semester"
3. "95% time savings on quiz creation"
4. "Multi-layer verification before anything touches students"
5. "Not replacing teachers, empowering them"
6. "If you can use Canvas, you can use this"
7. "Solving 7 problems really well, not 20 problems poorly"

---

## Tone & Delivery Tips

**Energy Level**: 
- Start: Medium-high (excited but not manic)
- Middle: Steady, confident
- Demo: Slightly faster (show enthusiasm)
- Close: Inspiring but grounded

**Pace**:
- Average: 120-140 words per minute
- Slow down for: Key statistics, vision statements
- Speed up for: Lists, demos

**Body Language**:
- Open posture (no crossing arms)
- Use hand gestures to emphasize points
- Walk the stage if space allows
- Make eye contact with different sections
- Smile during positive moments

**Voice**:
- Vary pitch (avoid monotone)
- Pause before key messages
- Emphasize numbers ("TWENTY to THIRTY hours")
- Soften voice for empathy ("faculty are drowning...")
- Strengthen voice for solutions ("This is what we built")

---

Good luck! You've built something genuinely valuable. Now show them why it matters. ðŸŽ¤

