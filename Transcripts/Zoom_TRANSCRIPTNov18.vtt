WEBVTT

1
00:00:01.123 --> 00:00:05.376
Classroom 410: Got a whole minute.

2
00:00:07.040 --> 00:00:08.660
Classroom 410: It's about that.

3
00:00:08.900 --> 00:00:11.220
Classroom 410: Did you hear record?

4
00:00:12.159 --> 00:00:26.430
Classroom 410: It's gonna put us to sleep. It's weird, it's either like all the way dark. Yeah.

5
00:00:27.587 --> 00:00:30.870
Classroom 410: good afternoon, folks, 2 days ago.

6
00:00:31.350 --> 00:00:37.730
Classroom 410: So we have a case study today. But, as usual on Monday, we like going through what's next?

7
00:00:37.990 --> 00:00:44.999
Classroom 410: We have not including this class, 4 classes left. You can believe that until this is done.

8
00:00:45.070 --> 00:01:00.280
Classroom 410: So a couple things. So you saw your grading for the group exam. And I forgot my notes in the back. I want to pass on a couple of things that I'll help you out during the final exam. And the way of thinking about this as well.

9
00:01:00.530 --> 00:01:11.600
Classroom 410: So the exam average is the highest. Been in a couple of years for that it was a 90% for the median. And I like going the median rather than mean for that. They're about the same.

10
00:01:11.780 --> 00:01:18.489
Classroom 410: 2 pieces of advice for moving forward, especially for the final exam

11
00:01:18.680 --> 00:01:22.579
Classroom 410: is, it's great to put down the stop.

12
00:01:22.710 --> 00:01:47.659
Classroom 410: But the best answers have evidence. So this is like, where did this thinking come from? Is it from a framework? Is it from a reading? You have everything in front of you? You should be easily be able to make the connections rather than a stream of consciousness of different things, where I don't know why these things are pulled together in the way they're pulled together. So try to always use evidence

13
00:01:47.660 --> 00:02:09.839
Classroom 410: foundations for all your arguments because it's open book. That should be easier done than a closed book environment. Do you understand what I'm saying by that. It's like you jotted down 6 things for this answer, like, why, those 6 things, what are you drawing on for? Those particular things is, are the very best answers. And some of you did an amazing job of doing exactly that

14
00:02:10.110 --> 00:02:12.340
Classroom 410: case. Studies were back.

15
00:02:12.510 --> 00:02:23.070
Classroom 410: Participation is key in those case studies. That's a hint for today. The Mini case study that is coming up when you all presenting.

16
00:02:23.250 --> 00:02:48.239
Classroom 410: Yeah. So there's only 2 questions for you to fill out. It's just like discussions. We pulled that into your participation. As well. So we'll be doing those 2 questions. I'll look at them, curate them, give them to the teams in advance, and they can use them. How they want for those 2 questions as well. And then we have a virtual class on the 25th

17
00:02:48.290 --> 00:02:55.109
Classroom 410: quick reminder about etiquette in zoom classes. If you forget, remember that whole thing.

18
00:02:55.110 --> 00:03:20.010
Classroom 410: It's important that we all show up our cameras are on. There's nothing distracting during, you know. Remember all that zoom etiquette we had to worry about. So I just want to do that because I don't want Joe Grant, who's a very busy person to show up to a bunch of black screens or people, you know, in distracting environments. Let's show up with our a game for that particular thing on the 25, th and again thank Professor Lewis for talking me into that

19
00:03:21.370 --> 00:03:28.090
Classroom 410: as well. So and then the last thing I have. If you look down, we have this final exam.

20
00:03:28.440 --> 00:03:32.609
Classroom 410: This is when it's due. Right? So we have one more case discussion.

21
00:03:33.180 --> 00:03:36.359
Classroom 410: This is when it's due 5 pm. The 17.th

22
00:03:37.168 --> 00:03:41.079
Classroom 410: We are going to launch the final exam

23
00:03:41.600 --> 00:03:46.880
Classroom 410: right after the last class on December 4.th So you have a couple of weeks

24
00:03:47.030 --> 00:03:51.369
Classroom 410: to take this thing. Well, a couple of weeks is a stretch, but it's not far of a stretch.

25
00:03:52.400 --> 00:04:04.780
Classroom 410: so you'll be able to take a look at that. And it's same thing. Time exam scenarios. We provide you with chat, Gt answers. And we want your thinking about how you solve particular problems.

26
00:04:04.850 --> 00:04:14.940
Classroom 410: You should be really good at it by the final exam. Right? And we draw, we should all 8 set as well. So that's all the announcements I had today any questions or anything I can help you with.

27
00:04:15.390 --> 00:04:30.872
Classroom 410: Yeah, so for the exams, like, I don't really know, because I didn't get a hundred like. I don't really know what scores a hundred like. I don't like contextualization for that. So if you look at the

28
00:04:31.510 --> 00:04:52.709
Classroom 410: I gave you example answers for 100. If you look under the things in that. So you're gonna see a text that's like about this debts for all of them that will anchor. This is what I'm looking for. These are the elements, and this is the the thing I was looking for. So take a look at that, and if still not sure what that Delta is it? Just come, chat with me. I'm happy to help you out.

29
00:04:56.770 --> 00:04:59.000
Classroom 410: No grad groups get a pass.

30
00:04:59.140 --> 00:05:06.240
Classroom 410: Yeah on. Are you talking about the discussion questions for that? Yeah, let's concentrate on the presentation

31
00:05:07.030 --> 00:05:26.059
Classroom 410: sounds good. But you can help each other out because, like, we said, we're gonna help out. Our fellow students. And you guys are gonna have a great discussion with the 2 mini presentations. Right? So they're not standing up here ask a question, and then nobody answers it for 5 min, like you do for me. You'll actually help them out.

32
00:05:26.610 --> 00:05:32.470
Classroom 410: It's 30 seconds, but it seems like 5 min when you're standing up here. Nobody answers. Yeah, it seems like a long time.

33
00:05:32.510 --> 00:05:34.000
Classroom 410: Any other questions.

34
00:05:34.900 --> 00:05:42.440
Classroom 410: Yeah. Great job with group exam, keep it up with cases. Let's go with the participation. And let's end strong. Does that sound good? All right.

35
00:05:57.025 --> 00:06:02.880
Classroom 410: Okay, right side equifax for my favorite case.

36
00:06:02.930 --> 00:06:11.769
Classroom 410: Maybe my second favorite case. But it's a classic example, because it affected all of you. So the 1st question in the case write up is, How did you become an Equifax customer.

37
00:06:12.260 --> 00:06:20.739
Classroom 410: Hopefully you thought about that and said, Well, I don't even sign up to become an Xbox customer. Well, that's because you're a customer, even though you didn't sign up to be.

38
00:06:20.770 --> 00:06:31.779
Classroom 410: And that's part of the outrage of this case that a lot of people affected. They didn't go sign up for Equifax to be a customer of equifax because of how their business model works.

39
00:06:32.960 --> 00:06:45.140
Classroom 410: So we start the next few classes. Now that Professor Wright's reign of terror is over talking about Internet of things again. So I've got one for you. Let's play. Is it real before we jump into it?

40
00:06:45.780 --> 00:06:51.440
Classroom 410: So these are real hackers actually attacked a casino through a

41
00:06:51.490 --> 00:06:55.919
Classroom 410: an Internet connected thermometer in a fish tank in the lobby.

42
00:06:55.950 --> 00:07:09.329
Classroom 410: They actually went through this this thermometer in the lobby. They moved laterally. They were able to gather data about the high, the high rollers database. And then they exiled that through that same thermostat. What do you think?

43
00:07:09.520 --> 00:07:11.790
Classroom 410: We think that that's a plausible story.

44
00:07:12.840 --> 00:07:24.290
Classroom 410: and we're getting more cynical. So yeah, that that happened. This was an attack venue for a very large Casino group.

45
00:07:24.330 --> 00:07:32.330
Classroom 410: where they actually were able to expo all this data through this Internet thermometer. The Nicole Egan, who

46
00:07:32.460 --> 00:07:58.279
Classroom 410: is a very nice lady Dark trace was one of the firms that actually figured out the forensics of how they got into the system and how they got access to this data, and they did it. You know this thermostat was running this early version of Android, because that you know, it's easier than writing your own operating system. And so the hackers actually hacked this this thermometer, and they used it to move laterally within the Casino. Gather this data and then exfil it through that same thermometer.

47
00:07:58.890 --> 00:07:59.870
Classroom 410: Oh, great!

48
00:08:00.240 --> 00:08:01.259
Classroom 410: That's pretty cool.

49
00:08:01.847 --> 00:08:20.220
Classroom 410: So experts estimate that we're looking at 31 billion IoT devices on networks this year. So we talked about it before average Americans have about 15 in their house, now 15 in American households. And so all of those are a potential access method into a corporate network.

50
00:08:22.510 --> 00:08:27.249
Classroom 410: So before we go into equifax today, we're going to talk about risk

51
00:08:27.290 --> 00:08:39.209
Classroom 410: registers. I'll get to do a little exercise on risk registers. Then we'll talk about the equifax breach in some detail, because it's a really important kind of bellwether about incident response.

52
00:08:39.440 --> 00:08:44.649
Classroom 410: And then we'll wrap up incident response today and get ready for the grab on Wednesday.

53
00:08:45.740 --> 00:09:03.879
Classroom 410: So management. So Professor Wright ran out of time when we were talking about the subject. But the idea here is that risk and the management risk can be estimated. A lot of what you'll do if you go into this field is actually think about potential scenarios and how impactful they would be to different companies.

54
00:09:04.350 --> 00:09:20.939
Classroom 410: So one tool to do that is called a risk register. And so, you know, if a risk is catastrophic. But the chances of it happening are not very common, then it's probably less of a risk than a less impactful risk that might happen more often.

55
00:09:21.210 --> 00:09:25.690
Classroom 410: So a risk register is just that is actually trying to codify these risks.

56
00:09:26.250 --> 00:09:43.259
Classroom 410: So we're going to go back to the Phoenix case here and look at an example of a risk register where the Phoenix Project team, when they were engaged to try to solve this critical cybersecurity issue, they went through, and they actually came up with a number of different risks, and then thought about how likely they'd be.

57
00:09:43.562 --> 00:09:46.589
Classroom 410: So I'm gonna ask you all to do the same thing now.

58
00:09:46.908 --> 00:09:51.919
Classroom 410: So we're gonna take about 10 min. Just grab 4 or 5 people around you up on canvas.

59
00:09:52.370 --> 00:09:58.519
Classroom 410: They're under November, November 11.th There's a template for you to work in your groups

60
00:09:58.610 --> 00:10:07.030
Classroom 410: and think about 3 to 5 risks that Uva faced when they were making the decision specifically when they were making decision to turn the network on

61
00:10:08.367 --> 00:10:27.759
Classroom 410: so that template is up under November 11.th It's a word, Doc. Grab your neighbors. Let's go groups of at least 4, and then, when you're done, I'll give you 10 min. We'll come back at 1250. I'll just go ahead and submit that it's an ungraded quiz on canvas. Then we'll talk about what risks you thought about sound good

62
00:10:30.160 --> 00:10:34.729
Classroom 410: sounds good. Alright, is it? There? It's under November 11.th Okay.

63
00:11:01.200 --> 00:11:08.010
Classroom 410: okay?

64
00:11:14.920 --> 00:11:16.095
Classroom 410: No.

65
00:11:19.410 --> 00:11:43.930
Classroom 410: So pick a scribe. Not everyone has to fill this out. But in your group

66
00:11:43.930 --> 00:12:23.109
Classroom 410: 3 or 4, 5, just one person can write it down that could probably arrest

67
00:12:50.170 --> 00:12:56.369
Classroom 410: like a 3rd party

68
00:13:01.352 --> 00:13:21.279
Classroom 410: that could be like.

69
00:13:55.160 --> 00:14:15.559
Classroom 410: I think it could actually.

70
00:14:15.560 --> 00:14:40.329
Classroom 410: really, what you were focused on is the impact and the probability. So identify the risks. How impactful you think they are. And what's the likelihood of

71
00:17:45.700 --> 00:17:58.020
Classroom 410: yeah.

72
00:18:25.566 --> 00:18:47.699
Classroom 410: I feel like it's a little lower than

73
00:19:12.480 --> 00:19:24.890
Classroom 410: yeah.

74
00:20:32.916 --> 00:20:56.110
Classroom 410: You guys doing pretty good. You got you got a few enough to discuss.

75
00:20:56.110 --> 00:21:20.890
Classroom 410: All right. Let's give it a shot if you still work on it, you know again this is ungraded. It's 1 per group. You submit it. We just want to

76
00:21:20.890 --> 00:21:28.310
Classroom 410: see your thoughts after the fact dude. That's really impressive. Give me one who's got a risk

77
00:21:29.531 --> 00:21:41.270
Classroom 410: like a timing issue like how they're not able to like, reset all the systems, the department on time, because they only had, like a weekend to do everything so

78
00:21:41.570 --> 00:21:45.540
Classroom 410: it could be an issue where it's like they weren't able to get to all the departments.

79
00:21:45.870 --> 00:22:12.000
Classroom 410: So what did you feel like in your group? You're talking about that. What's the impact of that one to 4? I would say the impact would probably be like a 3 probability would probably be like a 2, because I assume they planned it out well enough were they able to get it. But they're still, like, you know, just depending on how long it takes for them to make those assessments. Who else has got one

80
00:22:12.120 --> 00:22:13.014
Classroom 410: another?

81
00:22:14.778 --> 00:22:28.230
Classroom 410: So we said, like they like mitigation. Strategy is like they kind of like segmented the whole entire network.

82
00:22:29.360 --> 00:22:35.520
Classroom 410: So what's the risk that you identify?

83
00:22:35.910 --> 00:22:44.090
Classroom 410: Okay? And what's the likelihood in your group's estimate? The impact would be additional 4. And then probability is equal.

84
00:22:44.460 --> 00:22:46.550
Classroom 410: Whoa! So this is a big one

85
00:22:46.830 --> 00:22:53.359
Classroom 410: like and you right? You're rightly recommend. I mean, they moved to 63 obviously lateral movement was a big thing in this attack.

86
00:22:53.620 --> 00:22:56.519
Classroom 410: So okay, that's a big one. Who else has got one.

87
00:22:57.400 --> 00:23:06.250
Classroom 410: We talked about like unclear communication. If everyone's on different pages. So that would delay like the going dark phase and everything like that.

88
00:23:06.609 --> 00:23:16.899
Classroom 410: And the mediation for that was basically how she was on phone calls with the personal phone numbers of like the Board of Directors, and then created the war room for all the teams to be on the same page in one room

89
00:23:17.010 --> 00:23:19.840
Classroom 410: risk factor. I think we put it at a

90
00:23:21.230 --> 00:23:26.290
Classroom 410: 3 and we plan it at 3, 4.

91
00:23:29.476 --> 00:23:35.800
Classroom 410: okay, so couple more couple more in the room. What else we have.

92
00:23:36.810 --> 00:23:58.039
Classroom 410: Phoenix Project. You read the case, you read the follow. What else? We got systems that need to be brought down and completely rebuilt, cannot be adequately achieved. Oh, that's a big one. So what happens when we try to go light and our systems aren't ready. So how likely did you see that as happening?

93
00:23:58.711 --> 00:24:03.530
Classroom 410: Okay, they did a lot of planning. But anything's possible.

94
00:24:03.740 --> 00:24:10.410
Classroom 410: And then the impact would be it. It really depends on the system. Right? It doesn't matter if

95
00:24:10.650 --> 00:24:18.229
Classroom 410: Professor Wright can't get to his cat video database. But it does matter if the hospital can't get to their critical patient records.

96
00:24:19.160 --> 00:24:26.960
Classroom 410: Okay, so you understand, the concept of risk registers. The reason why we walk through this exercise is we will do this again.

97
00:24:26.990 --> 00:24:30.359
Classroom 410: and you know. But is this a science?

98
00:24:32.720 --> 00:24:44.610
Classroom 410: No, not really. It's there's a little bit of art in here. So estimating, the likelihood of something happening is a challenge. And this is what Pwc and accenture in Deloitte. This is what they do.

99
00:24:45.030 --> 00:24:52.169
Classroom 410: And then estimating the impact is a challenge, too, because sometimes you don't know how impactful something is until it happens.

100
00:24:52.652 --> 00:24:58.909
Classroom 410: But this is important exercise, because it makes all the stakeholders think about what could go wrong and how wrong it could go.

101
00:24:59.940 --> 00:25:01.179
Classroom 410: That's right. You wanna

102
00:25:01.310 --> 00:25:10.860
Classroom 410: add anything to the end of risk registers? Or, yeah, I think one of the things I'll just underline what I ended up last class talking about

103
00:25:11.160 --> 00:25:22.399
Classroom 410: risk registers really help us identify what the right simulations we're going to run. So your company is like, do we do a ransomware simulation? Do we do a simulation about

104
00:25:22.560 --> 00:25:38.240
Classroom 410: about Pii? Do we do a simulation about a cloud attack like what which ones do we do? There's so many different types, what we had, 9 different groups and 9 different simulations. I actually wrote 12 of them. There were so many more that we could have done. Is it a ddos etc?

105
00:25:38.330 --> 00:25:46.850
Classroom 410: So this tool will help you identify. This is our most pressing risk. We should probably know how to address and respond to this

106
00:25:46.960 --> 00:26:16.840
Classroom 410: right. And it's the same thing when you're talking about the Phoenix project. This is our most pressing risk with the Phoenix project. We should probably be able to address this. So when it happens, we're not scrambling, trying to find all the parts we love, we know exactly what to do. We know exactly who to talk to, and we run that play like a playbook, and it helps out tremendously. That is what we talk about building resilience. So I don't know if you wanted my answer to be that long, so I apologize. I never do. No.

107
00:26:18.200 --> 00:26:27.150
Classroom 410: all right. Well, thank you all. So let's jump into Equifax, and I'll start with. Been in this room for 2 and a half months. Why are there cyber attacks?

108
00:26:27.660 --> 00:26:28.860
Classroom 410: You've got an answer.

109
00:26:29.020 --> 00:26:31.569
Classroom 410: What's 1 reason there are cyber attacks.

110
00:26:31.790 --> 00:26:37.380
Classroom 410: Let's go. And it's valuable information that you can sell a lot of the time. Okay, so who's doing the attacks? Then

111
00:26:38.569 --> 00:26:44.159
Classroom 410: criminals, right. Criminals do things for money. Why else why else are there cybers?

112
00:26:44.260 --> 00:26:56.930
Classroom 410: Let's keep going. That could be like nation state actors just trying to cause like panic or geopolitical right? So we we. This happens all the time the Ukraine is under constant attack, so try to find your competitors.

113
00:26:57.440 --> 00:27:22.449
Classroom 410: That's right. So I, my hot dog, stand's not doing well. So I'll just Ddos Sarah's hot dog stand, and I'll keep moving. I don't think they're gonna be like forms of protest, or just like want to take down company servers or like you're trying to like protest something they're doing activists. Right? You know, I'm trying to make a message. I'm going to stop your message. Maybe even like, test their programs like, test their viruses

114
00:27:23.010 --> 00:27:33.130
Classroom 410: just for fun. See what I can see. Okay, why are there cyber attacks?

115
00:27:33.702 --> 00:27:36.599
Classroom 410: Can all cyber attacks be stopped?

116
00:27:37.020 --> 00:27:38.450
Classroom 410: Can we stop all attacks?

117
00:27:42.350 --> 00:27:50.640
Classroom 410: Why are you sitting here? We can't stop all the time? Not necessarily just because there's so much like information out there that, like.

118
00:27:50.700 --> 00:27:58.330
Classroom 410: there's bound to be weaknesses in certain systems. But it's not, I think, like one of the main focus has been like, it's always about like stopping the attack, but kind of responding

119
00:27:58.460 --> 00:28:07.729
Classroom 410: correct. So we've just spent 4 class periods on incident response probably wouldn't do that if the answer was, build a bigger wall, build a bigger mode.

120
00:28:07.840 --> 00:28:11.980
Classroom 410: We've established that we can't keep the bad guys out. Cyber attacks are gonna happen.

121
00:28:13.250 --> 00:28:21.740
Classroom 410: So keep that in mind as we talk about equifax equifax equifax

122
00:28:22.393 --> 00:28:32.759
Classroom 410: you know, one of the 3 major credit reporting bureaus that you know. Help make your bear, Isaac and Company score your fico score. Does anybody know what their credit score is?

123
00:28:34.370 --> 00:28:48.959
Classroom 410: You don't have to tell me. But yeah, you need a credit score if you're actually going to initiate new credit. So this is pretty big to basically the fundamentals of capitalism. You know, if we can't extend credit, then people don't buy things.

124
00:28:49.160 --> 00:28:54.579
Classroom 410: What are the other 2? Equifax is one, know what the other 2 are majors, cotton spirit.

125
00:28:54.790 --> 00:28:59.663
Classroom 410: trans. One. It's a 3rd transient. Okay, we got all 3 right?

126
00:29:00.110 --> 00:29:07.820
Classroom 410: So what happened back in 2017? Well, equifax was breached, and it affected 143 million people.

127
00:29:07.990 --> 00:29:20.670
Classroom 410: So one of the reasons why this angered people so much is that, do you remember signing up to be an Equifax customer? No, you don't, because you didn't have the option. You don't have the option not to be an equifax customer.

128
00:29:20.730 --> 00:29:29.740
Classroom 410: If you were going to live on the grid and do financial things. In this country, you, or in most countries, you are going to be a customer of equifax.

129
00:29:31.030 --> 00:29:38.689
Classroom 410: So equifax as it ranks. So I love information is beautiful. They visualize all kinds of fun things.

130
00:29:38.830 --> 00:29:43.729
Classroom 410: But we're going to take a look at some of the biggest breaches in history.

131
00:29:44.050 --> 00:29:46.859
Classroom 410: so I'll point out a couple of things here if I can.

132
00:29:47.420 --> 00:29:49.029
Classroom 410: It's obnoxious to have

133
00:29:49.545 --> 00:29:56.370
Classroom 410: cool site right? And so it shows all the biggest breaches in history whether or not they're interesting. And what happened?

134
00:29:56.873 --> 00:30:00.539
Classroom 410: Notice a couple of things here, one. As I scroll down.

135
00:30:00.550 --> 00:30:03.900
Classroom 410: We're going from 2024 backwards.

136
00:30:04.200 --> 00:30:12.250
Classroom 410: And so you may look at this and say, Wow! We're getting so much better at not having major breaches. But the answer is just the opposite. We are getting

137
00:30:12.630 --> 00:30:19.859
Classroom 410: equally bad worse. In a lot of cases we lose more records every year as a holistically

138
00:30:19.890 --> 00:30:22.639
Classroom 410: and so equifax was a massive breach.

139
00:30:22.790 --> 00:30:27.100
Classroom 410: and at the time it was staggeringly big. And does anyone remember it

140
00:30:27.510 --> 00:30:31.280
Classroom 410: like I asked you a question like, Were you personally affected? Were your parents affected?

141
00:30:31.480 --> 00:30:34.520
Classroom 410: Was anyone like spitting on the floor, mad about this.

142
00:30:34.530 --> 00:30:41.060
Classroom 410: No, I was saying that since this was like 2017, because I was like 14, I am.

143
00:30:41.230 --> 00:30:45.359
Classroom 410: I think we were just oblivious to it. Kind of, but I think

144
00:30:45.480 --> 00:30:51.633
Classroom 410: the reality of it is we probably did get affected, or something we know got affected just from like the sheer size of it.

145
00:30:52.200 --> 00:30:56.500
Classroom 410: but it's hard to tell, because we were so young. I think we just didn't really doing but

146
00:30:56.720 --> 00:31:00.400
Classroom 410: aware of it, or like, maybe just didn't really care. I don't really know.

147
00:31:01.240 --> 00:31:13.079
Classroom 410: Yeah, I asked my mom. And she said, like, we get so many letters about data breaches all the time that, like none of them, actually stick out as memorable ones. So probably, but like we don't know.

148
00:31:13.180 --> 00:31:25.509
Classroom 410: So you know, if you look at this, does anyone not use Facebook anymore? Because, well, you guys never use Facebook anyway. But Facebook owns Instagram. You guys don't use Instagram right? Because of these major data breaching.

149
00:31:25.870 --> 00:31:38.920
Classroom 410: You don't shop at home depot. You don't show up at target. You never stay at Marriott Hotel. Oh, wait the list, the list, the list the list. They've all lost your data. They've all had major cybersecurity breaches. But because of the size and scope of this thing.

150
00:31:39.260 --> 00:31:44.359
Classroom 410: I there's just no way to avoid companies that have had missteps.

151
00:31:47.210 --> 00:31:49.560
Classroom 410: Oh, fun! Fun! Fun!

152
00:31:49.946 --> 00:32:01.379
Classroom 410: This databreaches.net is another cool site, because we don't have time to go into it today, but it actually lists out every single law that was broken during the data.

153
00:32:01.610 --> 00:32:09.579
Classroom 410: And so it has a if you were affected, you got that letter in the mail. You can actually go see what laws were affected, and why you got that letter.

154
00:32:10.800 --> 00:32:14.865
Classroom 410: But let's talk about Equifax so

155
00:32:15.900 --> 00:32:20.269
Classroom 410: As I mentioned before, you know, Equifax has been around for a long time.

156
00:32:20.290 --> 00:32:30.920
Classroom 410: fair Isaac and Company, and the Fico Score Equifax is one of the granddaddies of collecting information on you to let other businesses know what your credit worthiness is.

157
00:32:31.550 --> 00:32:38.199
Classroom 410: So I will turn to one of the world's foremost cyber security experts. To give you a succinct

158
00:32:38.250 --> 00:32:40.709
Classroom 410: summary of what?

159
00:32:40.820 --> 00:32:58.759
Classroom 410: There's nothing more powerful than you making your thing happen, really going for it, doing business now with that massive security breach, possibly putting 143 million Americans at risk hackers targeting credit Monitoring Company Equifax.

160
00:32:58.760 --> 00:33:21.540
Classroom 410: And now the FBI is investigating, and Rebecca Jarvis is here with all the details. Good morning, Rebecca. Good morning to you, Michael, and this is one of the largest data breaches in history. It happened at equifax the company that tracks all your credit cards and mortgages to determine your credit score. Half of all Americans potentially exposed their highly sensitive personal information now in the hands of hackers.

161
00:33:22.170 --> 00:33:51.139
Classroom 410: This morning 143 million consumers potentially hidden a massive data breach of Credit Monitoring Company equifax, the hackers accessing highly sensitive information, including social security numbers, birth dates, addresses, even some driver's license numbers as well as credit card numbers for approximately 209,000 Americans. The problem is that the social security number is the skeleton key to our identities.

162
00:33:51.260 --> 00:33:57.940
Classroom 410: And when that's stolen, we're in a position where we're going to have to be looking over our shoulders for the rest of our lives.

163
00:33:58.050 --> 00:34:27.850
Classroom 410: Equifax is one of 3 companies that tracks everything from your payments on credit cards, mortgages, student and credit loans to utilities to determine your credit score. What Equifax knows and reports about you decides whether you get a loan and how much you pay. But, unlike previous data breaches, many may not even be aware they're customers of equifax. Since Equifax gets its information from banks, credit card companies, and lenders not consumers themselves.

164
00:34:27.850 --> 00:34:32.919
Classroom 410: The unauthorized access happening between mid-may and July of this year.

165
00:34:33.469 --> 00:34:57.869
Classroom 410: Equifax says it will mail consumers who've been affected. They've also set up a website, equifax security, 2 0 1 7.com to help you determine. If you've been impacted, you can also sign up there for credit monitoring and identity theft protection. But, Michael, you know, once this number gets out, it's out, and when in the hands of a bad actor it's a real big problem. You're always looking over your shoulder, and the most important thing is to ask.

166
00:34:57.870 --> 00:35:05.640
Classroom 410: now make sure as a consumer, you know what's happening with your information, so much damage can be done with all this information so much. Thank you, Rebecca.

167
00:35:06.810 --> 00:35:10.270
Classroom 410: We tried to get Strahan in to do it. He's a busy guy.

168
00:35:10.805 --> 00:35:24.970
Classroom 410: So here's the business model. I think we all pretty much have it now. So Equifax is collecting information from people you do business with to create that score. They also have a number of direct consumer products such as

169
00:35:27.260 --> 00:35:28.770
Classroom 410: anybody. Anybody.

170
00:35:29.440 --> 00:35:47.930
Classroom 410: Yeah, that's ironic. A little irony there. But they have, you know, credit monitoring products. They have basic credit reporting products for individual consumers, because some people believe it or not like to see their credit score every single day, and they want to see what affects it as it goes up.

171
00:35:48.600 --> 00:35:49.206
Classroom 410: Let me.

172
00:35:50.640 --> 00:36:04.219
Classroom 410: So as we go into the case, academics, love frameworks. And so we'll look at a framework for how we address risk. Try to put your your hat on in terms of equifax through equifax. What do you do? You handle data for a living.

173
00:36:04.530 --> 00:36:09.010
Classroom 410: And so this is just one. And we just talked about risk registers is another one.

174
00:36:09.080 --> 00:36:31.580
Classroom 410: but a risk management approach for it solutions. So in order to identify risk. You have to know what your risks are. You have to clarify it, and then you have to do that exercise that we just did where you think about potential losses from a particular incident, because if the risk is catastrophic, but the chances of it happening are one in a million, you shouldn't spend too many resources on.

175
00:36:33.150 --> 00:36:50.530
Classroom 410: So in any scenario like this, like in Equifax, you're going to think about your potential sources of risk from an it perspective. So that can be your own internal employees. That could be folks you're working with. That can be bad actors like hackers. And it can be your technology itself which actually brings risk into your environment.

176
00:36:51.230 --> 00:36:58.770
Classroom 410: So all of this framework is just a precursor to our conversation about what happened and why it happened.

177
00:37:00.320 --> 00:37:03.769
Classroom 410: So let's look at the timeline. So this is directly from the case.

178
00:37:03.790 --> 00:37:15.719
Classroom 410: There's a couple of things here, you know. We all read the case. We understand what happened more or less, but just identifying the big gaps here. Right? So things bad things happened here on the 10.th

179
00:37:15.950 --> 00:37:26.670
Classroom 410: And then there's these huge stretches of time until we actually, you know, have notifications for for important folks within the company.

180
00:37:27.010 --> 00:37:32.130
Classroom 410: And so part of the conversation today, when we think about the case is, those stretches of

181
00:37:33.290 --> 00:37:35.739
Classroom 410: this happened during this class.

182
00:37:35.980 --> 00:37:39.520
Classroom 410: So we got to watch equifax implode.

183
00:37:39.630 --> 00:37:46.799
Classroom 410: So they announced this after hours on Thursday, and then they lost 2.3 3 billion dollars in market cap.

184
00:37:47.100 --> 00:37:50.199
Classroom 410: which is significant amount of money.

185
00:37:50.360 --> 00:37:53.240
Classroom 410: It's actually 2.7 billion dollars in market. Cap.

186
00:37:53.360 --> 00:38:12.010
Classroom 410: What's really interesting, then, is then the following, so they announced it publicly, on Thursday market cap collapsed 2.7 7 billion. That's a huge hit to your equity. The following week they took a number of steps. Each one of their steps led to more market cap loss.

187
00:38:12.250 --> 00:38:24.199
Classroom 410: So that's 1 of the reasons why this case is used as a massive example. They lost another 2.2 billion. That's a total of 5 billion dollars in market cap. Because of their efforts to contain this incident.

188
00:38:26.040 --> 00:38:27.930
Classroom 410: So to discuss

189
00:38:28.429 --> 00:38:41.219
Classroom 410: I'm going to ask you break back up into your groups here and just take a few minutes to think about what factors equifax was wax, and they were at fault for. And then what factors were they? Just unlucky?

190
00:38:41.360 --> 00:38:52.520
Classroom 410: We won't take a lot of time. I think we all have this queued up. But let's do it. So break up. We'll take 3, 4 min and talk about lax factors and unlucky factors.

191
00:42:38.440 --> 00:42:47.200
Classroom 410: What's a lax factor.

192
00:42:48.520 --> 00:42:51.870
Classroom 410: I think a big last minute here is just

193
00:42:52.690 --> 00:42:56.009
Classroom 410: they have like 6 like minus, like the certificates.

194
00:42:56.120 --> 00:43:00.399
Classroom 410: like the Ssl. Certificates like encryption. They just did not

195
00:43:00.760 --> 00:43:16.750
Classroom 410: like renew it. So like, it was months without being renewed. So that left the big vulnerability. But, like the data is just once encrypted because, yeah, for data exfiltration, huge vulnerability, not renewing those certificates is pretty unacceptable. Let's keep going

196
00:43:16.830 --> 00:43:31.149
Classroom 410: lax or unlucky. Lax. Say, like manion had warned them that they're like unpacked systems. And they're like, misconfigured like security policies that could like indicate major problems. What? And like, they just didn't do anything.

197
00:43:31.170 --> 00:43:35.559
Classroom 410: Okay. So they had gotten prior knowledge that something bad could happen right?

198
00:43:35.890 --> 00:43:52.269
Classroom 410: Kind of just talked about the structure. Oh, sorry lax. We kind of talked about the structure and the culture of the company, which also leads into some of the other questions. But just how the Ciso wasn't really viewed as important, like they weren't at

199
00:43:52.450 --> 00:44:05.949
Classroom 410: some of the meetings like about cyber security. They weren't reporting the CEO or board. So we kind of just see that as a major problem, did anyone in the room have a problem with the reporting structure?

200
00:44:06.390 --> 00:44:09.980
Classroom 410: Did anybody see a problem? What was the problem?

201
00:44:12.047 --> 00:44:23.430
Classroom 410: Who had like a known background or experience security.

202
00:44:23.570 --> 00:44:27.929
Classroom 410: and we'll talk about the Cll a little bit more, because he's an interesting character for this

203
00:44:28.753 --> 00:44:48.590
Classroom 410: other lax factors or unlucky, unlucky usually people shy away from. For unlucky. We kind of talked about how equifax is continuously like a targeted company because of the large amount of Pii information that they carries. What is their business?

204
00:44:49.420 --> 00:44:56.989
Classroom 410: It's information right? And so you think you would protect your information? It's everything you possibly could, right?

205
00:44:57.150 --> 00:45:01.620
Classroom 410: They don't make widgets keep going. Oh, I have another lax wax, these

206
00:45:01.630 --> 00:45:09.430
Classroom 410: they don't. They don't apply any of the cyber hygiene practices like. I remember they talked about that they didn't have segmentation in their network, because

207
00:45:09.590 --> 00:45:23.710
Classroom 410: they thought it was like easier like for their business to like, be able to like, literally move, and have everyone have access about that stuff, and then again, like you never donate anything with Patchy. Didn't have Mfa. And the city as well. So

208
00:45:26.056 --> 00:45:35.763
Classroom 410: went with the last one we never done to update. So that's why.

209
00:45:40.440 --> 00:45:41.989
Classroom 410: yeah, to me.

210
00:45:42.460 --> 00:45:57.650
Classroom 410: it didn't feel like the the management had much awareness about cyber security. There was something in the case which mentioned that a former employee, who stated that any attempts to do something about the issue wasn't really taken well by the management, because they didn't really understand why it wasn't

211
00:45:58.820 --> 00:46:11.889
Classroom 410: all right. Elizabeth blacks pile it all right. One thing I remember was they had this like website that we're using

212
00:46:12.050 --> 00:46:16.200
Classroom 410: sort of like access their customer data. And then.

213
00:46:17.453 --> 00:46:23.499
Classroom 410: it was someone out there was like, not secure. And like, basically anyone could access it.

214
00:46:23.640 --> 00:46:31.439
Classroom 410: and as far as I know, they didn't do anything to fix that. But that also tells me that they don't really have good access controls, because I feel like it's weird that

215
00:46:31.490 --> 00:46:39.170
Classroom 410: employees can just access all this information on our website. So we're back to the 5 Pillars. Right? You know, Principal, at least. Courage, Donna.

216
00:46:39.410 --> 00:46:47.979
Classroom 410: I gave them a 1.5. What's the point? 5 for the point 5?

217
00:46:48.110 --> 00:46:58.298
Classroom 410: Well, the one is because I equated it. I wish I had done it in like my in my answer, but I didn't think it was appropriate. I in my mind. I kind of equate

218
00:47:00.596 --> 00:47:01.153
Classroom 410: equated.

219
00:47:01.850 --> 00:47:06.589
Classroom 410: I don't know. I for me it was kind of like the equivalent of

220
00:47:06.750 --> 00:47:09.959
Classroom 410: the FBI like ignoring a bomb threat.

221
00:47:10.450 --> 00:47:17.479
Classroom 410: Because they did get a warning about the Apache threats. And they just didn't do anything about it.

222
00:47:18.210 --> 00:47:29.160
Classroom 410: So, in my opinion, even though they had so many things prior to that that were to their credit for cyber security they put. They invested a lot of money and time into it

223
00:47:29.250 --> 00:47:36.770
Classroom 410: because of that one thing that was so simple and so detrimental. Everything kind of goes out at the window

224
00:47:36.870 --> 00:47:40.100
Classroom 410: for me, at least, and the point 5 is

225
00:47:40.710 --> 00:47:44.129
Classroom 410: I'll give them like a slight luck thing.

226
00:47:44.440 --> 00:47:47.889
Classroom 410: just as like a benefit of the doubt thing, because.

227
00:47:48.000 --> 00:47:55.390
Classroom 410: like in every, in every situation, everyone is always like, Oh, that it sucks that that's a thing, but it's never going to happen to me.

228
00:47:55.470 --> 00:47:59.730
Classroom 410: So that's why I gave him 1, 25. Okay, got it

229
00:47:59.930 --> 00:48:22.569
Classroom 410: with the extent of the breach. I'm on the lack side, but as far as the instance of the breach, I'd say they were unlucky just because Cert notified them on March 8, th and even if they had had their patching right, it still was a 40 h time window, and the breach 1st occurred on the 10, th so I still think they would have been breached, even if they had fixed all the glaring issues that were brought up in the case. But the extent of the breach probably would have been less.

230
00:48:22.620 --> 00:48:34.940
Classroom 410: Okay, that's very fair point. The bad guys were good in this, you know, these aren't clowns that stumbled across this. This was, and we'll see. You know the postmortem here, as we know who it was.

231
00:48:36.420 --> 00:48:41.439
Classroom 410: But just in general, so who would say they were more lax than unlucky.

232
00:48:42.010 --> 00:48:45.850
Classroom 410: Would anyone any brave soul say they were more unlucky?

233
00:48:47.480 --> 00:48:48.740
Classroom 410: Oof man.

234
00:48:48.800 --> 00:49:02.539
Classroom 410: good job here. Okay. So this is the next question that I have. And we're gonna go through a little warm calling in the room on it. You guys want a couple of minutes to talk about it with your classmates.

235
00:49:02.650 --> 00:49:10.359
Classroom 410: All right, take a couple of minutes. We'll come back, yes or no. Our boards of public companies responsible for data breaches.

236
00:50:23.897 --> 00:50:42.280
Classroom 410: It's also, like.

237
00:51:07.110 --> 00:51:33.530
Classroom 410: all right, we're back. We're back. We're back, John, yes or no. Our boards responsible for data breaches.

238
00:51:39.760 --> 00:51:40.510
Classroom 410: custom.

239
00:51:40.710 --> 00:51:42.649
Classroom 410: Kyle had a different approach to it.

240
00:51:42.850 --> 00:51:52.469
Classroom 410: But I basically said that boards are responsible to continue to flow, and the the other officer.

241
00:51:52.500 --> 00:51:57.520
Classroom 410: I guess they they have like, let's say in, can you just bought?

242
00:51:58.010 --> 00:52:03.970
Classroom 410: They certainly have a say at the top level. Who, Max, does anybody anybody agree?

243
00:52:04.040 --> 00:52:05.370
Classroom 410: Wants to speak on?

244
00:52:06.070 --> 00:52:33.460
Classroom 410: Oh, so I said, yes, they're part of it, because I kind of talked about how the main responsibility for this entire issue was the current organization structure, and, like their lack of proper cybersecurity, leadership. And so I ultimately like, reached the conclusion that I thought the Board of directors and others were responsible because they had the power to implement more cybersecurity leaders within the firm

245
00:52:33.640 --> 00:52:59.070
Classroom 410: created more resilient structure for them. Anybody disagree with Clip? Anybody, say hard. No, boards are not responsible. Hard? No, that's good. It wasn't like a hard no, but more so like kind of building on that point, like one of the things was like the they like one made like the chief legal officer. John Kelly. Yeah. Like the Chief Security Officer for some time, and then when I think they switched that to like

246
00:52:59.472 --> 00:53:02.697
Classroom 410: I forgot the name. I think it was like Susan

247
00:53:03.060 --> 00:53:11.839
Classroom 410: Maldine, or something, she reported to John. Yeah, like she was. She didn't have say in like the regular security meetings. So I don't know if that's like

248
00:53:11.880 --> 00:53:22.178
Classroom 410: the Board's responsibility per se to like, you know, manage who gets to say during these like senior leadership meetings, but like from my perspective, I thought it was like more of

249
00:53:22.580 --> 00:53:43.839
Classroom 410: like the CEO on like who is? Who are the people that should be in this room to like manage that. It just again goes back to like the organizational structure we're talking about. Yeah. So we're, I'm in a room full of leaders that will be leading companies. You're going to be on boards at some point. Do you think this is your fault when you're a board of director like? That's the question.

250
00:53:44.412 --> 00:53:52.400
Classroom 410: I think that in this case, specifically, since like data holds your main asset, like, if you're in the business of like managing data.

251
00:53:52.863 --> 00:53:58.919
Classroom 410: Cyber security needs to be like very closely like woven into your strategy. And like.

252
00:53:58.930 --> 00:54:02.500
Classroom 410: since the board is basically in charge of like reviewing competitive strategy

253
00:54:03.110 --> 00:54:06.430
Classroom 410: and their fault that it wasn't a huge thing in the company.

254
00:54:06.810 --> 00:54:09.289
Classroom 410: It is their phone and your location.

255
00:54:09.520 --> 00:54:10.390
Classroom 410: For sure.

256
00:54:11.340 --> 00:54:21.200
Classroom 410: I would say, it depends on my definition of responsibility. Are we talking about the legal responsibility? Big question? So should they be fired.

257
00:54:21.470 --> 00:54:27.620
Classroom 410: Should they be prosecuted? 2 separate calls? No, just because I think we discussed this earlier, like, if

258
00:54:27.820 --> 00:54:32.760
Classroom 410: we know that cyber attacks are inevitable, because just how we respond

259
00:54:32.860 --> 00:54:38.880
Classroom 410: that no one would want to be consistent. How would anyone be encouraged to be able to pull

260
00:54:38.970 --> 00:54:42.039
Classroom 410: if they could be held equally responsible for something like this?

261
00:54:42.100 --> 00:54:47.140
Classroom 410: So I think there shouldn't be any responsibility unless, like, it's just

262
00:54:47.470 --> 00:54:52.090
Classroom 410: like a clear case of just pure negligence or something they did

263
00:54:52.160 --> 00:54:54.510
Classroom 410: with like knowledge that I'm able.

264
00:54:57.650 --> 00:55:06.410
Classroom 410: I was gonna say, like, when you're choosing the part of your board, I think also like signing up for, like the responsibility of like oversight, and like making sure that, like management of that company is like

265
00:55:06.430 --> 00:55:09.569
Classroom 410: doing things effectively. And I feel like there wasn't.

266
00:55:09.860 --> 00:55:19.029
Classroom 410: you know, like there was so many warnings, and like the audits that highlighted that there was, and, like that, was on management to like address those issues. But

267
00:55:19.040 --> 00:55:24.280
Classroom 410: the Board has, like the role of oversight, and like they needed to make sure that management was actually addressed

268
00:55:24.970 --> 00:55:26.120
Classroom 410: seamlessly.

269
00:55:26.410 --> 00:55:29.560
Classroom 410: Okay, so you're putting blame on the board?

270
00:55:29.590 --> 00:55:37.279
Classroom 410: Not entirely. I would. You're putting some blame on the war. Okay, we're not prosecuting them, but we should hold them responsible. Okay.

271
00:55:37.370 --> 00:55:50.970
Classroom 410: go across, Kyle. There's a strong argument to be made in this specific case that the Board might be responsible because they have the technology committee. And as Aronto was saying earlier, like the business is data that being said, the Board wasn't notified of this for like over a month.

272
00:55:51.410 --> 00:56:03.579
Classroom 410: and that's on management. So you can't like. If the management's not telling the board the Board's not going to go in there. These people have other jobs. They meet quarterly, so I don't even think in this case the Board should be held responsible because they're not being told.

273
00:56:04.030 --> 00:56:10.830
Classroom 410: Interesting. Yeah. So great point. So S. And P. Board of directors, are they full time employees of these firms?

274
00:56:11.130 --> 00:56:12.630
Classroom 410: No, they are not.

275
00:56:12.640 --> 00:56:13.849
Classroom 410: Do we have more

276
00:56:13.990 --> 00:56:27.289
Classroom 410: more points to make here. Yeah, I agree with him. Like boards meet like 4 to 6 times a year. They're not operational. And something like this, like the CEO, needs to be hands on and actually figure it out, because otherwise they'll never figure out the information. And, like like you said, they have other jobs to do.

277
00:56:27.390 --> 00:56:40.979
Classroom 410: spoken like a true future board member. I was thinking like, even if the board like told them like, Hey, you should focus on this like a lot of the other like 3rd party security that did like security audits like they were like telling, like

278
00:56:40.980 --> 00:56:59.040
Classroom 410: the Equifax employees and the management team like, Hey, you need to fix this. But the management team did like nothing really about it. So even I feel like, even if the board told them like, Hey, you should do something about it like it's really up to like the executives, the management team and the employees to actually take that action because the Board can't take action. That's a very valid

279
00:56:59.310 --> 00:57:01.150
Classroom 410: oh, you bet!

280
00:57:01.280 --> 00:57:10.339
Classroom 410: Then, again, like they were the only one of the 3 who had a separate technology committee mandated specifically to monitor security. So what was this

281
00:57:10.540 --> 00:57:12.930
Classroom 410: committee of the Board actually doing?

282
00:57:12.980 --> 00:57:19.148
Classroom 410: And they had many like 2015 audits. And there's so many people from Lloyd.

283
00:57:20.230 --> 00:57:24.399
Classroom 410: Other companies. I forget all the names that we're telling them. You have these blank issues

284
00:57:24.840 --> 00:57:49.890
Classroom 410: for years that they just didn't address correct. I also think, even though it's like the employees role to be doing this stuff if that comes from like a higher up issue, that they're not doing it like, there's clearly a cultural issue there that they're not doing. And I think that's on the board and the CEO to be forcing those types of things.

285
00:57:50.860 --> 00:58:16.089
Classroom 410: So I mean, I think boards can't create culture like that's not like part of their job. More like, is it possible for them to do that. I think you could like kind of create like this effective effect, like, okay, maybe they could have replaced the CEO. But essentially like you have like blatantly, like a security team that ignored the patch. They had a meeting about it. Managers didn't even show up. They had emails going about it, and no one did anything which is like they were the most direct impact they legitimately just ignored like

286
00:58:16.140 --> 00:58:28.870
Classroom 410: they legitimately just ignored like the breach. And so it's like 100%. Their fault. Yeah, you could blame the culture. Yeah, like, there are external factors that like, Oh, if this happened, then this would have happened. This would happen, yes, but like more directly they were negligent, and they didn't do their jobs

287
00:58:28.900 --> 00:58:31.625
Classroom 410: alright. Strong words, Elijah. Final point

288
00:58:32.240 --> 00:58:36.420
Classroom 410: but going off like probably a combination of this, but I just think that.

289
00:58:36.580 --> 00:58:53.419
Classroom 410: like they are, they are responsible as well. But I don't give them like the full responsibility because of like communication issues with scene management and stuff. But they also create, like the policies that's related to like like it. And like the cyber security like disaster, recovery. So at the same time.

290
00:58:53.420 --> 00:59:13.830
Classroom 410: yeah, they may not have, like the full control and tell people what to do. But at the same time. They are the ones that gives the strategy. They're the ones with the technology community to hand out and put down policies in place just for something like this to happen so like people like the CEO, or at least will follow that.

291
00:59:14.938 --> 00:59:16.850
Classroom 410: So in the room.

292
00:59:18.140 --> 00:59:21.189
Classroom 410: Any responsibility? Yes. Who says yes.

293
00:59:21.290 --> 00:59:29.530
Classroom 410: board has some responsibility for a data incident who says, No, alright.

294
00:59:29.740 --> 00:59:31.350
Classroom 410: So does this change. Your

295
00:59:31.790 --> 00:59:35.959
Classroom 410: average compensation. S. And p. 500 is $321,000

296
00:59:37.410 --> 00:59:40.979
Classroom 410: that change anybody's mind whether or not they're responsible or

297
00:59:41.200 --> 00:59:45.555
Classroom 410: seem about right for a part time. Gig as a board of directors.

298
00:59:46.355 --> 00:59:53.100
Classroom 410: Alright, let's keep going because we're running out of time. So equifax response, we'll do it real time.

299
00:59:53.260 --> 00:59:56.589
Classroom 410: Did somebody tell me about their response and what you thought of it.

300
00:59:57.560 --> 01:00:17.870
Classroom 410: I didn't think that they had a great response. It kind of seemed like the like when they gave the like benefits to people who had been affected. It kind of seemed like they were just throwing out random things. And then there actually ended up being a lot of backlash, and the fact that like they couldn't sue equifax, and like other things like that.

301
01:00:17.880 --> 01:00:28.600
Classroom 410: So I thought that maybe they should have had a kind of better thought out plan on how to actually give customers like what they needed to better protect their data and kind of like

302
01:00:28.610 --> 01:00:32.839
Classroom 410: actually make them happy. Knowing that they do that.

303
01:00:34.130 --> 01:00:42.809
Classroom 410: I thought the response to the like incident itself was pretty good with the glaring stake of not telling the board for like 3 to 4 weeks.

304
01:00:43.149 --> 01:00:56.379
Classroom 410: So like, I feel like the board you kind of need to read in on all of it earlier on like I understand. And I agree that, like waiting till the public was good. Once they had all the information to not kind of create like chaos of like partial information out there.

305
01:00:56.666 --> 01:01:14.409
Classroom 410: I do think they got a lot of backlash from the fact that there was like the insider trading incidences like, that's not necessarily the fault of the overall company that's just like those 3 managers who are basically out for their own gain. So like, I know, they got back off for that. But like the overall company shouldn't have.

306
01:01:14.900 --> 01:01:16.940
Classroom 410: Alright. I'll stay. I'll stay here, sir.

307
01:01:17.210 --> 01:01:26.790
Classroom 410: I kind of mixed opinions on their communication strategy, because I thought that they waited almost like too long to tell the public like. They waited like over a month.

308
01:01:26.930 --> 01:01:46.079
Classroom 410: but they like waited also long enough, and they didn't have all the information when they went public, so it just made them look even worse when, a few weeks later, they were like, oh, also, like 700,000 of you in the Uk. Like your stuff lost, too. They waited so long, and then they didn't even have a good enough read on the situation, so I just thought it looked.

309
01:01:46.470 --> 01:01:47.419
Classroom 410: No, I'm not

310
01:01:47.850 --> 01:01:54.180
Classroom 410: alright. I'm gonna you know, we we can pick this apart for a while. But I'm gonna I'm gonna ask this question.

311
01:01:54.510 --> 01:01:55.639
Classroom 410: lag time.

312
01:01:56.160 --> 01:02:00.600
Classroom 410: So they knew about the breach. But they didn't tell the board. Why.

313
01:02:00.670 --> 01:02:01.949
Classroom 410: Why would that happen?

314
01:02:02.230 --> 01:02:04.189
Classroom 410: Have a hypothesis for us?

315
01:02:05.840 --> 01:02:14.260
Classroom 410: Were they probably trying to assign like, find out who's responsible for it was just looking at the next steps, like more of who to blame, or who should take the fall for it

316
01:02:14.670 --> 01:02:29.889
Classroom 410: find the fall, Guy? I like that, Nicole, I would say. Maybe like they have the fear of being fired because the board is responsible for playing like delivering bad news is super fun, right? And so I mean, I believe that that is human nature where

317
01:02:30.610 --> 01:02:38.489
Classroom 410: I agree with you completely. Let's keep going. I think one of the issues that they were scared of is going in front of the board without the full information.

318
01:02:38.650 --> 01:02:39.890
Classroom 410: It's a while.

319
01:02:40.120 --> 01:02:49.550
Classroom 410: Bingo, because trickling information to powerful people is even worse than just delivering bad news in a in a single blow.

320
01:02:50.200 --> 01:03:05.419
Classroom 410: Any other thoughts? Why, Sanji also, even with the little information going to the board and not having some sort of remediation, plan or solution is even worse. So probably take some time to come up with a plan before they go to them. Sure. Hey? We got a problem.

321
01:03:05.430 --> 01:03:08.750
Classroom 410: Oh, you better have the next answer be, this is how we're gonna fix it.

322
01:03:09.260 --> 01:03:20.949
Classroom 410: So the the delay here is unacceptable, like, keep in mind that there's a reason why there's a case about this, because, waiting that long to inform the powers that be is a bad plan.

323
01:03:20.990 --> 01:03:23.619
Classroom 410: but there's lots of reasons why it could have happened.

324
01:03:26.170 --> 01:03:32.440
Classroom 410: So we already kind of answered this, so I'll skip that one and come to the last question.

325
01:03:32.750 --> 01:03:41.260
Classroom 410: what questions would you ask? Will you ask when you're on boards? You know? What are you? Gonna ask your CEO, your CIO, your Ciso.

326
01:03:41.410 --> 01:03:44.209
Classroom 410: What what kinds of questions can you ask

327
01:03:44.430 --> 01:03:48.529
Classroom 410: in your role as a board of directors? Who's got a thought on that?

328
01:03:48.550 --> 01:04:00.059
Classroom 410: What could have I? Asked Neil. I mean, one is like connecting the vulnerabilities to like the stakeholders. In the company. So understanding like who might be responsible for a certain issue. And then being able to

329
01:04:00.160 --> 01:04:05.369
Classroom 410: assess, like, how big of an impact that was, do we need to maybe have a change in like that position.

330
01:04:06.330 --> 01:04:27.189
Classroom 410: Yeah, okay, let's keep going. I think one of the things that we found is like, it's important to build culture around cyber security. And it's like, if we can ask questions like for the Ci like to the CEO Cso. And CIO in terms of like what the relationships look like, what they're trying to build. I think those would be important questions, but even more so like trying, like financial incentives, to like how much time like they devote to like

331
01:04:27.340 --> 01:04:31.469
Classroom 410: creating and like up like improving like operational efficiency like around

332
01:04:31.500 --> 01:04:34.040
Classroom 410: their cyber security culture. I like it.

333
01:04:34.160 --> 01:04:55.600
Classroom 410: You gotta insent the right things. We've seen that before. We saw that with Maersk and sending the wrong things, can have disasters. Also, I think I would want to ask kind of like the question that we talked about like lax versus unlucky, like. What were we doing wrong that made this our fault, and like what was surely just kind of like our bad luck. And like how

334
01:04:55.730 --> 01:04:59.200
Classroom 410: this wasn't like, maybe our fault completely.

335
01:05:00.150 --> 01:05:12.238
Classroom 410: Yeah, I think it's important. Also, like, get a timeline like when they 1st discovered the breach as well as knowing about, like the prior information beforehand, to know if they had like kind of like tips or so, not tips, but like

336
01:05:12.730 --> 01:05:20.269
Classroom 410: like trends of like some sort of thing, and they failed it. Yeah, okay.

337
01:05:20.590 --> 01:05:34.249
Classroom 410: any closing thoughts, you know, this is a issue. This is a management case. Right? I was gonna say, like in general, before breaches even occur like asking if they have, like a clear incident like response. Strategy like it tells you like whether management is

338
01:05:34.510 --> 01:05:43.770
Classroom 410: proactive or if they're like more, the reactive type. And like, if they are reactive type and changing that ahead of time by like seeing if they have a clearance and response targeting.

339
01:05:44.510 --> 01:05:45.380
Classroom 410: Yeah.

340
01:05:45.520 --> 01:05:58.550
Classroom 410: I'm a firm believer that boards should talk to the Ciso. They should know who that person is. They should be able to ask these questions, and they should have access to audit reports that have to be conducted for a lot of different legal reasons.

341
01:05:58.760 --> 01:06:04.260
Classroom 410: So this case, which thank you for a good discussion here.

342
01:06:04.900 --> 01:06:11.639
Classroom 410: is really crystallized by this happened, and all of these things happened, and then Equifax responded.

343
01:06:11.880 --> 01:06:20.169
Classroom 410: and their crisis response is really where we saw that second 2.2 billion dollars in market cap loss.

344
01:06:20.430 --> 01:06:30.190
Classroom 410: So if we're responding to an incident, we have to think about transparency to the public. We can't tell half truths. We have to have professional communicators that know how to disseminate these messages.

345
01:06:30.692 --> 01:06:40.360
Classroom 410: We have to not have people get a busy signal if they call, because I just saw something on the news. And I'm concerned. I need to be able to talk to people.

346
01:06:41.130 --> 01:06:49.199
Classroom 410: and empathy is really important, because if you act uncaring, it makes the public react in an even worse way.

347
01:06:49.850 --> 01:06:57.940
Classroom 410: Let's look at what we did so. They knew about the breach on July 29, th but they didn't inform the public for 6 weeks.

348
01:06:58.300 --> 01:07:00.539
Classroom 410: That's a long time to sit on that news.

349
01:07:01.020 --> 01:07:08.600
Classroom 410: They had 3 executives sell personal stock in Equifax before that multi 1 billion dollar collapse. That's not great.

350
01:07:08.870 --> 01:07:21.670
Classroom 410: They set up that equifax breach settlement website, the website didn't work. They had a misconfigured ssl, cert. So when you tried to go visit it, you got a security warning like you do when you're connecting to one of my access points.

351
01:07:21.680 --> 01:07:23.700
Classroom 410: That's not great, either.

352
01:07:24.569 --> 01:07:40.649
Classroom 410: So this. So keeping going. So when you went, you know, this affected me, this affected Professor Wright. This affected a lot of your parents. You went to a website. You had to enter the last 6 digits of your social security number into the website

353
01:07:40.760 --> 01:07:45.219
Classroom 410: which made people really excited. Hey, you just lost all my information.

354
01:07:46.362 --> 01:07:53.610
Classroom 410: What they offered proactively, as if they were being very good about. It was a year of free credit monitoring.

355
01:07:53.690 --> 01:07:55.980
Classroom 410: Yeah, they're legally required to do that.

356
01:07:56.907 --> 01:08:04.559
Classroom 410: It's a legal requirement. And so they offered it as if it was some sort of gift for this thing that happened.

357
01:08:05.460 --> 01:08:10.160
Classroom 410: In addition, the only credit monitoring they would pay for was from equifax.

358
01:08:10.220 --> 01:08:17.769
Classroom 410: That was the service that they offered in response to losing all of your data again, not not great.

359
01:08:18.310 --> 01:08:25.869
Classroom 410: And then they tried to have a clause on the agreement where you signed up for your free credit, monitoring that said you wouldn't sue them.

360
01:08:25.899 --> 01:08:30.170
Classroom 410: It's part of this which is staggeringly bad. Pr.

361
01:08:31.189 --> 01:08:38.579
Classroom 410: And then, ultimately, as we'll see as we look at the aftermath. They blamed this on one guy.

362
01:08:38.689 --> 01:08:47.620
Classroom 410: They had a CEO of a company go before Congress and blame Bob in it. How did this happen? Well, it's Bob's fault in it.

363
01:08:49.660 --> 01:09:04.119
Classroom 410: So this is the actual screenshot of of what the site looked like half the time it didn't work. So when you fill them random information, you could get a response that said, Oh, yeah, your data was lost or your data is fine.

364
01:09:04.340 --> 01:09:06.509
Classroom 410: It was fairly ridiculous.

365
01:09:06.630 --> 01:09:18.730
Classroom 410: As I mentioned, the CEO went in front of Congress and said the reason for this breach was not structural. It wasn't procedural. It wasn't reporting lines. It was Bob in it.

366
01:09:19.069 --> 01:09:27.060
Classroom 410: and the general public does not like that when when millionaires and billionaires blame Bob and it for an issue like this.

367
01:09:28.470 --> 01:09:39.160
Classroom 410: who got fired well, Susan got fired. She was the the CIO Webb.

368
01:09:39.310 --> 01:09:43.590
Classroom 410: the CEO Richard Smith. He got fired as well.

369
01:09:43.990 --> 01:09:59.219
Classroom 410: you know, who did not get fired. Is that chief legal officer, John Kelly. John Kelly, is a graduate of the University of Virginia Law School. John Kelly does not want to talk to us about this case just out of curiosity.

370
01:09:59.790 --> 01:10:07.630
Classroom 410: So when Richard Smith got fired, he received a golden parachute in the neighborhood of 90 million dollars.

371
01:10:08.160 --> 01:10:12.580
Classroom 410: So about 63 cents for every person that was affected

372
01:10:12.830 --> 01:10:19.479
Classroom 410: on the way out the door. So it's good to be a CEO, because you you still get the money on the way.

373
01:10:20.770 --> 01:10:26.570
Classroom 410: So what did it cost? We lost almost 148 million Americans information.

374
01:10:26.580 --> 01:10:41.409
Classroom 410: More importantly, we lost 15.2, and then 19,000 Canadian citizens. They're so nice up there, and we and we lost their information as well in the postmortem, retrospective of what happened.

375
01:10:41.430 --> 01:10:46.939
Classroom 410: The bad guys scanned the databases over 9,000 times without detection.

376
01:10:47.530 --> 01:10:50.729
Classroom 410: This was a bad bad thing to have

377
01:10:52.060 --> 01:11:02.710
Classroom 410: so direct financial issues. Equifax ended up paying. Actually, that number is higher. So they ended up paying almost 500 million dollars to compensate people.

378
01:11:03.735 --> 01:11:16.669
Classroom 410: The civil penalties go in, you know, at the time not every State or Territory had data, privacy, laws. And so some States had to go class action because they couldn't actually prosecute on their with their own State attorney. Generals.

379
01:11:17.790 --> 01:11:24.540
Classroom 410: Direct costs are about 700 million dollars, 27% year over year profit drop.

380
01:11:24.820 --> 01:11:26.839
Classroom 410: That's not great.

381
01:11:27.534 --> 01:11:31.250
Classroom 410: So what good happened? Because of this? Well.

382
01:11:31.460 --> 01:11:35.920
Classroom 410: there was a settlement. And so people affected actually got paid.

383
01:11:36.050 --> 01:11:39.530
Classroom 410: I'm 1 of them. So I actually saw financial gain.

384
01:11:42.770 --> 01:11:48.529
Classroom 410: Prior to this 2017. You could only freeze your credit for 30 days without evidence of fraud.

385
01:11:48.690 --> 01:11:58.389
Classroom 410: And so, if you wanted to, you know, I'm not going to take out any credit. Can I freeze my credit? The answer was, no, you have to show evidence that you. Your data has been lost.

386
01:11:59.535 --> 01:12:11.130
Classroom 410: Lifelock, which we'll talk about in a second was a business model that exploited that. And they basically just put these temporary credit freezes on your credit every 30 days. It was. It was a real interesting company.

387
01:12:11.633 --> 01:12:18.519
Classroom 410: But because of equifax. Now, all 50 States have data, privacy laws on the books, and they have data, breach notification laws

388
01:12:19.125 --> 01:12:24.500
Classroom 410: and that sweet Cheddar, and I'll show you like I became financially rich because of this.

389
01:12:25.240 --> 01:12:36.589
Classroom 410: So here's lifelock. This guy used to post his social security number everywhere, you know, as part of his business model. This is the CEO of lifelock. Do you ever? His ad used to be everywhere?

390
01:12:37.058 --> 01:12:47.559
Classroom 410: Well, his identity was stolen 13 times, or he stopped doing this, and it will continue to be stolen because his social security number is on ads and billboards and have been forever.

391
01:12:48.520 --> 01:13:11.200
Classroom 410: But back to me, my equifax settlement. So yeah, that's me. So I got a court appointed settlement. I followed it to the full extent of the law, because I wanted to make equifax pay and equifax did pay me $5. And that's what a class action lawsuit looks like when all the lawyers are done.

392
01:13:12.300 --> 01:13:26.129
Classroom 410: So what can you do? Well, what you can do now is freeze your credit. Real real great U.S.A. Dot Gov has a great article. It's how you freeze your credit people. Your credit cannot be issued in your name without your authorization.

393
01:13:26.490 --> 01:13:39.219
Classroom 410: Technologically, it's great. Now they can text you. They can send you links so you can. Temporary UN, you know, if you're applying for a credit card, you can basically unfreeze your credit to get new new credit issued to you.

394
01:13:39.310 --> 01:13:40.929
Classroom 410: But you should do that.

395
01:13:41.390 --> 01:13:47.210
Classroom 410: You should do that immediately. You should tell your parents to do that when you have children

396
01:13:47.250 --> 01:14:00.860
Classroom 410: you should freeze their credit as soon as they're born. They have a social security number, so credit cannot be issued in their name without anyone knowing about it. So this is a direct impact of equifax. And they're bundling of this so badly

397
01:14:03.032 --> 01:14:06.959
Classroom 410: so 2 min left. Let's go to the whodunit. So

398
01:14:07.100 --> 01:14:09.030
Classroom 410: where did this data show up?

399
01:14:10.160 --> 01:14:12.080
Classroom 410: Was it for sale the next week?

400
01:14:13.330 --> 01:14:21.689
Classroom 410: No, never seen it again? Who does that generally mean stolen nation state? And, in fact.

401
01:14:22.061 --> 01:14:28.929
Classroom 410: you know, the United States has actually indicted 4 members of the Pla Chinese Liberation Army for actually

402
01:14:29.160 --> 01:14:32.817
Classroom 410: ex filling this data and taking. So

403
01:14:33.800 --> 01:14:51.230
Classroom 410: that's the charges. So they actually issue charges against 4 members of the Chinese military. These are the charges themselves, a number of different charges. They linked it back to this hacking group within the Chinese military.

404
01:14:51.340 --> 01:15:02.119
Classroom 410: Don't hold your breath on China turning these folks over, so I don't think justice is ever going to be served. There's some question of what the Chinese Government might do with this data at some point.

405
01:15:03.370 --> 01:15:29.469
Classroom 410: So 1 min left. What did we learn? This has never happened again. Right? No, this keeps happening. You know, some of these aren't technical hacks. That's the funniest part. So there's a great example of the experian data breach was just a fraudster. Got experian to actually send him hundreds of thousands of credit reports just by impersonating a paying customer. That's pretty good. Don't have to hack in.

406
01:15:30.870 --> 01:15:34.380
Classroom 410: All right, closing 1, 45, 4. Biggest mistakes

407
01:15:34.510 --> 01:15:46.389
Classroom 410: don't have a plan. You're screwed, and it's a response. You must have a plan. If you don't test that plan, you know, if you don't do table tops, if you don't review that plan, you're in a lot of trouble.

408
01:15:46.864 --> 01:15:58.220
Classroom 410: If you know you're gonna need help. Then you know, Virginia Evans talked about how she had a card from Mandian. That relationship should already exist within your company. You should know who to call

409
01:15:58.280 --> 01:16:00.230
Classroom 410: if something bad happens

410
01:16:00.790 --> 01:16:11.610
Classroom 410: and then thinking about the 3rd party, because you are doing business with lots of people you don't even think about because you are outsourcing things to the cloud. And 3rd party providers and all of those can hurt you.

411
01:16:13.040 --> 01:16:15.759
Classroom 410: That's what I got good chat today.

412
01:16:17.490 --> 01:16:31.779
Classroom 410: Next time we're gonna do the grad cases, and then the whole class pivots for privacy and cyber crime after the last 4 class. So appreciate it. Y'all.

413
01:17:25.090 --> 01:17:31.310
Classroom 410: yeah.

414
01:17:31.310 --> 01:17:59.770
Classroom 410: And then next week from today's class.

415
01:18:01.470 --> 01:18:05.279
Classroom 410: No, I didn't mention yeah.

