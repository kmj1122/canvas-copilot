WEBVTT

1
00:00:00.150 --> 00:00:16.770
Classroom 410: Waiting for our guest speaker. So last class of the semester whose last class of the entire semester is this, today

2
00:00:16.950 --> 00:00:20.589
Classroom 410: we have anybody got one person.

3
00:00:21.880 --> 00:00:25.030
Classroom 410: The rest of you have classes tomorrow. I'm assuming.

4
00:00:26.250 --> 00:00:29.489
Classroom 410: No, I'm confused about your answers.

5
00:00:30.150 --> 00:00:33.589
Classroom 410: Yes, as well. So a couple of things

6
00:00:34.050 --> 00:01:00.730
Classroom 410: with with regards to the final exam that is released actually, 2 min ago. You can take it same same thing. You can take it anytime between now and literally we had the last slide in of all final exams that there was out there. So if we did the traditional sit down exam, you would have been having it on the 17.th Yeah.

7
00:01:01.153 --> 00:01:06.610
Classroom 410: so we are leaving it open. Then, if you want to take it, then that is perfectly fine.

8
00:01:06.740 --> 00:01:17.830
Classroom 410: but just out of curiosity. And of course I'm not going to hold this to you, but we're just trying to do a quick, strong poll who thinks they're going to take the final exam next week.

9
00:01:19.100 --> 00:01:25.029
Classroom 410: So the majority of you who thinks they're going to take the final exam the week after that they can't

10
00:01:25.440 --> 00:01:30.789
Classroom 410: few of you. Okay, that's perfectly fine. Who's gonna take it on the 17? th

11
00:01:31.220 --> 00:01:36.340
Classroom 410: Is there anyone? Okay? Maybe meals in for the 17?

12
00:01:36.784 --> 00:01:45.169
Classroom 410: So that's good. Any questions about the final. Do we have them here? Okay, any questions about the final before I turn over?

13
00:01:46.440 --> 00:01:50.680
Classroom 410: Yeah. Any previews for us, any previews, hot tips.

14
00:01:51.131 --> 00:01:55.208
Classroom 410: No, so I haven't been drinking, so I don't know if this will help you.

15
00:01:58.167 --> 00:02:04.379
Classroom 410: You know what I'll say about the final. You've seen this before, but now we're looking for more depth.

16
00:02:04.670 --> 00:02:13.899
Classroom 410: That would be my hot tip for you folks. You know how to approach it. It'll ask you to bring a whole bunch of things together. Now it's time to figure out

17
00:02:14.910 --> 00:02:42.740
Classroom 410: unlike other classes. I really really like grading. Unlike all other classes, I really like grading this final exam, because it's like they get it like, everything's coming together. They could be in a meeting with other security people. And they could answer that question, and that's a good answer. And I think we've accomplished what we've accomplished in this class. If you can do that for 4 or 5 different types of things. Yep.

18
00:02:43.350 --> 00:03:11.549
Classroom 410: yeah, it's kind of like this class is. It's hard to pretend like something like it's all cumulative in a way. Right? Yep. Did you end up posting like good responses to exam questions? Yeah. So I have example. If you go and do gradescope, I have example answers for all of them under that rubric. It'll show you, and the answers are lengthy. So there's a lot. I spent a lot of time providing responses, so it'll hurt my feelings if you don't read them

19
00:03:12.957 --> 00:03:15.350
Classroom 410: 2 h. Yep.

20
00:03:15.870 --> 00:03:25.599
Classroom 410: the exam is designed to be 90 min, and we give you 2 h of flight in case computer goes down. You don't practice very rarely. Will you run out of time?

21
00:03:25.740 --> 00:03:35.519
Classroom 410: You'll run out of time because you're stuck, which is, that's a different issue more of an emphasis on like one particular unit than the others like.

22
00:03:36.010 --> 00:03:39.950
Classroom 410: And you're asking me to remember things

23
00:03:40.010 --> 00:04:02.060
Classroom 410: like, I don't know, like, like we talked a lot about like like more emphasis on like beginning of the like, the beginning modules. No, they're kind of equally balanced as my design. Between them. There's some amazing stuff from Professor Lewis, some amazing stuff for me. And then, when we did it jointly, there's some stuff there.

24
00:04:02.840 --> 00:04:04.190
Classroom 410: My stuff's not patient.

25
00:04:05.316 --> 00:04:07.979
Classroom 410: Alright, I think we have you with us.

26
00:04:08.910 --> 00:04:10.410
Em: Oh! Hi!

27
00:04:10.850 --> 00:04:12.669
Classroom 410: Whoa! You're here!

28
00:04:12.670 --> 00:04:13.700
Em: I am here.

29
00:04:13.960 --> 00:04:16.679
Em: Oh, I'm so blurry. Okay, there we are.

30
00:04:16.680 --> 00:04:18.269
Classroom 410: It's good to see you again.

31
00:04:18.510 --> 00:04:19.399
Em: Yeah.

32
00:04:19.680 --> 00:04:43.369
Classroom 410: So Em joins us from Cisa as we talked about last class. So she's here to talk about all things that Cisa does under dhs. And the other thing about what's great about them is, Em will talk to you about what the career actually looks like, what the job's actually like. So, Em, without further ado, I'll turn it over to you to talk about yourself.

33
00:04:43.620 --> 00:04:43.940
Em: Yeah.

34
00:04:44.610 --> 00:04:56.949
Em: thanks, Ryan. I didn't know Brian was gonna be here. So hey, Brian? So my name is MI work at Cisa. We were previously

35
00:04:58.070 --> 00:05:07.360
Em: a component of the Department of Homeland Security, and I started working here as an intern. In 2017.

36
00:05:07.370 --> 00:05:25.519
Em: They liked me enough and offered me a full-time job. So that's like that's like the dream, right? Like you get an internship. You get. You get the full-time offer, and you're you're like doing cyber security and so I work within

37
00:05:26.230 --> 00:05:30.018
Em: threat hunting at Cisa, which is

38
00:05:31.040 --> 00:05:39.769
Em: we get called the big sexy, and it is pretty much there's it's not

39
00:05:39.900 --> 00:05:48.050
Em: penetration testing. That's a vulnerability management which is like our sister organization. So we

40
00:05:48.490 --> 00:05:51.920
Em: we have. We get like a tip.

41
00:05:52.790 --> 00:06:01.090
Em: probably from our own sensors or our intelligence partners say, there's there's been an intrusion.

42
00:06:01.620 --> 00:06:10.030
Em: and we get called in, as we're like the cyber swat team or ghostbusters, whatever you want to call it

43
00:06:10.671 --> 00:06:21.699
Em: and we do not eradicate the threat. But we we stop the bleed. We're like, we're basically like, I would say, Emts.

44
00:06:22.450 --> 00:06:30.179
Em: So we go in, we take a look at everything. We ask for copies of logs. We

45
00:06:30.190 --> 00:06:38.410
Em: make sure that we can contain the issue, and then we generate a report

46
00:06:38.580 --> 00:06:52.620
Em: and document our findings and our recommendations. We don't. We are also not law enforcement. So if we come across any unscrupulous activity, we're we're not gonna like call the cops. And we actually.

47
00:06:52.740 --> 00:06:53.985
Classroom 410: Purposely

48
00:06:55.580 --> 00:06:58.669
Em: Break things that would allow

49
00:06:58.770 --> 00:07:10.290
Em: our findings to be presented in a court of like in a court. We don't act as professional witnesses. We pretty much do it.

50
00:07:11.695 --> 00:07:20.269
Em: Because I would say, we really love the mission. There's there's still like do-gooders.

51
00:07:20.805 --> 00:07:22.320
Em: In the government.

52
00:07:22.640 --> 00:07:31.439
Em: And yeah, I mean, I'll start with that. I I was your your alum. Chris Krebs

53
00:07:31.820 --> 00:07:43.526
Em: was famously fired by Tweet, and he was the our former director. So I used to run in to him on the bike path and like,

54
00:07:45.020 --> 00:07:56.579
Em: so so yeah, I was working under him when he was ousted for basically posting a blog on Cis, denouncing.

55
00:07:56.890 --> 00:08:08.020
Em: like disinformation about elections and kudos to Ryan for giving me this slot in December, because.

56
00:08:08.460 --> 00:08:14.589
Em: as you know, we had an election this year, and that was it was.

57
00:08:14.630 --> 00:08:22.720
Em: It was hot and heavy over at Cisa, so I'm glad to be here, glad to have eaten like 2 pumpkin pies.

58
00:08:23.170 --> 00:08:28.350
Em: and to like have have some time since the 6.th

59
00:08:29.300 --> 00:08:31.129
Em: But I'm ready to take your questions.

60
00:08:32.240 --> 00:08:40.899
Classroom 410: All right. Well, I'll start so specifically about the election. What? What is Cis's role in securing elections? And can you tell us anything

61
00:08:41.039 --> 00:08:43.909
Classroom 410: cool that you've done the last month or so.

62
00:08:44.720 --> 00:08:48.176
Em: Absolutely so. Yo, I

63
00:08:49.700 --> 00:08:52.149
Em: I never really thought about elections.

64
00:08:52.150 --> 00:08:55.059
Em: And until I think, like 2016,

65
00:08:55.520 --> 00:09:05.029
Em: politics seemed like just a thingy, that happened. It seemed pretty boring. And then 2,016 happened.

66
00:09:06.230 --> 00:09:17.550
Em: And I felt like I I needed to like, do something I need to like work for the government, and like figure

67
00:09:18.060 --> 00:09:23.119
Em: and like, do do cybersecurity at like a level that wasn't just like

68
00:09:24.718 --> 00:09:29.360
Em: at a small company like trying to trying to like

69
00:09:30.140 --> 00:09:37.360
Em: do it, which was what I was doing at the time. So

70
00:09:37.850 --> 00:09:48.020
Em: since joining in 2,017, we've homeland security has been

71
00:09:49.089 --> 00:09:56.830
Em: has been tasked with securing critical infrastructures, of which elections is one of them.

72
00:09:57.865 --> 00:10:00.640
Em: We have been since then

73
00:10:02.340 --> 00:10:13.899
Em: meeting with State partners, so you meet at the State level. There's 50 States, and then DC. In the United States. And if you've seen one election

74
00:10:14.504 --> 00:10:24.220
Em: you've seen one election, so elections are different in each State. So it's not just the year that the election happens in. It's like

75
00:10:24.770 --> 00:10:32.109
Em: all the years before it. Right? You've if you've got to secure 51 areas of how

76
00:10:32.360 --> 00:10:49.840
Em: the election's going to happen. You've got to be meeting with basically potentially 51 groups of partners. And then there's like State and elections happen at all the different levels. There is like this, there's the Presidential election

77
00:10:50.370 --> 00:11:09.759
Em: for, like the Federal level. But then there's also state elections that happen more often than every 4 years. So we really think about, I think, as a country like the Presidential election every 4 years. But there's many small elections that happen all the time, and then also special elections. So

78
00:11:10.400 --> 00:11:14.430
Em: there's a lot there was a lot of like tabletop exercising.

79
00:11:14.700 --> 00:11:21.630
Em: And we're I have this joke. We're kind of like we're like vampires. We have to be invited in.

80
00:11:22.080 --> 00:11:22.985
Em: So

81
00:11:23.960 --> 00:11:29.399
Em: that doesn't mean that we only work with like blue States or Red States like, we're not partisan

82
00:11:29.500 --> 00:11:40.850
Em: so, but we do have to be allowed in. We don't. We can't barge in and say, like, we're we're going to secure your election. We're going to do it like it is.

83
00:11:41.910 --> 00:11:48.260
Em: It is a conversation, and we do have to work with partners, and they're partners. They're not like underlings.

84
00:11:49.230 --> 00:12:06.529
Em: So this year especially, or at least I think so. Back in 2016 we did find that there was election interference from Russia, and that's been proven, and this year it has.

85
00:12:08.840 --> 00:12:17.500
Em: I would I would say that election interference has continued, but not in ways that are like, I would say the

86
00:12:18.000 --> 00:12:27.889
Em: people think it's not like someone voted for Candidate A, and then, like all the votes actually counted for Candidate B.

87
00:12:27.910 --> 00:12:35.750
Em: I think election interference these days is, it can be much more insidious. And it's more psychological.

88
00:12:36.020 --> 00:12:38.740
Em: And that's not. That's not like

89
00:12:39.630 --> 00:12:48.500
Em: that's not necessarily cyber security in the zeros and ones sense. It's not like the computers are lying. It's not necessarily

90
00:12:49.191 --> 00:13:02.459
Em: the most obvious type of computer crime. But like, I'm sure Professor Ryan and Professor Brian have spoken about like the the human side of security, and

91
00:13:02.540 --> 00:13:09.500
Em: how our minds are fallible. And we're all humans with biases and

92
00:13:09.810 --> 00:13:12.810
Em: and our own experiences. So I think

93
00:13:13.610 --> 00:13:16.699
Em: when we talk about election security

94
00:13:16.740 --> 00:13:25.949
Em: while it is air gapping and having contingency plans, for if there's a flood, if there's a if there's a bomb threat. There is also

95
00:13:27.910 --> 00:13:37.399
Em: making sure that we can get the American people to understand the truth. And what is happening, and how are we

96
00:13:37.720 --> 00:13:46.240
Em: working with election officials who are a lot of times volunteers. They're just people. There are a lot of

97
00:13:46.400 --> 00:13:51.170
Em: people that show up on just election day which who have to go through

98
00:13:51.190 --> 00:13:59.850
Em: several trainings, and they they're the ones to say, Hi, how are you? And they help you get to the polls.

99
00:14:00.226 --> 00:14:04.819
Em: Depending on the state you're in, like they give you the right ballot. So it's

100
00:14:06.740 --> 00:14:12.090
Em: it is about, I think, people this year.

101
00:14:12.200 --> 00:14:19.340
Em: and that's that that seems like it's been a bigger shift towards that.

102
00:14:19.650 --> 00:14:20.190
Classroom 410: Yep

103
00:14:21.660 --> 00:14:34.100
Classroom 410: so, and I'll turn it over to students. But I do want to ask. You know, there's a lot of talent in this room. Obviously you're a very talented person. Why, why, the government like what? What interests you about working for the Government versus.

104
00:14:34.120 --> 00:14:37.959
Classroom 410: you know, making may maybe a little bit more in the private sector.

105
00:14:38.670 --> 00:14:50.019
Em: Sure. This is a cool and personal question. So thank you. So I have. I have an Mba. And I was getting my Mba. At the time that I met

106
00:14:50.850 --> 00:15:05.550
Em: Brian, and there was a scholarship that was being offered. It's called the Cyber Core Scholarship for Service program, and I wanted to be in it, and there was a different Brian

107
00:15:05.630 --> 00:15:17.880
Em: at the University of Massachusetts, who was a professor of computer science, and he said to me, why would you want to do this? You're getting an Mba. You could make like a million dollars.

108
00:15:21.570 --> 00:15:29.458
Em: And you'll you'll find out, unfortunately, that it's like. It's not as easy as that.

109
00:15:30.570 --> 00:15:32.390
Em: But I

110
00:15:32.470 --> 00:15:41.510
Em: felt as a person of color and a person of the LGBT community that I was an American, too. And

111
00:15:42.110 --> 00:15:46.390
Em: I wanna like, get into

112
00:15:46.710 --> 00:15:55.100
Em: serving people of this country. And I think when you think of service work, you probably think of like being in the military

113
00:15:56.000 --> 00:16:02.709
Em: and that's not the same right. I don't put my life on the line

114
00:16:03.150 --> 00:16:15.789
Em: for my job, but I do dedicate my time, and I do think about all the people that live in this nation that look or don't look like me, and think, or don't think like me, and I want them to like

115
00:16:16.480 --> 00:16:19.380
Em: would be able to live their lives every day in this country.

116
00:16:19.960 --> 00:16:21.860
Em: So I mean.

117
00:16:22.060 --> 00:16:25.929
Classroom 410: That's why government and I like working around people that.

118
00:16:26.820 --> 00:16:36.190
Em: You know, also like look or don't look like me, think, or don't think like me, but also want to have this mission to like preserve people's lifestyles like

119
00:16:36.630 --> 00:16:49.829
Em: I. I like living in a community where some people would agree or disagree with me. I don't. I don't want to live somewhere where, like everyone's the same, and says the same stuff, and thinks the same thing.

120
00:16:54.320 --> 00:16:55.890
Classroom 410: All right. I'll open it up

121
00:16:56.414 --> 00:17:04.030
Classroom 410: questions for M. About her role at Cisa, or about Cisa, or about life.

122
00:17:04.220 --> 00:17:04.890
Classroom 410: But

123
00:17:10.200 --> 00:17:19.177
Classroom 410: sure, hey, I'm good to see. I'm sitting way in the back of the room so you could probably hopefully you you remember my voice. So

124
00:17:19.589 --> 00:17:22.310
Classroom 410: you know you started this journey.

125
00:17:22.380 --> 00:17:31.260
Classroom 410: My math is right. It's like a decade ago. Does that sound about right as far as it being at how long you been at Cisa for.

126
00:17:31.652 --> 00:17:37.149
Em: I've been there since 17, so I mean almost a decade, but not yet.

127
00:17:37.470 --> 00:17:47.806
Classroom 410: Not yet. So yeah, so what do you? What's been the biggest change in that organization over the last 7 or 8 years that you've seen with everything that's gone on, has there been?

128
00:17:48.370 --> 00:17:50.300
Classroom 410: And then the second question, What's

129
00:17:50.510 --> 00:17:54.469
Classroom 410: how have the attacks changed over the 7 or 8 years.

130
00:17:55.130 --> 00:18:04.950
Em: Absolutely. That's a great question. Thanks. So I think. Hands down. It was the pandemic. That was the biggest thing that just rocked the whole world right? It wasn't just

131
00:18:06.250 --> 00:18:12.710
Em: wasn't just me. But like overnight, basically, like I had to like.

132
00:18:12.970 --> 00:18:25.150
Em: we just didn't have the policy for it, like from a standpoint like we just nobody did. No one was like suddenly, like March of 2020. We've got to shut down

133
00:18:25.290 --> 00:18:30.749
Em: and no one can go outside and we're gonna work

134
00:18:31.170 --> 00:18:38.210
Em: in our homes. I mean, luckily, we're we're like a technology agency. So everyone

135
00:18:38.420 --> 00:18:51.690
Em: had laptops. We already had the provisions to work remote. Because, like, we have like VPN set up. And really, what we did was we just like ordered everyone

136
00:18:52.120 --> 00:18:54.650
Em: an extra monitor, a keyboard, and a mouse.

137
00:18:55.600 --> 00:19:02.579
Em: so that you could. You could work more efficiently without, like a 50 inch screen and like a little trackpad.

138
00:19:02.730 --> 00:19:10.350
Em: so that worked all right for for us. But that increased like the load on our networks.

139
00:19:10.430 --> 00:19:19.727
Em: So we had. It was. It was bumpy for everyone, but it also showed that, like we can be really resilient. And

140
00:19:20.450 --> 00:19:23.109
Em: continued to meet the mission even when

141
00:19:24.010 --> 00:19:38.470
Em: we're not meeting with our partners in person all the time. But it's it's not like the technology wasn't there. And like we weren't already having partners that weren't in the same time zone. And we had to like figure out a time to meet and

142
00:19:38.840 --> 00:19:42.230
Em: like do our stuff. I think the hardest part was that we have

143
00:19:42.460 --> 00:19:49.379
Em: some secure facilities that cannot be accessed from outside. So we did have to have people go in

144
00:19:50.120 --> 00:19:53.750
Em: in person, but that's a smaller number.

145
00:19:54.950 --> 00:20:02.440
Em: And how the attacks have changed. I mean, generative AI is is huge. And this was something that

146
00:20:02.510 --> 00:20:08.899
Em: we were talking about when I started so 7 years ago, and you didn't really see it. And it wasn't like

147
00:20:09.440 --> 00:20:16.170
Em: chat. Gpt wasn't like you couldn't just sign up for free but

148
00:20:16.860 --> 00:20:19.749
Em: generative AI, I think, is like the

149
00:20:20.810 --> 00:20:26.929
Em: really you're really starting to see it happen. Because you can.

150
00:20:27.160 --> 00:20:39.242
Em: you can launch an attack and change strategies in real time, like no longer. Our adversaries have, like a certain footprint that we expect, whether it's like

151
00:20:40.160 --> 00:20:48.630
Em: timestamps, right? Like we used to be able to see attacks happen 5 days a week during

152
00:20:48.720 --> 00:20:51.400
Em: certain hours. So then, you're like, if this.

153
00:20:51.450 --> 00:20:57.294
Em: this is someone's job, then this is someone's 9 to 5. And then you think about

154
00:20:58.720 --> 00:21:03.970
Em: like, what? What part of the world would this be? A 9 to 5? And maybe

155
00:21:03.980 --> 00:21:10.069
Em: they work, they're only attacking 6 days a week. So then, you're like, well, maybe

156
00:21:10.460 --> 00:21:28.610
Em: this, these attacks are coming from a country that observes one day of the week where they don't work. So is this, does this mean that they might have a certain like religious influence in this country, so we could pinpoint things easier.

157
00:21:28.950 --> 00:21:38.409
Em: whereas now we sort of have to pinpoint things by like, what is the target? What is the pattern of the targets? What are they trying to get.

158
00:21:40.290 --> 00:21:40.843
Classroom 410: Thank you.

159
00:21:43.270 --> 00:21:57.550
Classroom 410: I'm anon I'm a 4th year. I'm doing Cs and it in the Comp school. I'm kind of curious more on the personal side, being in this type of work for almost a decade, does.

160
00:21:57.780 --> 00:22:10.599
Classroom 410: I guess the weariness of like how many attacks you've seen over the years come into your own personal life. Do you have anxiety around? I guess what I'm asking is like. Would you rather have had ignorance towards all of this cyber security related attacks.

161
00:22:10.770 --> 00:22:16.810
Classroom 410: That's kind of what I'm asking. Or do you set up anything for your personal life in a way that stops these attacks.

162
00:22:17.750 --> 00:22:21.997
Em: That's that's such an awesome question. Thank you. Because

163
00:22:23.620 --> 00:22:31.439
Em: Before the pandemic, like, we'd have more parties, and like a couple times a year we'd go to my boss's house, and he'd

164
00:22:31.900 --> 00:22:39.610
Em: he'd invite everyone, and he would continue to invite people that had left the organization. And so

165
00:22:39.970 --> 00:22:47.040
Em: I talked to these people. We stay in touch because, you know, the world is still kind of small

166
00:22:48.954 --> 00:23:00.559
Em: and people that have left our organization say that, like, I like working at like Amazon, or whatever because I couldn't sleep at night.

167
00:23:00.710 --> 00:23:09.920
Em: and now I can sleep at night. I can sleep at night with my 3 cars, 2 garage house like whatever and like they just.

168
00:23:09.930 --> 00:23:12.290
Em: I don't know, do like data architecture.

169
00:23:13.060 --> 00:23:21.040
Em: So I would say that absolutely like this is not for everyone. I think this year was especially tough.

170
00:23:22.550 --> 00:23:30.269
Em: mentally, I can see across the organization people.

171
00:23:30.830 --> 00:23:32.040
Em: People did leave

172
00:23:33.355 --> 00:23:42.280
Em: we had some attrition more than usual this year from Feds, and also contractors. For sure, I think

173
00:23:44.730 --> 00:23:47.539
Em: not. Everyone has the stomach for this work.

174
00:23:48.740 --> 00:23:59.145
Em: And I am an ultra athlete. I raced bicycles. I did

175
00:24:00.930 --> 00:24:04.549
Em: a race this year, where I covered like

176
00:24:04.890 --> 00:24:09.739
Em: a hundred 25 miles in like 12 h.

177
00:24:09.800 --> 00:24:12.549
Classroom 410: Yeah, cause it was like, really mountainous.

178
00:24:12.670 --> 00:24:18.499
Em: So. And I joke that like, that's how I can do the work I do. So like.

179
00:24:20.110 --> 00:24:29.180
Em: Maybe with lots of disassociation. Sometimes, like I do like have a system where I I try to like

180
00:24:29.360 --> 00:24:35.469
Em: like literally escape from technology, right? Like, if I'm like in a remote place, and no one can find me

181
00:24:36.400 --> 00:24:41.510
Em: to let me know that there was a breach. And we're having a national emergency like

182
00:24:42.380 --> 00:24:51.379
Em: sometimes, like, you know, some people do do that, and some people at my work are like Marathon runners. I think I think you'll find that like

183
00:24:53.910 --> 00:24:58.040
Em: to to take care of our mental health like a lot of people do turn to exercise.

184
00:25:02.150 --> 00:25:11.310
Classroom 410: Others. Hi, I'm my name is Matt. I'm 4th year studying finance and it here. My question is kind of 2 parted.

185
00:25:11.450 --> 00:25:19.499
Classroom 410: 1st I think you kind of touched on it, but I'm just curious to hear, like the chain of command within Cisa and then kind of stemming from that question.

186
00:25:19.880 --> 00:25:32.559
Classroom 410: I've said that you said you started in 2017 and now there's like a different President than there was then, and I'm kind of curious of like as that changes. Do the roles of your job change or like? Do you see, like the initiatives change

187
00:25:32.580 --> 00:25:33.970
Classroom 410: within Cisco.

188
00:25:35.120 --> 00:25:36.440
Em: Sure. Yeah. So

189
00:25:38.710 --> 00:25:52.139
Em: The Christopher Krebs, like level now, is Jen easterly. She is the director of Cisa, and below her

190
00:25:53.181 --> 00:26:01.879
Em: our divisions, and so within Cisa I work under the Cybersecurity division. That's Csd.

191
00:26:01.990 --> 00:26:09.054
Em: and then under Csd, I work at threat hunting, and I have a director there and then.

192
00:26:10.260 --> 00:26:22.109
Em: threat hunting is actually split into threat and hunt. So threat is more like, I would say, left of boom. It's more proactive, and then Hunt is like

193
00:26:23.060 --> 00:26:40.790
Em: something has hit the fan we've got to deploy. Let's go. So I work at the threat hunting level in sort of like I've got like 250 people reporting to me. But I also have to report up to

194
00:26:42.800 --> 00:26:52.290
Em: talk about our outcomes and our metrics, and like foresee any issues in terms of

195
00:26:52.580 --> 00:27:00.775
Em: how my work is going to change with the incoming administration. I I've seen 2 now and

196
00:27:02.260 --> 00:27:09.220
Em: you know, I think I imagine cyber security could become

197
00:27:09.290 --> 00:27:16.990
Em: more bearish, maybe less congressional funding coming to Cisa.

198
00:27:17.190 --> 00:27:20.520
Em: I can. I've been.

199
00:27:21.040 --> 00:27:23.929
Em: There's been some mutterings that

200
00:27:24.030 --> 00:27:32.160
Em: we won't focus as much on election security. Moving forward, you can. You can take what you want about that

201
00:27:34.385 --> 00:27:38.010
Em: and probably focusing more on China.

202
00:27:41.330 --> 00:28:07.890
Classroom 410: Are we got time for one or 2 more sorry. So we just completed a case for class today. Actually, that was discussing like Gdpr, and sort of like some of the policies that, like America, wants to take like moving forward for like regulation, for consumer privacy, and one of the perspectives that, like that, one of the perspectives in the case was like a governmental or like law enforcement agency, which actually like we had, I had to do for my portion.

203
00:28:07.890 --> 00:28:15.000
Classroom 410: I was just like curious like, what is your take like working at as a slash like? And I like a government agency on what

204
00:28:15.000 --> 00:28:24.889
Classroom 410: we should be doing, moving forward in terms of like, how much data companies have, how much information consumers are giving and like, whether or not that poses a risk for, like nation, state actors.

205
00:28:25.790 --> 00:28:34.409
Em: Oh, yeah, absolutely. So I mentioned earlier that, like, we don't do law enforcement and

206
00:28:34.860 --> 00:28:42.289
Em: homeland security is not so much internationally reaching as we are more domestic.

207
00:28:43.380 --> 00:28:49.318
Em: But that said like I can give you my my like personal take on it like

208
00:28:49.890 --> 00:29:02.289
Em: I think the right to be forgotten, right? Like you being able to have control over your data is important. Because, like.

209
00:29:02.450 --> 00:29:06.960
Em: I mean, even if you search yourself on these like people, find our websites like

210
00:29:07.150 --> 00:29:11.069
Em: you can ask to like you can, you can look yourself up.

211
00:29:11.330 --> 00:29:26.590
Em: And then you're gonna be. You might be surprised that, like the information they find they're gonna like for free. Right? Like you could find your identity, you can find all. Probably most of the addresses you've been associated with. You can find

212
00:29:28.500 --> 00:29:34.170
Em: utilities that you've been using your phone number, your

213
00:29:34.530 --> 00:29:42.219
Em: birthday, your associated social media accounts. And then people that you have been associated with. And

214
00:29:42.720 --> 00:29:50.329
Em: I do search for myself regularly and like request that I get deleted off those websites, and I do.

215
00:29:50.960 --> 00:29:56.880
Em: But new websites come up right. So it's like, if there's this

216
00:29:57.040 --> 00:30:00.349
Em: open source information, you at least need to have

217
00:30:00.430 --> 00:30:04.720
Em: some sort of way to like, get rid of it. And like

218
00:30:06.100 --> 00:30:13.359
Em: we live in the digital world. We all get spam. You get spam to your phone. You get spam to your emails, you know, like

219
00:30:13.890 --> 00:30:23.040
Em: these companies are just like selling it to make more money. So I think we like personally like.

220
00:30:23.570 --> 00:30:28.989
Em: I think we should protect consumers. Because if we don't, and we're just being run by like

221
00:30:30.570 --> 00:30:34.410
Em: organizations that profit off us like

222
00:30:34.640 --> 00:30:41.710
Em: without our consent, like. It's 1 thing for me to purchase a product or service because I want it.

223
00:30:41.810 --> 00:30:44.840
Em: But it's another thing that like

224
00:30:45.640 --> 00:30:51.470
Em: to like secretly or unknowingly agree to have.

225
00:30:52.630 --> 00:30:56.320
Em: like, basically the metadata around that purchase sold

226
00:30:57.750 --> 00:31:04.814
Em: like and continue being profited off of. So though that's that's my personal. Take on it like

227
00:31:07.190 --> 00:31:14.630
Em: I think, like a lot of folks that work at the Government would feel like

228
00:31:15.140 --> 00:31:20.900
Em: reasons why you would be an American is to like, have certain freedoms. So

229
00:31:21.580 --> 00:31:24.720
Em: I think if you dig deep enough like, they might agree with me.

230
00:31:27.160 --> 00:31:27.850
Classroom 410: Second.

231
00:31:29.890 --> 00:31:33.435
Classroom 410: Alright, I can still the last one, if there's no more.

232
00:31:34.900 --> 00:31:49.600
Classroom 410: These are generally short responses, but I'll try. So, Em, it's been 3 and a half years since the colonial pipeline attack. Can you tell us any more about Cis's role in that remediation, or is that your answer still going to be. I can't comment on that.

233
00:31:50.830 --> 00:31:51.719
Em: You got it.

234
00:31:52.672 --> 00:31:53.757
Classroom 410: I tried.

235
00:31:54.678 --> 00:32:09.730
Classroom 410: Okay? Well, m. 1 more question. We'll go to the back room. Hi, my name is Jess. I'm a master's in accounting student. I was wondering, as consumers going forward like, what would you recommend from your perspective that we establish or

236
00:32:10.060 --> 00:32:20.790
Classroom 410: install to prevent any attacks on our side can't read it, or for small businesses.

237
00:32:24.510 --> 00:32:25.275
Em: Okay.

238
00:32:26.270 --> 00:32:38.700
Em: I think it's less about like the services that you're gonna install and more about like where you put yourself in the 1st place. So making sure that you've got separate things for separate

239
00:32:38.890 --> 00:32:47.820
Em: functions right? Like, maybe you don't set up a shared email for every single person in your organization to

240
00:32:50.090 --> 00:33:01.900
Em: receive invoices or pay invoices because you want to be able to track. Who's doing that? So

241
00:33:03.050 --> 00:33:06.720
Em: just making sure your access control

242
00:33:06.830 --> 00:33:12.239
Em: is there, and and really like, plan out,

243
00:33:13.980 --> 00:33:18.480
Em: the roles and responsibilities. I think so. If

244
00:33:19.760 --> 00:33:28.210
Em: you've got an email address where you get like all like, where you do all your shopify, but also pay your bills and also get like

245
00:33:31.120 --> 00:33:35.530
Em: like your financial stuff, too, like that's

246
00:33:35.940 --> 00:33:41.559
Em: that's such a honeypot for someone who wants to get information about you.

247
00:33:42.130 --> 00:33:45.099
Em: So thinking about like

248
00:33:48.130 --> 00:34:04.849
Em: being an individual having separate email accounts for like your work and your play that typically like when when you start work at an organization, they give you an email address. But like making sure you don't like. Then sign up that email address for, like lots of personal stuff.

249
00:34:06.440 --> 00:34:24.259
Em: That should be like one on one. But like sometimes I don't. I don't even see that on like it security trainings. And then so and then for, like a small business, making sure that everyone gets their own like credit card it's not just one credit card that everyone is using. So

250
00:34:24.420 --> 00:34:28.329
Em: you want to just make sure that, like, there's no one person that can like.

251
00:34:30.480 --> 00:34:38.330
Em: It's probably a negative way to pose it as like you don't want one person to screw everyone over. So I'm going to say that, like you don't want to

252
00:34:39.120 --> 00:34:46.900
Em: open your risk to one person like potentially taking advantage of everything.

253
00:34:49.859 --> 00:34:56.569
Classroom 410: On a bigger scale. What is your guys's process for deploying like a team? If there's an attack

254
00:34:57.559 --> 00:35:00.009
Classroom 410: cause it's more on the hunting side.

255
00:35:00.880 --> 00:35:10.550
Em: Sure. So on the hunting side, the 1st thing we do is usually victim notification. So we'll reach out to the organization. Say, like, hey.

256
00:35:11.570 --> 00:35:16.090
Em: we've got an indicator of compromise for your organization.

257
00:35:16.510 --> 00:35:21.848
Em: We have these services we want to do. And sometimes they're like, Yeah, we

258
00:35:23.000 --> 00:35:31.559
Em: we're like fire eyes on it like we're we. We've got our own folks like we'll deal with it, and then we're like, cool, all right, and we back off

259
00:35:34.240 --> 00:35:42.600
Em: Otherwise, if they want our help, we do require them to sign a memo of understanding

260
00:35:43.070 --> 00:35:47.601
Em: go through, and it usually requires a couple of rounds with their lawyers,

261
00:35:48.100 --> 00:35:52.179
Em: and their lawyers are always like. No, we don't want you to come in and

262
00:35:52.560 --> 00:35:56.589
Em: do these things to our data, and then

263
00:35:56.610 --> 00:36:00.620
Em: they never win. So if they want us to come in, they have to

264
00:36:01.430 --> 00:36:08.480
Em: basically sign our paperwork, and then we go in depending on the compromise.

265
00:36:08.580 --> 00:36:14.790
Em: We can deploy within 24 h. And so we have like a

266
00:36:14.960 --> 00:36:26.208
Em: big list. We'd we'd take a look at pretty much like the footprint of the organization like, do they have assets in the cloud? Are they mostly a mom and pop shop?

267
00:36:27.190 --> 00:36:31.309
Em: do they have like an extensive network footprint?

268
00:36:31.420 --> 00:36:36.930
Em: And so we've we pretty much like, pick our analysts. Like.

269
00:36:37.110 --> 00:36:50.330
Em: if you were to like, choose your team in a video game, we've got cloud analysts. We've got host analysts. We've got network analysts we have Ics analysts, so that Ics is like, it's like

270
00:36:50.830 --> 00:36:56.139
Em: special computing that you would see more in like power plants.

271
00:36:56.703 --> 00:37:05.370
Em: This is this is like, or like, yeah, definitely like, nuclear type power plants. You, that's much more specialized computing.

272
00:37:06.337 --> 00:37:10.540
Em: And then we we would put that team together

273
00:37:10.980 --> 00:37:18.269
Em: get probably like a writer on that team, and then someone to lead the team. And we'll we have

274
00:37:18.280 --> 00:37:22.739
Em: a analyst kit that we deploy. We send that out by Fedex.

275
00:37:23.290 --> 00:37:24.410
Em: It's like.

276
00:37:24.961 --> 00:37:36.889
Em: It's like 4 stacks of servers. We have couple vans. So if it's like within 3 States or something we can drive. We'll load it up into a van and we'll we'll drive over.

277
00:37:37.050 --> 00:37:39.630
Em: Otherwise people are flying.

278
00:37:39.880 --> 00:37:41.220
Em: People are up in the air.

279
00:37:45.700 --> 00:37:56.579
Classroom 410: All right and well, we got to talk about the pandemic and cyber crime and all kinds of stuff today. So let me lead the way, give me a round of applause. Thank you for for

280
00:37:57.438 --> 00:38:01.740
Classroom 410: good to see you always good to talk to. You, appreciate it.

281
00:38:02.670 --> 00:38:03.970
Em: Thanks everyone, bye.

282
00:38:09.340 --> 00:38:12.042
Classroom 410: He's the only one to talk about something.

283
00:38:26.420 --> 00:38:27.130
Classroom 410: yeah.

284
00:38:30.270 --> 00:38:34.859
Classroom 410: okay, we're good. Okay. So if

285
00:38:34.860 --> 00:39:01.190
Classroom 410: you know one of the things that Em is great about is, we used to take groups of students up to see the CIA and some other government organizations great careers there. If you want to think about that career path. Em is always happy to talk to people, but it's a path that a lot of commerce students never think about, because, you know the government, I could make double, triple, quadruple what they make. But in this type of role in Cisa they pay fairly well for the government.

286
00:39:01.270 --> 00:39:05.179
Classroom 410: So, anyway, Emma's always happy to talk to students going forward.

287
00:39:05.950 --> 00:39:09.960
Classroom 410: Alright. I assigned you a 2 page case.

288
00:39:10.350 --> 00:39:17.660
Classroom 410: Wasn't that awesome? 2 page case for the last day of class. What was it about? Who can sum it up for me in 30 seconds or less?

289
00:39:17.700 --> 00:39:19.409
Classroom 410: 15 seconds or less?

290
00:39:21.200 --> 00:39:22.400
Classroom 410: Anybody read it

291
00:39:23.450 --> 00:39:52.679
Classroom 410: alright. We got it. It's kind of a debate between, like big companies like Apple and Google. They were using some technology with Bluetooth for contract tracing for Covid. And there were some other entities like the French government. That kind of wanted more extreme policing of this data so that they could, you know, have effective tracking. And it was kind of how Apple and Google against that and weighing the pros and cons of that

292
00:39:53.040 --> 00:39:55.379
Classroom 410: perfect. So thank you so much.

293
00:39:55.711 --> 00:40:05.059
Classroom 410: So what I did was I put you by group into a persona and asked you a few questions about this, you know, to put on the hat of an organization.

294
00:40:05.310 --> 00:40:10.180
Classroom 410: So I'll do the same thing in this room. So you can talk to each other about this.

295
00:40:10.190 --> 00:40:25.839
Classroom 410: But in your persona, within your group. Please have a conversation about this statement, and we'll come back in a couple minutes and talk about the United States would be in a better position if we adopted Gdpr type legislation that is in place for the 27 members of the

296
00:40:26.490 --> 00:40:29.122
Classroom 410: so discuss.

297
00:40:34.551 --> 00:40:55.260
Classroom 410: I don't know. I think.

298
00:41:54.840 --> 00:42:07.280
Classroom 410: Okay.

299
00:42:33.450 --> 00:42:44.909
Classroom 410: I think it's gotten quiet enough. So who? Which of my groups were the government and law enforcement? All right, what's your take on this statement?

300
00:42:45.420 --> 00:42:58.380
Classroom 410: We said that the Us. Government would typically be anti adopting the Gdpr type legislation. That's because, like we as like a governmental agency, and because, like the patriot act like want access to all this information.

301
00:42:58.420 --> 00:43:10.499
Classroom 410: And like, if hackers are gonna be able to like, yeah, access to databases that have like consumer and like consumer private information that could be that use against like the Us. Government like we would want it first.st

302
00:43:10.650 --> 00:43:19.759
Classroom 410: And so like increasing legislation around that, like increasing the privacy laws that, like consumers, have like limits, like the Us. Government's ability to like, interfere, and like, look at communications or not

303
00:43:19.820 --> 00:43:21.499
Classroom 410: interfere. I like that word.

304
00:43:21.560 --> 00:43:23.100
Classroom 410: Other government takes

305
00:43:24.300 --> 00:43:40.028
Classroom 410: still, government or no. Okay, which which group are you? Oh, we're the consumer. All right. Let's let's a rebuttal from our consumer. So we kind of said like we wanted to like, adopt, like a more like Gdp, like legislation, because it also like allows us to like

306
00:43:40.600 --> 00:43:57.649
Classroom 410: give consent to how much data we want like businesses to like have it also gives us like the right to be forgotten, like we don't want all of our data to like for our businesses to have it and then use it for like like bad stuff like, and also protects us from like risk of like data, breaches as well and like potential like identity. Theft.

307
00:43:57.680 --> 00:43:59.909
Classroom 410: Is anyone in here a citizen of the EU?

308
00:44:01.520 --> 00:44:12.220
Classroom 410: And have you ever invoked your right to be forgotten? No, okay, all right? So we got a consumer view. We got a government view. What about our large corporations? Who are they?

309
00:44:12.720 --> 00:44:14.990
Classroom 410: What are your thoughts on this statement?

310
00:44:15.170 --> 00:44:19.210
Classroom 410: So we were all kind of convinced that

311
00:44:19.660 --> 00:44:29.439
Classroom 410: it might well, it might be good for the Government to have the kind of Gdpr style law, just because it would simplify completely

312
00:44:29.600 --> 00:44:33.650
Classroom 410: compliance with, compared to the current

313
00:44:33.970 --> 00:44:38.119
Classroom 410: kind of patchwork system that we have where it's different by state.

314
00:44:39.000 --> 00:44:39.860
Classroom 410: But

315
00:44:41.242 --> 00:44:56.407
Classroom 410: on the other hand, it would be really expensive and really high, costly to implement all that into our systems, and to make sure all of our branches and all of our subsidiaries are following the same laws, and it would also,

316
00:44:57.260 --> 00:45:26.700
Classroom 410: really interfere with our ability to collect certain types of data that we need to have on our customers. So for you, okay, so it was a mixed bag. Yeah. So yes, it would make regulations easier, because you would have one instead of potentially 51. But on the other side it's going to cost money, and it may cost you customers. The ability to sell any other takes from a large corporations.

317
00:45:27.370 --> 00:45:28.250
Classroom 410: Anybody

318
00:45:28.560 --> 00:45:38.519
Classroom 410: also more so like it depends as well. Oh, I like, that's a faculty answer. But you know, I just like the just. The idea of having

319
00:45:38.620 --> 00:45:45.459
Classroom 410: a consistent, you know, having consistency throughout would be really beneficial, because

320
00:45:45.580 --> 00:45:49.149
Classroom 410: you don't have to worry about different laws and regulation different

321
00:45:49.522 --> 00:45:56.770
Classroom 410: states where all the you can have your corporations in all those States. But then, at the same time, you.

322
00:45:57.000 --> 00:46:00.330
Classroom 410: even though you will be able to build consumer, trust.

323
00:46:00.600 --> 00:46:03.559
Classroom 410: With this you also have to then

324
00:46:03.630 --> 00:46:11.949
Classroom 410: have. There's so much due to regulations where it's like, you don't have that much data. And as a large corporations, probably trying to grow. You know.

325
00:46:12.080 --> 00:46:19.130
Classroom 410: your having data is, it's really good. But same time it's like

326
00:46:19.280 --> 00:46:23.310
Classroom 410: not having. It's a smaller pool of data that you have to collect. And then it's like.

327
00:46:23.900 --> 00:46:31.770
Classroom 410: yeah, for a large corporation. They do have like primary data. So they have to worry worry about things like as like other corporations. So if you think about

328
00:46:32.170 --> 00:46:35.442
Classroom 410: it, might be kind of hard for them to actually grow

329
00:46:36.020 --> 00:46:46.049
Classroom 410: so mixed bag as well. All right. Yeah, I was kind of on the side where, like, more data is just overall, more beneficial to the company. Just because you can make like

330
00:46:46.730 --> 00:46:54.810
Classroom 410: more personalized customer experiences and like it helps the company run more efficiently. So like

331
00:46:55.510 --> 00:46:58.340
Classroom 410: a comprehensive data, privacy law would kind of

332
00:46:59.290 --> 00:47:03.560
Classroom 410: limit the amount of data that impinge that perhaps.

333
00:47:04.352 --> 00:47:08.879
Classroom 410: But you know, you know to the point made before, if I have a data breach

334
00:47:09.030 --> 00:47:15.389
Classroom 410: in the United States, and I do business with customers in all 50 States. How many attorney generals might I have to notify?

335
00:47:15.930 --> 00:47:16.600
Classroom 410: Hmm.

336
00:47:18.485 --> 00:47:19.710
Classroom 410: 50.

337
00:47:19.870 --> 00:47:46.860
Classroom 410: That's fun. Right? Let's keep going. I'm also on the large corporation side and kind of on top of all the other points that were said. I also mentioned how we wouldn't want to like voluntarily put ourselves in a position where, if we were to somehow violate this rule, we'd have to pay like a large punitive consequence. Nobody mentioned that. Yet. So Gdpr is 4% potential fines of global revenue. Does that worry you guys as large corporations?

338
00:47:46.870 --> 00:47:54.260
Classroom 410: I mean, that's a large amount like, so as we talk through these cases and these settlements.

339
00:47:54.400 --> 00:48:17.930
Classroom 410: these, these fines that companies are receiving in the United States are so minuscule that they don't even matter. They're rounding errors. But with a Gdpr type legislation. You know, privacy has to be important, because if I lose, if I lose the court cases, basically after the end of the day, I could be liable for 4% of global revenue which is in the multi billions of dollars for these companies.

340
00:48:19.660 --> 00:48:30.799
Classroom 410: All right. Next question, we'll just go hot. Takes. Now I have a question about the right to be forgotten thing, so if he is able to do it in Europe, or whatever, how does that

341
00:48:30.840 --> 00:48:34.329
Classroom 410: like, would it only be for, like European sites, or does it also apply to like

342
00:48:34.670 --> 00:48:36.519
Classroom 410: American sites too? If you

343
00:48:36.550 --> 00:49:01.329
Classroom 410: so in theory it applies to American sites as well. So there's a you know, every company, every website that you visit right now, you have the banner that makes you opt in and select cookies. There's no law in the United States that says anything about that, because I'm doing business with potential EU citizens is one of the reasons why the University of Virginia has to deal with Gdpr. Is because we have EU citizens that are our customers here.

344
00:49:01.390 --> 00:49:07.769
Classroom 410: So in theory, when a block as big as the EU does something like this. It can affect companies worldwide.

345
00:49:08.394 --> 00:49:16.029
Classroom 410: Apac, Asia, Pacific economic consortium has very similar laws. You know, it's not as famous as Gdpr, but

346
00:49:16.040 --> 00:49:20.300
Classroom 410: yeah, so if you're gonna do multinational business, you have to worry about Gdp.

347
00:49:23.609 --> 00:49:26.479
Classroom 410: all right. The hot take hot. Take

348
00:49:27.090 --> 00:49:31.799
Classroom 410: consumers vote with their feet. They want to give up privacy, convenience. What's the possible harm?

349
00:49:34.630 --> 00:49:39.339
Classroom 410: Who in here has Gmail, who in here read that agreement?

350
00:49:40.600 --> 00:49:44.500
Classroom 410: I have free email from Gmail, is that a

351
00:49:44.550 --> 00:49:51.430
Classroom 410: I I'm giving up my privacy for that service. What's the possible harm anybody got a hot take on that.

352
00:49:52.860 --> 00:50:02.611
Classroom 410: I mean, it's your data, you're willingly giving it up. What's the problem? Maybe if you have like a great idea, for example, you're emailing someone about it.

353
00:50:03.230 --> 00:50:12.780
Classroom 410: in a sense, since you're giving up that data for Gmail to have if someone doesn't come across or someone in Google, maybe they could use it and say, it's their data.

354
00:50:13.720 --> 00:50:17.880
Classroom 410: So you're saying, there's a possible downside to this.

355
00:50:18.250 --> 00:50:24.199
Classroom 410: So the agreement that you signed when you signed up for a Gmail account so that they can read your email.

356
00:50:24.630 --> 00:50:28.940
Classroom 410: Does that bother anybody anybody ever think twice about that?

357
00:50:29.630 --> 00:50:36.830
Classroom 410: You know, if you don't want to, there's a couple of takes on this. I'll open up the room. Any other thoughts on this statement.

358
00:50:37.030 --> 00:50:43.920
Classroom 410: So consumers can choose not to do business with companies if they're concerned about their data practices, right?

359
00:50:44.460 --> 00:50:46.009
Classroom 410: Can they or can they not?

360
00:50:46.730 --> 00:50:54.250
Classroom 410: I mean, I feel like at this point. Most people expect that most of their data is just kind of like accessible by anyone.

361
00:50:54.810 --> 00:51:02.770
Classroom 410: At least, that's kind of what I think. And so it's kind of like a yeah gmail gets into whatever, because it's already up there.

362
00:51:02.800 --> 00:51:08.789
Classroom 410: So I'll ask it to the roof. Does anyone have an expectation of privacy anymore? Electronically.

363
00:51:09.360 --> 00:51:15.309
Classroom 410: because who does not raise your hands? If you, if you think along the same lines that

364
00:51:15.970 --> 00:51:19.684
Classroom 410: somebody's gonna be looking at my data at some point. I shouldn't expect it.

365
00:51:20.130 --> 00:51:26.050
Classroom 410: Cool, cynical room. Okay? I like it. So we have no expectations of privacy.

366
00:51:27.910 --> 00:51:29.410
Classroom 410: Any other takes on this.

367
00:51:31.630 --> 00:51:34.439
Classroom 410: Alright, we'll go on to the next step.

368
00:51:35.177 --> 00:51:41.090
Classroom 410: Law enforcement should be able to access every device they save lives every day. With this information.

369
00:51:41.440 --> 00:51:46.199
Classroom 410: anybody have a reaction to that statement. I see a head shake.

370
00:51:46.750 --> 00:51:48.170
Classroom 410: Yeah, I disagree.

371
00:51:48.650 --> 00:51:50.743
Classroom 410: I think I think

372
00:51:51.830 --> 00:51:57.779
Classroom 410: as a company, especially like a like a tech. I think in cases like a technology provider

373
00:51:58.440 --> 00:52:09.230
Classroom 410: kind of like sign a contract with your customers that you're gonna protect their like, safeguard their data. And although I do get that like some crime is is

374
00:52:09.800 --> 00:52:16.590
Classroom 410: sneak in through text or whatever it be, I think that you still have to like preserve that, because.

375
00:52:17.860 --> 00:52:21.480
Classroom 410: like, that's just the reality of like a contract. I mean.

376
00:52:21.750 --> 00:52:26.359
Classroom 410: you can't just get out of a contract just because you think someone's doing wrong. But I do think, however, like

377
00:52:27.730 --> 00:52:37.950
Classroom 410: I don't know, I'm trying to think back to the example of I don't know what the attack was when they found them through like his application, like, there's multiple occasions of that.

378
00:52:38.100 --> 00:52:45.299
Classroom 410: If it's like a terrorist threat or something like that. I do get that. I think companies should be able to release it in the event of like

379
00:52:46.350 --> 00:52:48.379
Classroom 410: it's see, it's for the

380
00:52:48.950 --> 00:52:55.250
Classroom 410: the safety of like the greater community I do get in that sense. But I don't think it should just be like constantly

381
00:52:55.620 --> 00:53:08.020
Classroom 410: looked over and stuff like that. Okay, so you may say there's an intervention, perhaps a warrant right, and at that point you would open the doors. I guess the other flip side to this is like

382
00:53:08.540 --> 00:53:14.670
Classroom 410: you also hope that, like as a company, these like law enforcement agencies are like working in the best interest of like

383
00:53:14.830 --> 00:53:17.179
Classroom 410: consumers, citizens of also like.

384
00:53:17.430 --> 00:53:22.639
Classroom 410: you know, it's also like setting a certain level of trust with them. Because, like.

385
00:53:22.690 --> 00:53:27.289
Classroom 410: if it's denied, obviously, like, you know, customers would probably be happy. But like

386
00:53:27.360 --> 00:53:31.915
Classroom 410: then I feel like it can only open the door, for like more questions, and, like

387
00:53:32.290 --> 00:53:42.139
Classroom 410: other thoughts that, like these law enforcement agencies can have is like, why aren't they doing that? And like, I feel like we just have a negative reputation as well. So where are you on the statement itself.

388
00:53:42.190 --> 00:53:44.070
Classroom 410: probably, like on the side of

389
00:53:45.250 --> 00:53:47.690
Classroom 410: it. Can. It can be good to that good step?

390
00:53:48.990 --> 00:53:50.050
Classroom 410: More cut?

391
00:53:50.380 --> 00:53:57.909
Classroom 410: I think there's a case to be made for agreeing with this statement, because law enforcement is probably not out there constantly searching

392
00:53:58.330 --> 00:54:09.129
Classroom 410: people's randomly random people's information. You'd think that they'd be going after whatever. But all it takes is one bad apple, so I would fall in the sense. I don't think the 3rd party doctrine under the 4th Amendment should

393
00:54:09.510 --> 00:54:26.560
Classroom 410: allow for warrantless search of people's devices or people's data from 3rd party companies, and the burden shouldn't lie on us as individuals to constantly prove our innocence. The burden should lie on law enforcement to find the probable cause that allows them to execute searches within the like

394
00:54:26.570 --> 00:54:35.879
Classroom 410: bounds of the 4th Amendment, as it was written originally. All right. So we're back to warrant. You know, we need a court. We need a warrant. We need to follow the justice system to compel

395
00:54:36.060 --> 00:54:37.100
Classroom 410: keep going.

396
00:54:37.690 --> 00:54:39.500
Classroom 410: I definitely understand

397
00:54:39.510 --> 00:54:45.060
Classroom 410: that point, and I think where it gets kind of tricky. But when I like, when I saw this question

398
00:54:45.080 --> 00:55:08.049
Classroom 410: last night, I was thinking that if law enforcement is able to like track all of your devices, and that's going to be like publicly known to everyone, it's not like they can do this in secret or secretly have this power. And I was just thinking that it would really kind of harm the law enforcement agencies, because they would probably just get so many more attempted cyber attacks from people who like bad criminals, know they have access to like

399
00:55:08.120 --> 00:55:21.300
Classroom 410: everyone's information. And so it's really going to weaken their own cybersecurity, because we'll have to have so much better cybersecurity to block all the threats that this would just bring to them. This is a fantastic point. Once there's a backdoor.

400
00:55:21.340 --> 00:55:24.610
Classroom 410: there's a back door so can apple open your phones.

401
00:55:25.640 --> 00:55:27.370
Classroom 410: Can they unencrypt your phone?

402
00:55:29.390 --> 00:55:31.190
Classroom 410: Can they?

403
00:55:31.925 --> 00:55:34.479
Classroom 410: Can they unencrypt your icloud storage.

404
00:55:34.560 --> 00:55:37.389
Classroom 410: Yeah, they can do that. Can they get onto your physical device?

405
00:55:38.740 --> 00:55:45.940
Classroom 410: You guys think so. But they cannot. So encryption is encryption. They don't have a magic back door. So Tim Cook.

406
00:55:46.290 --> 00:55:59.930
Classroom 410: when asked about it, is basically saying, You know, this is about the San Bernardino shooting where they compelled Apple to basically unlock a terrorist's phone and Apple said, We can't.

407
00:55:59.950 --> 00:56:02.190
Classroom 410: that we have no way of doing that.

408
00:56:02.570 --> 00:56:09.090
Classroom 410: And we wouldn't do it if we could, because if we open a backdoor to the point made, then there's a back door.

409
00:56:09.240 --> 00:56:16.630
Classroom 410: and that back door is a wicked problem, because it means that it's a backdoor. Once there's 1 backdoor, there's always a way to assist them.

410
00:56:17.750 --> 00:56:24.660
Classroom 410: Neat. Oh, so last question and we'll talk about cyber crime.

411
00:56:26.290 --> 00:56:37.880
Classroom 410: should security researchers. So these are people we actually met one of them that's trying to hack hardware. So if he finds a way to break into something, should he be selling that to the government or law enforcement.

412
00:56:38.570 --> 00:56:43.050
Classroom 410: and doesn't matter which government 1st takes.

413
00:56:44.900 --> 00:57:13.310
Classroom 410: So Joe Grand, who was literally in front of you, showing off how he was hacking hardware. Should he do that? And if he finds something, should he sell it to the Government? I feel it's just kind of like the bug program that we learned how like, where, like some companies like hire people to like search for bugs in their system. So I don't think like researchers should sell the flaws. But the Government, like wanted to hire people to identify flaws. I think that would be like.

414
00:57:13.780 --> 00:57:39.059
Classroom 410: so they can do it. So the and the Government does this. By the way, some of the things that we saw early on in the semester, with not Petya. Those vulnerabilities in windows were found by the Nsa. Found by Tau, found by our offensive security people. And why do they keep them secret? Is so they can use them, you know, for espionage. They can break into machines with these tools.

415
00:57:40.139 --> 00:57:50.050
Classroom 410: Doesn't matter. Let's go back. To which one does it matter which government I sell an exploit to. Should I only sell it to the Us. Or possibly Canada? Probably not Canada

416
00:57:51.520 --> 00:57:57.139
Classroom 410: or can I sell it to Russia or Saudi Arabia or Iran? Does it matter?

417
00:57:57.420 --> 00:58:02.740
Classroom 410: I mean, if I'm selling one of these vulnerabilities, can I sell it to whoever I want to? Whoever's gonna pay me the most?

418
00:58:02.900 --> 00:58:15.530
Classroom 410: I mean, I think it matters depending on what your goal of selling it is like. If you want to make the most money, then you're not gonna only sell it like the Us. Because you'll make more money off of it, selling it to like Russia or China, or someone like that.

419
00:58:16.020 --> 00:58:19.949
Classroom 410: But if you're kind of trying to follow like a moral code. Then you

420
00:58:20.020 --> 00:58:29.719
Classroom 410: probably would want to like sell it to a government that you like more align with, but at the same time kind of all the governments would use it to kind of conduct surveillance on each other. So it's kind of

421
00:58:30.480 --> 00:58:32.300
Classroom 410: what's around each other, right?

422
00:58:32.590 --> 00:58:33.154
Classroom 410: So

423
00:58:34.270 --> 00:58:47.669
Classroom 410: these are wicked problems for a reason they don't have simple answers. I appreciate you talking about it. These devices exist so Apple can't break into your phone. But you know, 3rd party, Israeli companies can

424
00:58:48.248 --> 00:58:54.149
Classroom 410: and they sell these devices to law enforcement so they can break into phones. They

425
00:58:54.220 --> 00:59:01.320
Classroom 410: sell these to governments like Saudi Arabia to break into journalists, funds? All of these things exist.

426
00:59:01.440 --> 00:59:06.810
Classroom 410: So I can break into one apple iphone with a device, one.

427
00:59:07.000 --> 00:59:10.060
Classroom 410: How much do you think it costs to break into that one phone?

428
00:59:11.720 --> 00:59:12.949
Classroom 410: We've got a guess.

429
00:59:13.120 --> 00:59:22.709
Classroom 410: Is it $50? 50 bucks? Alright, anybody high, higher, lower 50 bucks, 1 5,050 bucks.

430
00:59:22.950 --> 00:59:25.692
Classroom 410: Try a hundred, $50,000.

431
00:59:26.708 --> 00:59:31.720
Classroom 410: You know, breaking this, you know, military grade encryption on devices is not easy.

432
00:59:32.020 --> 00:59:37.990
Classroom 410: And so when law enforcement is going to this, they have a really good idea that they're going to find something on a device.

433
00:59:38.409 --> 01:00:02.169
Classroom 410: But these. You know these types of devices. You can go buy them. Now, there's a number of different security research firms that can break into hardware devices like your iphone or your Mac, and how do they do it? They exploit things in the hardware. They exploit vulnerabilities in Bluetooth to gain access to iphones. You know. How do they do it? It's it's hard to say

434
01:00:02.580 --> 01:00:10.090
Classroom 410: it's a reminder. This is exactly what Joe Brand does right? He was sending electro pulses into chips to find vulnerabilities.

435
01:00:10.580 --> 01:00:13.959
Classroom 410: He's doing it to unlock. He was doing it for the power of the good.

436
01:00:14.010 --> 01:00:16.419
Classroom 410: But these are the same types of folks who

437
01:00:16.450 --> 01:00:23.569
Classroom 410: unlock phones for a variety of reasons he was unlocking phones for cryptocurrency. What's the difference here? Right? What's the difference?

438
01:00:23.890 --> 01:00:26.890
Classroom 410: So one Israeli firm is celebrate

439
01:00:27.198 --> 01:00:36.549
Classroom 410: one of the things that law enforcement has to deal with is they can take your phone. They can use one of the things they can break into it, but because the company will never say how they broke into it.

440
01:00:36.620 --> 01:00:39.280
Classroom 410: It's probably not admissible in court.

441
01:00:39.580 --> 01:00:54.720
Classroom 410: And so, even if law enforcement is doing this, they may never actually be able to use that evidence in court, because it was, you know, who's to say they didn't plant that evidence because there's no chain of custody because there's no actual disclosure of how they broke into a phone.

442
01:00:56.343 --> 01:01:08.959
Classroom 410: We would do this. But we're not so just show of hands. I will give up my privacy for free services like email and social media show of hands. Who says, yes, we all do it right.

443
01:01:09.330 --> 01:01:12.260
Classroom 410: I will give up my privacy for my safety.

444
01:01:12.920 --> 01:01:17.149
Classroom 410: So I I'm okay with government surveillance. As long as it keeps me safe.

445
01:01:17.430 --> 01:01:19.569
Classroom 410: raise them high. If that's your answer

446
01:01:19.950 --> 01:01:22.110
Classroom 410: a little less, little less clear.

447
01:01:22.580 --> 01:01:23.450
Classroom 410: Okay.

448
01:01:24.620 --> 01:01:34.260
Classroom 410: alright. Well, thank you all. So we'll turn real quickly into cyber crime. And just some of the facts around cybercrime right now.

449
01:01:34.700 --> 01:01:42.829
Classroom 410: 10.5 trillion dollars annually. That is larger than the damage inflicted by all natural disasters on Earth

450
01:01:43.090 --> 01:01:53.030
Classroom 410: cybercrime. It's pretty amazing, and it's more profitable than all the illicit drug trade. So if any of you are thinking about becoming drug dealers, cybercrime, that's the way to go

451
01:01:54.229 --> 01:02:11.010
Classroom 410: cyber security. We've crossed a trillion dollars part of the reason. As we entered this room back in September, I said, Abe, always be employed. It's because of cyber criminals. So many cyber security professionals because of the bad guys

452
01:02:11.680 --> 01:02:19.540
Classroom 410: and ransomware damages have crested 20 billion dollars in terms of those you know, specific ransomware attacks.

453
01:02:21.250 --> 01:02:36.970
Classroom 410: So who's getting attacked? Well, you might imagine who's getting attacked. But these different organizations are getting attacked in different ways. But basically the store to this Pwc survey is basically everybody's under attack.

454
01:02:37.280 --> 01:02:43.539
Classroom 410: No industry is safe. Everybody has data. Everybody can be subject to mass ransomware

455
01:02:44.850 --> 01:02:47.329
Classroom 410: who are the biggest victims of cybercrime.

456
01:02:47.420 --> 01:02:49.359
Classroom 410: Well, it's the UK,

457
01:02:49.500 --> 01:02:57.590
Classroom 410: really. Yeah. So the Uk has the most prevalence of individuals falling victim to cyber crime. The second, most common

458
01:02:58.250 --> 01:03:05.730
Classroom 410: United States average of $38,000 lost per incident on a personal level

459
01:03:05.970 --> 01:03:08.159
Classroom 410: should give you a little bit of pause.

460
01:03:08.590 --> 01:03:29.000
Classroom 410: Romance scams, which are, I'm sure that some of our grandfathers are falling for that right now. But the idea that there are beautiful young ladies or beautiful young men that really want to be your partner. You just need to send them some money. Sounds funny when you say it out loud. This is a huge, huge problem

461
01:03:29.030 --> 01:03:43.020
Classroom 410: we have in past years when we've had the FBI or secret service in here. That's what they talk about most, because that is how money is being separated, especially from older Americans into some of these romance scams.

462
01:03:44.780 --> 01:04:07.740
Classroom 410: Cyber insurance is going up dramatically spending on cyber insurance. Because, how do we? How do we deal with risk we insure against it. That is a lot of things. If you go into this field there are a lot of cyber risk and audit positions within companies to actually assess you know how we should price cyber insurance based on your cyber security posture

463
01:04:07.900 --> 01:04:18.060
Classroom 410: who has cyber insurance? Well, the Americas. So we are the biggest victims of cyber crime. Right? So we actually spend a lot of money on cyber insurance

464
01:04:19.670 --> 01:04:45.650
Classroom 410: criminal activities. So what are the bad guys doing? Well, we talked about this before in attacks, you know, ransomware distributed Nile of service. 0 day attacks as well as phishing. Lately there is a crypto. Mining is on the rise again, so I can mine cryptocurrency. All I need is cycles on a machine, while I break into lots of machines, and I use that to mine cryptocurrency for me.

465
01:04:45.700 --> 01:04:59.719
Classroom 410: So we've seen over the years. As the price of Bitcoin goes up, we see a lot more cryptocurrency type crime where people are basically breaking into a machine, not for the data on that machine, but the ability to use that machine.

466
01:05:01.460 --> 01:05:05.060
Classroom 410: What's the most common way that companies get breached

467
01:05:08.160 --> 01:05:13.349
Classroom 410: social engineering. Okay, I'm gonna go easier fishing. Right? So fishing.

468
01:05:13.646 --> 01:05:20.039
Classroom 410: So, fishing is the most common way that we get it. You know, we attack the human humans are easier to attack than people.

469
01:05:20.240 --> 01:05:24.179
Classroom 410: Malware incidents are obviously through the roof.

470
01:05:24.370 --> 01:05:29.410
Classroom 410: We talked about ransomware and the dangers posed by ransomware.

471
01:05:30.560 --> 01:05:32.390
Classroom 410: Last year

472
01:05:32.460 --> 01:05:41.969
Classroom 410: last year Chris Krebs was here, so we got a chance to chat with him on a bunch of things. He is the former director of Cisa, who was fired by President Trump via Tweet

473
01:05:42.550 --> 01:05:50.459
Classroom 410: famously. But he talked to me about this, he said. Ransomware is enabled by 3 things. One is.

474
01:05:50.500 --> 01:06:07.130
Classroom 410: you know, vulnerable systems that we've talked about. How do we, the 5 pillars of cyber hiding like? How do we not get compromised? But we need other things. We need the ability to extract value. So if there weren't for digital currencies and untraceable financial transactions, ransomware would exist.

475
01:06:07.290 --> 01:06:22.599
Classroom 410: And then we need a state stable base of operations which, as we'll see in a second, is basically in foreign countries that don't really care if you're attacking different corporations in the United States, because it might actually help our geopolitical.

476
01:06:24.530 --> 01:06:37.590
Classroom 410: This is old, but average breach. These numbers are here, you know, massive numbers associated with breaches and mega breaches. In particular. Mega means that I've lost over a million records which are all too common

477
01:06:39.900 --> 01:06:52.799
Classroom 410: and time to identify. You know these numbers are from earlier in the semester, but people, the bad guys are breaking into systems and they're sitting. They're in the systems for a long time before discovery.

478
01:06:56.270 --> 01:07:00.370
Classroom 410: All right. So where do cyber attacks originate. Who's got a guess?

479
01:07:00.400 --> 01:07:04.679
Classroom 410: What do you think? The number one place for where the bad guys are based?

480
01:07:05.490 --> 01:07:13.109
Classroom 410: China, China? Okay, what else? Russia? Okay? Look Russian China. Yeah, that's 1 and 2.

481
01:07:13.120 --> 01:07:16.209
Classroom 410: Russia is, you know, has

482
01:07:16.310 --> 01:07:23.060
Classroom 410: army units. They're basically part of the government. They also have huge networks of cyber gangs.

483
01:07:23.150 --> 01:07:29.430
Classroom 410: China is more sophisticated. A lot of the hacking that they do is done by government units.

484
01:07:29.460 --> 01:07:35.290
Classroom 410: and so Russia and China are one and 2. We look down the list. It's the usual suspects

485
01:07:35.320 --> 01:07:55.530
Classroom 410: the biggest surprise on the end. Here is the United States. And so a lot of cyber attacks actually originate from the United States, because we have the best infrastructure for attacks like that who has the second best infrastructure in the world. South Korea. So also places to launch things like Ddos attacks because we have lots of ability to do it

486
01:07:57.820 --> 01:08:01.483
Classroom 410: alright. So we're running out of time. So I'll go quick.

487
01:08:02.330 --> 01:08:09.030
Classroom 410: But we're losing about 654,000 records per day companies.

488
01:08:09.615 --> 01:08:18.600
Classroom 410: There are 24,000 mobile apps, malicious mobile apps that are attempted to be posted to the apple and the play store every single day

489
01:08:18.649 --> 01:08:21.179
Classroom 410: that are denied by Google and Apple.

490
01:08:21.630 --> 01:08:24.210
Classroom 410: There are about 3 billion passwords in use.

491
01:08:24.800 --> 01:08:40.399
Classroom 410: 60% of all fraud actually comes from mobile devices. So your mobile device is on your person at all times. You may be just waking up. You may be intoxicated. You always have your mobile device. So it's a great way to attack people.

492
01:08:42.590 --> 01:08:49.220
Classroom 410: And lastly, 0 point 0 5% point 0 5% is the likelihood that a cybercrime

493
01:08:49.350 --> 01:08:51.680
Classroom 410: is detected and prosecuted.

494
01:08:52.569 --> 01:09:01.469
Classroom 410: So one, it's super profitable. Don't go into drug dealing. Go into cyber crime. And 2, you have a very, very low chance of going to jail.

495
01:09:01.870 --> 01:09:05.189
Classroom 410: because there's so much of it. It's not prosecuted in any way.

496
01:09:07.470 --> 01:09:24.120
Classroom 410: So who is fighting cybercrime? Well, the lead is the FBI. So the FBI cares about one thing they don't care about getting you back in business they don't care about, you know, making sure your customers are happy. They care about catching the bad guy.

497
01:09:24.220 --> 01:09:37.149
Classroom 410: So the FBI, when they lead a response, they might actually confiscate all your servers because they want to do forensics on them to catch the bad guy. They do not care about your business operations. They want to catch the bad guys.

498
01:09:37.540 --> 01:09:48.230
Classroom 410: The FBI maintains lists of cyber criminals. These are the most wanted criminals in the world. Our number one here is the guy that created a fake, basically

499
01:09:48.260 --> 01:10:04.980
Classroom 410: a fake application for cleaning off things off your hard drive, you know, when you we talked last time about hey? How do I rid my machine? Well, they have a fake one, and they installed it on hundreds of millions of machines. And so he's the number one cyber criminal in the world

500
01:10:06.140 --> 01:10:23.960
Classroom 410: cat teams so much like cert you heard the hurt teams from Cisa. That is what M. Leads. Cat teams are cyber response teams that are on site within 24 h. If there's a cyber incident, the FBI will be there with all their year, all their forensics, etc.

501
01:10:24.640 --> 01:10:41.090
Classroom 410: So, in addition to the FBI, the Secret Service is majorly involved in cybercrime, because the Secret Service, in addition to protecting the President, is in charge of the money supply. So any interstate commerce, fraud, wire, fraud. All involves the Secret Service.

502
01:10:42.930 --> 01:10:49.079
Classroom 410: There is a 30 agencies partnering together in a cybercrime initiative since 2,008

503
01:10:49.416 --> 01:10:54.790
Classroom 410: these are neat folks. I'd love to talk about them more. But we're almost out of time.

504
01:10:55.490 --> 01:11:02.900
Classroom 410: How do we report a crime? That's important. Before we finish up the semester website.

505
01:11:03.410 --> 01:11:04.799
Classroom 410: go to the website.

506
01:11:05.060 --> 01:11:14.670
Classroom 410: So if you think you're a victim of a cyber crime, you literally go to the FBI's website and you fill out a form that is the best way to get a response from the Federal agencies.

507
01:11:15.602 --> 01:11:29.279
Classroom 410: You can do that with us. Cert with Cisa M's group. You can do that with IC 3, which is the FBI site, you basically file a complaint. I've actually done this because my

508
01:11:29.350 --> 01:11:41.129
Classroom 410: father-in-law was actually victim of a scam. And it's not the most rewarding process. I'll just say it that way. But this is actually how you report crimes

509
01:11:43.760 --> 01:11:54.979
Classroom 410: all right. 2 min left, which is good. So final. Exam. Professor Wright led today talking about it. That's a little bit more detail. Obviously, this is in the slides.

510
01:11:55.150 --> 01:12:00.999
Classroom 410: When I say, Be smart about external resources. It means be organized before you start the exam.

511
01:12:02.066 --> 01:12:03.899
Classroom 410: Everything is open game.

512
01:12:03.990 --> 01:12:18.359
Classroom 410: Every lecture is recorded. It's posted on canvas. All the materials are there. If you want to use external sources, it's fine, but I will warn you that it can cost you time. If you're using resources in a bad way

513
01:12:18.490 --> 01:12:25.000
Classroom 410: you're welcome to use AI or Google. But sometimes that's not going to get you to the answer that you want that time

514
01:12:27.650 --> 01:12:35.450
Classroom 410: cool. 3 more things, one equifax. Second round of payments came out yesterday for anyone affected.

515
01:12:35.910 --> 01:12:44.403
Classroom 410: I got 1 $7 and 44 cents. So I my kids are getting that for Christmas.

516
01:12:45.550 --> 01:13:02.679
Classroom 410: Second point is, course, Evals, please fill out the Eval. You like what we do. You know what we do? We just want your feedback. It's worth a point on the final exam. So everybody that finishes the course. Eval will get an extra point on the final exam

517
01:13:03.330 --> 01:13:05.410
Classroom 410: and stay in touch.

518
01:13:05.560 --> 01:13:18.379
Classroom 410: So we want to, you know, as you've seen from this classroom, you're the you drive this. So you're going to be out in the world. We want to stay in touch with you. Please connect with myself and Professor Wright, because we want to hear about what you're doing in the world.

519
01:13:19.600 --> 01:13:20.690
Classroom 410: Thanks, everybody.

520
01:13:22.990 --> 01:13:23.710
Classroom 410: 14.

521
01:13:28.490 --> 01:13:29.930
Classroom 410: Let's see.

522
01:13:58.894 --> 01:14:19.469
Classroom 410: Yeah, this is fucking hard.

523
01:14:22.342 --> 01:14:39.580
Classroom 410: So I drove back to Bridge.

