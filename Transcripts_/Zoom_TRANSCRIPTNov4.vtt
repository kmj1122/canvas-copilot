WEBVTT

1
00:00:00.120 --> 00:00:07.429
Classroom 410: It was all at the same time who hasn't registered yet.

2
00:00:07.540 --> 00:00:32.379
Classroom 410: Oh, so we do have to be with that really. No, Dracula. On Thursday. I was like, you got into Dracula.

3
00:00:32.380 --> 00:00:43.589
Classroom 410: If you guys have your name tags with you, that'd be great. We have a guest lecture today

4
00:00:43.980 --> 00:00:49.730
Classroom 410: as usual. We're gonna start Monday off by what's coming.

5
00:00:50.212 --> 00:00:58.250
Classroom 410: And this Wednesday is going to be quite a bit different as we move to MoD 3, which is about response.

6
00:00:58.727 --> 00:01:05.340
Classroom 410: Then, anything we've done before. I'll give you a little bit of time. We're gonna go over at the end of this class.

7
00:01:05.459 --> 00:01:07.130
Classroom 410: Exactly.

8
00:01:07.649 --> 00:01:28.929
Classroom 410: What the expectations are for Wednesday, but just a quick heads up. You'll come to this room, and we'll immediately leave the room and go to a breakout room, so don't get too comfortable. With that we are. Gonna do some tabletop simulations, and I'll describe all those things at the end of this particular class

9
00:01:29.000 --> 00:01:44.037
Classroom 410: as well, hey? I got some also some great news. Your group exam is now open. You have until Sunday at midnight to submit your group exam. And you'll see your group exam. Has

10
00:01:44.520 --> 00:01:59.939
Classroom 410: Like, I said, some questions, some answers to chat, Gpt answers to those questions. And you're gonna tell me the reasons why that is all incorrect, and what the right way to think about things are. For those particular things. So

11
00:02:00.269 --> 00:02:15.760
Classroom 410: yeah, if you have any questions about the group. Exam. Please let me know. Make sure at least 5 spots today, and I'll have. We'll get out a little bit early today that you'll coordinate with your team. So you know, when you're taking that exam. Okay.

12
00:02:15.760 --> 00:02:34.099
Classroom 410: as far as that's concerned. And like, I said, we're transitioning to the 3rd and final module as well. When we move to that, your next case discussion is a week today. Similar format. You'll submit answers to 3 questions

13
00:02:34.484 --> 00:02:56.009
Classroom 410: for that, and then I'm going to do a little warm calling. So we went through this morning. We read through some answers. There's some interesting stuff that you all have. So be prepared. To talk about the answers that you submitted the case study today, and for sure again on next Monday as well.

14
00:02:56.670 --> 00:02:59.560
Classroom 410: Any questions about

15
00:03:00.010 --> 00:03:07.089
Classroom 410: what's new, what's coming? All these things? And the main piece is that group exam.

16
00:03:09.040 --> 00:03:12.270
Classroom 410: same thing. It's 2 h.

17
00:03:12.400 --> 00:03:15.709
Classroom 410: Got 2 h to do it. There's 3 questions.

18
00:03:19.870 --> 00:03:30.399
Classroom 410: any other questions we good. You feel good about the group exams. Now you know what you're getting yourself into, Nicole. Is the group exam like open note go crazy.

19
00:03:30.440 --> 00:03:31.306
Classroom 410: We're crazy.

20
00:03:31.910 --> 00:04:01.489
Classroom 410: Yeah, I'll tell you 2 things that aren't going to be very helpful on this, because I provide all the chat, Gpt answers, and Gemini answers on this, so running those again, which I clearly have done through Chat gpt, and say, How are you? Answer this, I would say when just ballparking it. Grade is like A B minus answer. So if you like, B minuses, go have fun. Stick that answer in. We're Mcintyre students. We don't like B minus answers to things. So

21
00:04:01.520 --> 00:04:11.409
Classroom 410: that's probably not going to be super helpful. But org the the hot tip for all of this is, organize your notes

22
00:04:11.440 --> 00:04:14.169
Classroom 410: and divide and conquer the exam.

23
00:04:14.350 --> 00:04:31.249
Classroom 410: Right? So you don't have 5 people staring at one question, trying to answer the same thing at the same time, is it inefficient use? This is a team exercise where you put it in a bit of a pressure situation, where your abilities to answer it, and then validate. It is probably the correct approach

24
00:04:32.000 --> 00:04:33.209
Classroom 410: that make sense

25
00:04:36.130 --> 00:04:39.090
Classroom 410: any other questions. Good question, Nicole.

26
00:04:40.650 --> 00:04:42.080
Classroom 410: Are you feeling good?

27
00:04:42.380 --> 00:04:49.741
Classroom 410: Alright! It's that time of year. I'm sure you're bombarded with a million things to do.

28
00:04:50.240 --> 00:05:00.032
Classroom 410: as well. Let me pull up the slides. We'll do a quick review of some of our topics that we talked about last week.

29
00:05:00.480 --> 00:05:06.400
Classroom 410: And then I want to introduce a couple guests that we have here that we can kick off our case on social engineering.

30
00:05:06.520 --> 00:05:09.170
Classroom 410: So let's do some

31
00:05:11.130 --> 00:05:37.870
Classroom 410: quick review of the 2 kind of topics. When we walk through this, we talked at length about cybersecurity training, and looked at all the current research regarding cybersecurity training. And then we had Carrie Pearlson from Mit come in and talk about cybersecurity, resilience, what that means and how to think about that as well. So who can give me that? Maybe one or 2 takeaways that they learned about cybersecurity training

32
00:05:38.500 --> 00:05:39.840
Classroom 410: from last week.

33
00:05:40.370 --> 00:06:01.250
Classroom 410: Yeah, Neil, I think the big piece was like the values, attitudes, beliefs so like being able to like create mechanisms around that like, just I don't know. Having that framework in mind, I think was helpful. Yeah, what do we call that? It's culture, right? It's like, how do you build culture in a systematic way, thinking about values, attitudes and beliefs. Yeah, that's helpful. Yeah.

34
00:06:01.645 --> 00:06:06.130
Classroom 410: mindfulness. Training is often a lot more valuable than rules based training. Yeah.

35
00:06:06.790 --> 00:06:17.010
Classroom 410: absolutely so. If you had to tell your grandma what mindfulness training is, would you say? Just taking a minute to stop and think when you're posed with like a potential security risk.

36
00:06:17.180 --> 00:06:30.469
Classroom 410: Yeah, rather than hey, I gotta remember these 15 rules that I'm not gonna remember, right, Patrick. Like group training is important where you kind of create like a shared responsibility within an organization with departments.

37
00:06:30.700 --> 00:06:49.159
Classroom 410: Yeah, so training for a specific individual to do a specific thing works. Okay? But if we really want to take approach, we create a culture around cybersecurity that involves some part of your team. And Anonym Marley, I got you next.

38
00:06:49.160 --> 00:07:05.469
Classroom 410: Yeah, if you do the phishing simulations incorrectly, they'll actually create their counter to the culture you're trying to create and to the not only cyber security culture but organizational culture.

39
00:07:05.780 --> 00:07:17.939
Classroom 410: So when we showed you evidence of the studies we've done, of how bad they could be and how they could destroy not only the relationship with the cybersecurity unit. But the relationship with the organization, if not done correctly.

40
00:07:18.090 --> 00:07:26.899
Classroom 410: that's what I was going to say. But also, I guess, to that point instead, gamifying it and adding rewards instead of just shaping.

41
00:07:27.910 --> 00:07:33.700
Classroom 410: Yeah, so gamifying, it works right? So we should all put shame boards on. Is that what you learned

42
00:07:33.860 --> 00:07:45.709
Classroom 410: no shame, boards. We don't know, because that study never got completed. So maybe shame boards work really really well. Etc. Good. Any last words, Matt is out of hand. Or is that just?

43
00:07:47.030 --> 00:07:49.309
Classroom 410: That's his thoughts. Anything

44
00:07:51.250 --> 00:08:11.279
Classroom 410: you feel like you're getting a grasp around this stuff and that. You can start thinking about it and designing it. We're going to talk about response as well. But so last semester Kylie Nagel and I wrote a case on the human factor that consisted of

45
00:08:11.300 --> 00:08:30.630
Classroom 410: several lengthy interviews. I think, as we figured out what this meant at Uva in particular, so I have her here to introduce herself she is. How many months now are you at Pwc. I think I'm like 2 and a half, 2 and a half months at Pwc.

46
00:08:30.810 --> 00:08:41.639
Classroom 410: I think Kylie sat in Carter's seat last year. Does that sound right? We used to switch every single class. Oh, of course, everyone would like come in early and try and take the seats on the end.

47
00:08:41.679 --> 00:08:50.640
Classroom 410: Yeah, the there, there! This this class is much more well behaved. as well, but maybe a quick introduction of yourself.

48
00:08:50.994 --> 00:08:57.190
Classroom 410: Would be great. Yeah, I'm kylie. I graduated last year from Com. I did it and business analytics.

49
00:08:57.290 --> 00:09:00.569
Classroom 410: And then, yeah, like Professor Wright said last semester.

50
00:09:00.820 --> 00:09:02.829
Classroom 410: yeah, I read this case with him.

51
00:09:02.890 --> 00:09:17.529
Classroom 410: I work at Pwc, I'm in the cyber section cyber sector there, and I'm in strategy, risk, and compliance. So I'm doing a lot of things that are similar to this class, specifically like what we're learning about today. So yeah, we have another guest. I'll let you introduce yourself.

52
00:09:17.650 --> 00:09:47.119
Classroom 410: Hi, everybody! My name is Thomas Sumner. I'm the Pwc. Recruiter for Uva. Thanks to Professors Wright and Professors Lewis for bringing Pwc. In today. Candidly, I just happen to be in town. And I was like, Oh, I want to be a fly on the wall for this one. Hear more about pilot research. But you know also, if you'd like to chat with a recruiter after the class today, feel free to come, hang out would love to chat with y'all, as I'm sure you know. Pwc. Started as an accounting firm. But really now we do

53
00:09:47.120 --> 00:10:14.620
Classroom 410: accounting, and just about seems like everything else. And so we really have to be at the cutting edge when it comes to cybersecurity for our clients. And I think you'll get to hear a bit about that from Kylie as Wednesday. So thanks again for Thomas. Maybe your connection to Mcintyre would be, oh, yeah, that's true. This is not my 1st time in this classroom. I graduated in 2019.

54
00:10:14.620 --> 00:10:25.840
Classroom 410: I was not an it concentration I did accounting and management. But I do have some memories in this classroom. So it's really fun to be back. Yeah, thanks for thanks for joining us

55
00:10:25.970 --> 00:10:49.459
Classroom 410: as well. So maybe, Kylie, come on, step out here. You could talk about how we started this project and the case, yeah, and how it went before we dive in. So, Professor, you had the data set that you collected more of like academic research. And then from there we took that. And we read through tons of like the Verizon Data Breach report and a ton of different online materials.

56
00:10:49.460 --> 00:10:59.436
Classroom 410: We interviewed Jason Belford, who was the former, says at the time, and then most of the interview feel like we just went back and forth with him.

57
00:10:59.930 --> 00:11:04.290
Classroom 410: yeah, we put this together. We also compiled the data set that you guys all got.

58
00:11:04.300 --> 00:11:06.459
Classroom 410: we slim that down.

59
00:11:06.590 --> 00:11:09.489
Classroom 410: And yeah, we just kind of went from there and

60
00:11:09.850 --> 00:11:12.910
Classroom 410: dug into like the research of breaches in education.

61
00:11:13.240 --> 00:11:31.430
Classroom 410: I think it was fun for us, looking at all your answers to the data set that we created to, and how you approached it, because, as I told Kylie, we gave you no guidance on how to analyze it. We just said, here's some stuff let's see what you come up with. So there's some interesting things that we're going to call out on.

62
00:11:31.430 --> 00:11:50.939
Classroom 410: So. As Kylie said, Jason Belfort was our primary contact for that we had some other people in this. The security team. I think he's the Ciso. Is that right? The city of Alexandria right now as well. He came from us from Georgia Tech, so he helped us, informed a lot about this.

63
00:11:50.950 --> 00:12:14.769
Classroom 410: The budget for security is around 6 million, but as it bleeds into over into it, and what it is, and what cyber security is. That's a fuzzy number as well, because you can't do it without doing security. But the the team here owns policies. They own education. They own incident tracking.

64
00:12:14.770 --> 00:12:30.499
Classroom 410: They own safeguard implementation about what are the guidelines which we know about, which are different than policies, etc. And then the risk assessment which we're going to get to exactly how to do the risk assessment. And those types of things

65
00:12:30.640 --> 00:12:43.630
Classroom 410: think next week is when we're going to get into that right after the Phoenix Project, which we'll talk about as well. So maybe we can start out with the softball questions, the kind of a warm up for the class.

66
00:12:43.790 --> 00:12:47.819
Classroom 410: And you can talk about why

67
00:12:48.050 --> 00:12:57.700
Classroom 410: is higher education, a consistent target, at least one of the top 2 targets in the last 3 years for cybersecurity, criminals and nation State actors.

68
00:12:58.220 --> 00:12:59.510
Classroom 410: Why is that happening.

69
00:13:00.620 --> 00:13:11.539
Classroom 410: I feel like, because at a lot of higher educations there's a lot of new research that's being found and developed. So if you can have access to that.

70
00:13:11.820 --> 00:13:17.860
Classroom 410: It's just like, I don't. Just the type of information can be very useful for criminals to like. I don't know, sell or exploit.

71
00:13:18.180 --> 00:13:24.579
Classroom 410: Yeah. So we have 750 million dollars in research expenditures at this university

72
00:13:24.590 --> 00:13:31.990
Classroom 410: with the goal of having 1 billion dollars spent on research in the next 5 years. That's considerable, right? That's a top

73
00:13:32.060 --> 00:13:38.760
Classroom 410: tier research institution as well. So I had Marley and Silvani after

74
00:13:39.381 --> 00:13:45.979
Classroom 410: it. They're decentralized. So it kinda makes it easier to get into the systems.

75
00:13:46.700 --> 00:13:53.255
Classroom 410: Yeah, we we are completely decentralized as Professor Lewis. I was gonna say that adding on to that

76
00:13:53.690 --> 00:13:58.099
Classroom 410: Also, there's like lots of connections to 3rd party vendors, and that kind of allows.

77
00:13:58.110 --> 00:14:14.430
Classroom 410: maybe not easier access, but some other ways of access. And if those vendors aren't as secure and don't have the same policies that Uva does. Then, you know, bad actors could still get in that way. Yeah, absolutely. In addition to the valuable research data. There's a lot of recently identifiable

78
00:14:14.450 --> 00:14:29.519
Classroom 410: alumni doctors think about all the cool data that's that we store medical records like financial records. We have it all.

79
00:14:29.630 --> 00:14:32.829
Classroom 410: We're like experian. But for higher Ed, right

80
00:14:32.960 --> 00:15:00.710
Classroom 410: as well. So another thing that's really interesting is, we have to have kind of loose but tight security in higher Ed. What I mean by loose but tight is, we have labs that people can walk in and access computers. Not many organizations have that ability, or you can go around and plug things into the wall or connect to a Wi-fi. If you can imagine a company like Apple like they don't even let you on on their campus.

81
00:15:00.860 --> 00:15:24.849
Classroom 410: let alone connect to their network. Do all this stuff. It is hard to control these environments. So there's a lot of vectors for those particular attacks in higher Ed, right? So one of the reasons that I've done a couple studies on Higher Ed, and why they're interesting is because they also have the most interesting attacks. So social engineering which we're going to talk about today.

82
00:15:24.850 --> 00:15:50.300
Classroom 410: And it's still the number one threat factor, as we know, for infrastructure, also for higher Ed. But we're also going to talk about another attack that happened in 2015. That was a fascinating attack, and you'll read about that in the Phoenix project and the response, when we start talking about, how do you respond to this? What does project management look like, what does risk assessment look like all these types of things?

83
00:15:50.510 --> 00:16:05.759
Classroom 410: So the things that are out there that we categorized in the case just a quick reminder things like unpatched servers. 0 day exploits social engineering. Of course we don't have any unpatched servers, do we, Professor Lewis?

84
00:16:06.230 --> 00:16:09.220
Classroom 410: Why can somebody remind me why

85
00:16:09.260 --> 00:16:12.950
Classroom 410: why we don't patch things the day the patch comes out.

86
00:16:15.110 --> 00:16:15.950
Classroom 410: Haley.

87
00:16:16.516 --> 00:16:37.720
Classroom 410: The patch itself can cause problems as well as you have to have downtime for patching, and it might not actually help. Yeah, I call that like, it's a pain in the ass to do Patch right because it breaks things. It takes time. You're not sure what it's going to do. And what's our famous patch story that took down Delta Airlines and others

88
00:16:38.060 --> 00:16:53.830
Classroom 410: crowdstriking right like that is a famous story about patching gone bad as well. Yeah, another thing about patching, especially in higher education, is because each business unit is silent from each other. You can't implement like a top down centralized patching

89
00:16:54.030 --> 00:16:57.510
Classroom 410: mechanism, because every business unit is separated.

90
00:16:57.840 --> 00:17:21.060
Classroom 410: Yeah, it's it's it's hard. It's easy to say, it's just like we're going to talk about this concept called 0 trust is like, why doesn't everybody do 0 trust? It's super secure because it breaks everything. And it's really really hard and the same thing in terms of patch management as well. So we also talked in the case about spear phishing more non personalized phishing. This thing called 2 factor Fatigue.

91
00:17:21.060 --> 00:17:34.500
Classroom 410: I've actually done a research study in 2 factor fatigue with an institution that half the people got 2 factor authentication. Half the people at this organization did not just to see what would happen, and what we found is.

92
00:17:34.720 --> 00:17:52.179
Classroom 410: there was a high propensity to start doing workarounds with people with 2 factor authentication. So rather than going on their trusted servers on their Microsoft onedrive, or whatever they would just start using Dropbox and Google drive because it was easier to access, and I could get there via link.

93
00:17:52.420 --> 00:18:00.929
Classroom 410: So there are these things like security, fatigue that changes user behaviors as well.

94
00:18:01.190 --> 00:18:22.679
Classroom 410: And then, if we look at the numbers. And this is from a recent article that came out this underscores like what this underscores? Yeah, the hackers are actually pretty good at getting into higher places. Just that trend line we're looking at 2020. We had 200 reported

95
00:18:22.680 --> 00:18:34.249
Classroom 410: public breaches were close to a thousand. By the end of this year per year of of breaches. That's a lot of things in higher education.

96
00:18:34.410 --> 00:18:43.039
Classroom 410: And then you look at the ways that these breaches are going into. It's the good old fashioned things that you all know about that we've talked in this class about

97
00:18:43.170 --> 00:18:44.710
Classroom 410: weak passwords.

98
00:18:45.800 --> 00:18:58.159
Classroom 410: data breaches like a general category that includes phishing and some other things. SQL, injections file upload all the stuff we've talked about. The main vectors of attack.

99
00:18:58.350 --> 00:19:08.909
Classroom 410: Attack. So why we passwords does somebody want to remind me that? Why, that continues to be a vulnerability. What's going on here? Who cares if my password is Princess one

100
00:19:12.040 --> 00:19:17.020
Classroom 410: which is one of the top 20 passwords just wasn't randomly came out of my head. By the way.

101
00:19:17.520 --> 00:19:19.550
Classroom 410: who cares if I have a weak password?

102
00:19:21.640 --> 00:19:22.900
Classroom 410: Why do you care?

103
00:19:25.450 --> 00:19:26.760
Classroom 410: You don't care.

104
00:19:30.470 --> 00:19:38.339
Classroom 410: What are we? Yeah, common packers stored password so they can just like try to enforce attack. And then also confident policies don't really align with

105
00:19:38.630 --> 00:19:44.749
Classroom 410: the new best practices under. This is where we just like change one character, or change every 30 days. That's everything.

106
00:19:44.850 --> 00:19:55.779
Classroom 410: Make us more secure. That's right. Like. They probably stolen our password from other accounts, which is another definition of a we password. So Bryce gets his password stolen from

107
00:19:56.050 --> 00:20:19.190
Classroom 410: Yahoo sports, and it's the same password is using for Uva. That's an easy one. That's a common common type of weak password attack. The other one is Princess. One is already a breach password. I can look that up, even if I have the hash value. I can look that up right because I can hash Princess one. It's the same hash that we have that we've talked about. So I can reuse that. And I can identify

108
00:20:19.725 --> 00:20:26.860
Classroom 410: username and passwords from that. So all sorts of this. So what are the mitigation

109
00:20:26.940 --> 00:20:31.249
Classroom 410: techniques? What are some of the things that we've talked about in this class

110
00:20:31.610 --> 00:20:34.239
Classroom 410: that mitigate this list of things?

111
00:20:34.450 --> 00:20:38.350
Classroom 410: And then I'm curious to hear from Kylie about what what they're

112
00:20:38.480 --> 00:20:40.279
Classroom 410: but they're talking about in the wild.

113
00:20:44.070 --> 00:20:47.969
Classroom 410: What are some ways, all these different attacks? What are some ways that we've learned

114
00:20:48.320 --> 00:20:49.780
Classroom 410: that we can mitigate

115
00:20:50.070 --> 00:20:51.350
Classroom 410: these attacks.

116
00:20:52.850 --> 00:21:02.339
Classroom 410: Yeah, you know, I guess, with passwords like the having a password manager. I know it's more like on an individual level compared to organization. But being able to implement that

117
00:21:02.370 --> 00:21:05.769
Classroom 410: like all employees, students, etc, just making things easier.

118
00:21:06.090 --> 00:21:10.479
Classroom 410: Yeah, if we were to set a password policy, what would it look like?

119
00:21:12.170 --> 00:21:13.580
Classroom 410: What do you think it would look like?

120
00:21:13.970 --> 00:21:14.870
Classroom 410: Yeah, Matt.

121
00:21:15.390 --> 00:21:19.910
Classroom 410: There'll be pass phrases as opposed to words like focus on

122
00:21:20.120 --> 00:21:21.120
Classroom 410: the actual

123
00:21:21.420 --> 00:21:27.362
Classroom 410: phrase, those words, because the words are easier to use like a brute force with the dictionary, as Kyle mentioned.

124
00:21:28.110 --> 00:21:45.019
Classroom 410: and you wouldn't change it nearly as much as you may, wouldn't change it right? Which is counterproductive. Yeah, so quick changes. And you probably look it up against a list of reach passwords to say, Oh, Princess, one that's probably not a good password, because they already know that

125
00:21:45.030 --> 00:21:50.669
Classroom 410: type of account. So passwords is absolutely a mitigation technique. What's that? What's some other ones?

126
00:21:52.390 --> 00:21:59.910
Classroom 410: Yeah, correct multi-factor authentication. Yeah. Mfa, you may make you're gonna make Professor Lewis cry here, this is good.

127
00:22:00.490 --> 00:22:03.699
Classroom 410: Multi factor. I don't think I need to describe that.

128
00:22:04.190 --> 00:22:05.160
Classroom 410: What else?

129
00:22:06.550 --> 00:22:09.519
Classroom 410: There's only 2. We got to 2. And now we're good.

130
00:22:09.770 --> 00:22:11.449
Classroom 410: Yeah. Ask case.

131
00:22:11.530 --> 00:22:21.290
Classroom 410: Yeah. So get away from the concept of that as well. Who uses pass keys on their apple or Google device just out of curiosity.

132
00:22:23.310 --> 00:22:24.600
Classroom 410: We got 2.

133
00:22:24.960 --> 00:22:27.639
Classroom 410: Take a look at Paskey's people. It

134
00:22:27.750 --> 00:22:31.310
Classroom 410: it's a game changer in terms of password management.

135
00:22:32.252 --> 00:22:35.517
Classroom 410: It attaches a local password.

136
00:22:36.460 --> 00:22:46.440
Classroom 410: so you don't have to recreate. That is basically unhackable. I shouldn't say, basically, it's near nearly unhackable. Never say never in terms of that Dana

137
00:22:47.880 --> 00:22:50.809
Classroom 410: Instead of having an arrow that shows

138
00:22:50.910 --> 00:22:57.789
Classroom 410: the password you chose this week happened so that it came up in a data breach. Be specific with your users.

139
00:23:02.150 --> 00:23:04.490
Classroom 410: There's a couple other ones to think about

140
00:23:04.830 --> 00:23:05.710
Classroom 410: right

141
00:23:05.910 --> 00:23:08.320
Classroom 410: like we talked about this, the 1st steps.

142
00:23:08.390 --> 00:23:16.590
Classroom 410: understanding your assets, understanding your policies. That type of work is important work as we move forward. So that was a.

143
00:23:17.140 --> 00:23:25.439
Classroom 410: you know, least privileges, you know the 5 pillars. So what are the 5 pillars? Just as a reminder? Because you need to know for your group. Exam. Anyways.

144
00:23:25.990 --> 00:23:27.689
Classroom 410: you guys remember the 5 pillars.

145
00:23:28.770 --> 00:23:40.339
Classroom 410: Now you're going to hurt Professor Lewis's feeling, Neil. Identify, protect, detect, respond, and recover. So that's NIST. Those are the 5 things in NIST. 5 pillars starts with least privileges.

146
00:23:40.710 --> 00:23:45.099
Classroom 410: Network segmentation. What else we got? Encryption, encryption.

147
00:23:45.490 --> 00:23:48.059
Classroom 410: There we go. What are the other 2

148
00:23:48.150 --> 00:23:52.849
Classroom 410: patching Mfa. And the one I like to add.

149
00:23:53.190 --> 00:23:54.910
Classroom 410: it's coastal engineering, right?

150
00:23:55.520 --> 00:23:56.280
Classroom 410: So good.

151
00:23:58.330 --> 00:23:59.560
Classroom 410: good, good, good.

152
00:23:59.660 --> 00:24:16.509
Classroom 410: So we've never been breached before. Right at Uva. Now we're we're constantly. In fact, we had a couple of bad ones, a close call and a bad one last year. Are you allowed to talk about the one in 2023 yet, are you still? What's that? You're writing a case on it? So

153
00:24:17.780 --> 00:24:20.999
Classroom 410: they maybe give the 30 second

154
00:24:21.530 --> 00:24:30.540
Classroom 410: case preview on that on that breach last year that everybody was freaked out about. Sure. We have a decentralized environment. The

155
00:24:31.870 --> 00:24:44.720
Classroom 410: I'll see. The bookstore was running a VPN server as a result that became a vector for attack that required all of you to change because they stole the credentials for a huge number of phone

156
00:24:44.740 --> 00:24:53.720
Classroom 410: Eba people. And so all of you had to change your password in the summer of 2023. If you were here because of that targeted attack

157
00:24:54.010 --> 00:25:02.337
Classroom 410: that basically took a huge volume of hash passwords off our environment. Why is the bookstore running a VPN. Why is the bookstore

158
00:25:02.900 --> 00:25:24.129
Classroom 410: goes back to know what's on your network, right? It's so critical on how to do this. So we had a web application that exposed some pii. We had hackers infiltrate, and we'll talk about this one in the next case, which is fascinating as well.

159
00:25:24.130 --> 00:25:52.890
Classroom 410: We had some social engineering done where they stole their tax documents, and they were so nice. They even filed their taxes for these people. That was really nice of these criminals. That's a common type of attack. We had a close call with some encrypted password, information being exposed, and then the case that so this is like an ongoing battle. So one of the questions I asked you, and then we're going to get Kylie's perspective from her work at Pwc.

160
00:25:53.050 --> 00:25:53.745
Classroom 410: Is.

161
00:25:54.490 --> 00:25:59.929
Classroom 410: should this information what what should these priorities be in the upcoming months. Given

162
00:26:00.070 --> 00:26:04.719
Classroom 410: what you read about this. So there's a couple couple answers that I wanna

163
00:26:04.860 --> 00:26:25.239
Classroom 410: want to start us off with. I thought we're really interested, but then invite, invite other folks as well. So, Bryce, you talked about this in terms of security teams, priorities, maybe. Give a snippet of your particular answer, and then, Claire, I'm coming to you next. Okay, I was saying that they should look over like.

164
00:26:25.290 --> 00:26:29.209
Classroom 410: who's the highest at risk here on campus and basically segment them

165
00:26:29.330 --> 00:26:35.389
Classroom 410: from everyone else, and basically cater their training their form of training to help

166
00:26:35.980 --> 00:26:43.490
Classroom 410: make them less at risk going forward. I guess the best way to put it and also implement things like the phishing button on emails, especially in a space like this, where

167
00:26:43.500 --> 00:27:00.870
Classroom 410: a lot of us are looking for jobs on Linkedin handshake. And there's a lot of scare phishing that happens on those platforms. So finding ways to have platforms where people can notify if they have phishing emails that are being sent to them or other forms of cyber security breaches. Yeah, really interesting is identifying

168
00:27:01.000 --> 00:27:06.740
Classroom 410: the high risk individuals which we did a little bit about in the data analysis, and we'll get to that

169
00:27:06.790 --> 00:27:07.989
Classroom 410: as well.

170
00:27:08.020 --> 00:27:18.419
Classroom 410: Claire, jumping off on that. Yeah. So I talked about how, in the case. Belford mentioned his shift from prevention to resilience mindset. And so I said, in the upcoming months

171
00:27:18.440 --> 00:27:36.440
Classroom 410: he needed to kind of expand on that and build it out more through, like the fact that the biggest weakness so far has been the human factor of like just people being naive with the different attacks. And so I said that they should enhance, like the human knowledge, to resist the attacks through kind of what we talked about with the mindfulness

172
00:27:36.470 --> 00:27:42.830
Classroom 410: learning current. You're technically using training and non punitive

173
00:27:42.860 --> 00:27:54.659
Classroom 410: simulations. But I said that that could be done through a team wide approach instead of just individual approach and they should just leverage those group dynamics to grow as a team rather than individuals. Yeah.

174
00:27:54.810 --> 00:28:03.659
Classroom 410: So you're building off a Neil's comment about attitudes and values. And we're really, you're really talking about culture, right in all those

175
00:28:03.690 --> 00:28:20.309
Classroom 410: all those things. So let me open it up. And then I want to hear our Pwc. Expertise in the room. No pressure 2 and a half months. You should be able to nail it for sure. Other thoughts about the team priorities that haven't been mentioned by Bryce or Claire

176
00:28:20.430 --> 00:28:47.400
Classroom 410: that you thought was interesting. Yeah, Marley, I think just the fact that the training isn't mandatory kind of sends a signal that it's not important. And obviously, we talked about that a lot of training doesn't actually do anything. So that's like that's important to consider. But just the fact that it's not mandatory at all like gives people a reason to not really care about it. So if there was a way to make the training

177
00:28:47.480 --> 00:28:54.660
Classroom 410: kind of about like this more mindful approach. But then also have people that are required to do it. I think that's really important.

178
00:28:55.140 --> 00:28:59.400
Classroom 410: Yeah. So how many? What was the percentage of people that fell for

179
00:28:59.680 --> 00:29:03.130
Classroom 410: on average, the simulated messages and data set one.

180
00:29:04.830 --> 00:29:09.069
Classroom 410: You gotta remind me because I don't remember. But I can look it up if you want. Can somebody help me out here?

181
00:29:09.410 --> 00:29:10.950
Classroom 410: What was that percentage?

182
00:29:13.020 --> 00:29:14.708
Classroom 410: You don't remember either?

183
00:29:15.140 --> 00:29:19.210
Classroom 410: What? Yeah, 12.3 7%.

184
00:29:19.350 --> 00:29:23.750
Classroom 410: Yeah, like 13%. Does that sound right? That's everybody

185
00:29:23.900 --> 00:29:27.369
Classroom 410: about 13%. Does that surprise you? All

186
00:29:27.560 --> 00:29:32.420
Classroom 410: 30% click rate at a university? If that's high, you think that's low?

187
00:29:35.700 --> 00:29:37.349
Classroom 410: You have no idea.

188
00:29:38.990 --> 00:29:43.260
Classroom 410: We think, Bryce, relative to the number of people that are here on grounds. I think it's

189
00:29:43.400 --> 00:29:46.539
Classroom 410: fairly odd, because that's about 1,000 plus people.

190
00:29:46.770 --> 00:29:50.789
Classroom 410: So it's a lot of people that clicked on these messages.

191
00:29:52.790 --> 00:29:55.750
Classroom 410: Yeah, do you guys remember when I showed you.

192
00:29:56.390 --> 00:30:00.130
Classroom 410: you know, over the course of the last 2 decades. What the average was.

193
00:30:00.240 --> 00:30:04.500
Classroom 410: It's a little under the average of like 1518% range.

194
00:30:04.730 --> 00:30:06.200
Classroom 410: which is interesting.

195
00:30:07.440 --> 00:30:09.699
Classroom 410: we'll get into the data analysis.

196
00:30:09.830 --> 00:30:14.199
Classroom 410: Anybody else want to add anything about the security team's priorities before we

197
00:30:14.970 --> 00:30:16.506
Classroom 410: talk to the consultants?

198
00:30:20.570 --> 00:30:21.380
Classroom 410: Yeah.

199
00:30:21.988 --> 00:30:28.610
Classroom 410: One thing I thought was interesting was that, like they had the breach with like the 3rd party

200
00:30:28.930 --> 00:30:37.049
Classroom 410: that runs like the trainings, like the drug and alcohol training, and then has kind of proceeded to still offer and mandate that training and not bring in

201
00:30:37.080 --> 00:30:40.669
Classroom 410: some of those materials can house or create the modules themselves.

202
00:30:41.040 --> 00:30:45.099
Classroom 410: Yeah, mandated training works really, really? Well, right? That's

203
00:30:45.320 --> 00:30:50.510
Classroom 410: we talked about that. We're all been mandated. Well, the majority of us in this classroom at some point.

204
00:30:50.570 --> 00:30:54.561
Classroom 410: and that creates a different kind of atmosphere.

205
00:30:55.410 --> 00:31:00.629
Classroom 410: but you need to do training. So we're gonna talk more about that exactly how you walk that

206
00:31:00.650 --> 00:31:02.560
Classroom 410: fine line as well.

207
00:31:03.060 --> 00:31:21.439
Classroom 410: so do you want to talk a little bit about your work at Pwc, and how this lines up to this question, yeah. So at Pwc, like, I said, I sit in strategy, risk, and compliance, which, if you look at this, this is everything that sector does so honestly. It's pretty similar to this class like it's

208
00:31:21.470 --> 00:31:31.339
Classroom 410: almost it's all non technical. And it's really similar to like just looking at what puts a company at risk to breaches to any type of like a threat that could come in.

209
00:31:32.200 --> 00:31:32.960
Classroom 410: So

210
00:31:33.300 --> 00:31:55.439
Classroom 410: so what I'm doing? Sorry I'm doing international risk assessments at a major bank. So what I'm doing is with all their 3rd party vendors in actually India. Right now, we're looking at each one and then generating risks that could be identified by working with these vendors. So like, for example, we're working with another consulting. Or we're working to like, assess another

211
00:31:55.957 --> 00:32:07.770
Classroom 410: consulting firm. That's in India right now, that's helping them to like, build out their anti money, laundering bots so like they scan messages and make sure that there's nothing fraudulent going on.

212
00:32:07.810 --> 00:32:33.890
Classroom 410: And so what we're doing is generating risk. Like, do they have the correct access controls in place like what access like, they're called lock levels. But it's like, what level of access do they have in the systems? So that's going to going back to least privilege. And then, wherever there is a risk that we identify, we find mitigations by working with the 3rd party, by working with the people with inside my client to make sure that everything is mitigated.

213
00:32:34.162 --> 00:32:54.589
Classroom 410: Yeah. And there's a ton of other work that goes on. That's kind of like this, for example, like what lines up to this class like a partner in my practice team. He just got hired by another major firm that had to fire their Ciso, and he went to this firm alone, like through Pwc. But to act as their Ciso. So there's a lot of cool work that goes on with cyber strategy.

214
00:32:54.700 --> 00:33:02.580
Classroom 410: And yeah, is there anything else that? Yeah, any questions about that particular work that might be helpful. We can continue the conversation

215
00:33:03.900 --> 00:33:04.900
Classroom 410: as well.

216
00:33:05.020 --> 00:33:07.390
Classroom 410: I have a little bit more, yeah, but

217
00:33:07.860 --> 00:33:10.010
Classroom 410: or on the next slide.

218
00:33:10.620 --> 00:33:33.390
Classroom 410: So let's talk about the second question, and I got a couple of interesting answers. Kyle, can we start with your answer about notifications and bid preferences? I thought that was interesting, maybe. Tell us what that is, and why you think that's the right way to go when you talk about organizational resilience. Sure. So most public institutions. When they contract out work

219
00:33:33.390 --> 00:33:42.170
Classroom 410: they run an auction. So it's a if anybody's an Econ major, there's a class called auction theory and practice that needs to be taught, and so still is.

220
00:33:42.300 --> 00:33:43.350
Classroom 410: Yeah, no.

221
00:33:43.510 --> 00:34:03.879
Classroom 410: I think it just took us a year off. It's it's coming next year. That's not helpful for you right now. So there's basically, companies will bid on projects. And they're always like, 1st price, low bid options. So whoever can get the job done the best at the lowest price, gets the job. And there's ways that you can

222
00:34:04.130 --> 00:34:09.084
Classroom 410: kind of incentive. There's ways you can incentivize people to win these bids. So I was saying that we should offer

223
00:34:09.500 --> 00:34:24.859
Classroom 410: a discount or a discount factor to companies that can check off certain boxes related to cyber security like resilience with like themselves. So it's kind of addresses. The 3rd party issue that someone brought up earlier. And

224
00:34:25.120 --> 00:34:36.730
Classroom 410: my solution is that companies that can say that they or that have strong cybersecurity, practices or cyber security. Resilience should be, have that discount factor applied to them, which means that they can bid at a higher price

225
00:34:36.800 --> 00:34:44.549
Classroom 410: and still be able to be competitive with companies that maybe don't have the same cyber security measures in place. So that way, when

226
00:34:44.730 --> 00:35:07.730
Classroom 410: Uva is contracting with someone like that does the alcohol and drug training. They might be less susceptible to cyber attacks themselves. Which will make, like Uva's data more protected overall. Yeah, yeah, I thought that was an interesting kind of lens to put on organizational resilience. I think, Marley, you talked about culture a little bit. So maybe dive more into that.

227
00:35:07.930 --> 00:35:15.990
Classroom 410: Yeah, I mean, one of the quotes that stood out to me. From the case was kind of just saying that

228
00:35:16.180 --> 00:35:27.689
Classroom 410: people know about cyber security. But it's their behavior. That is kind of the problem. So that just starts with building culture to try and

229
00:35:27.700 --> 00:35:36.690
Classroom 410: change people's behavior. So talked about a bunch of different ways to kind of build that culture. But one of I mean, we've also discussed it already, but kind of

230
00:35:37.050 --> 00:35:41.399
Classroom 410: forming teams or gamifying things in a way, and

231
00:35:41.600 --> 00:35:47.639
Classroom 410: having panels to try and really build up people's awareness of.

232
00:35:47.670 --> 00:35:49.289
Classroom 410: So now it's cyberse.

233
00:35:49.470 --> 00:35:55.970
Classroom 410: Yeah, yeah, I thought that was interesting. There's a lot of different pieces from a lot of different answers on culture. So I thought, that was.

234
00:35:56.180 --> 00:36:01.010
Classroom 410: we're talking about. But, Neil, you talked about the professors

235
00:36:01.620 --> 00:36:04.160
Classroom 410: in your particular answer.

236
00:36:04.360 --> 00:36:07.940
Classroom 410: the Uva professors and and what they needed to use

237
00:36:08.770 --> 00:36:10.659
Classroom 410: this long term. Correct.

238
00:36:11.030 --> 00:36:12.409
Classroom 410: I'll give you a beat.

239
00:36:12.490 --> 00:36:18.120
Classroom 410: because whenever you call up professors that that automatically flags for me as far as

240
00:36:18.750 --> 00:36:20.100
Classroom 410: yeah. I mean, I think

241
00:36:20.250 --> 00:36:40.220
Classroom 410: for me like a big thing. I mean, it was. I think I talked a little bit more about it, like questions to me, where I think I talked about like having like a separate like resource center. But I think it was the fact. I feel like with me. It was like, I don't know if I put it as much, but like now that I think about it, like professors, are

242
00:36:40.440 --> 00:36:50.340
Classroom 410: anything about like networks, and like where people are positioned like, they probably have access to. Like most groups of people, whether it's students, professors, colleagues, deeds, like as you go up leadership.

243
00:36:50.380 --> 00:37:01.550
Classroom 410: So I think for me, a lot of it was like figuring out, how can you like target, those specific show stakeholder groups. And I think that's why I kind of reference having like a separate resource center. Because, like.

244
00:37:01.860 --> 00:37:10.920
Classroom 410: I think, I found that like I took the average of like, how many like when they do training that was like once a year, which is like pretty bad compared to like

245
00:37:11.010 --> 00:37:16.940
Classroom 410: how it should be done more so, I think a lot of it stepped in the fact like making things man mandatory as we touched about, but like

246
00:37:16.950 --> 00:37:19.230
Classroom 410: being able to offer a space where it's like

247
00:37:19.350 --> 00:37:22.350
Classroom 410: helping them realize how it can impact their lives. Yeah.

248
00:37:23.130 --> 00:37:30.290
Classroom 410: when we did the data analysis, what do you what group, and we'll jump to this. But I'm kind of interspersing it.

249
00:37:30.380 --> 00:37:34.609
Classroom 410: What unit was the most susceptible according to our simulated data?

250
00:37:36.340 --> 00:37:37.540
Classroom 410: Don't remember?

251
00:37:38.420 --> 00:37:39.150
Classroom 410: Yep.

252
00:37:39.490 --> 00:38:07.570
Classroom 410: business unit, one business unit one and some student and I won't call them out, said something very interesting. It's like, Oh, that's because professors don't read their emails is what they said. I don't know if that's true or not my feelings a little bit, but I won't take it very personal. But Brian Lewis agrees with you, apparently, as far as that's concerned with. So let's talk about culture from the Pwc perspective.

253
00:38:07.570 --> 00:38:29.320
Classroom 410: Yeah, so I kind of written it up here. But and like I just talked about, it's very holistic. So even going back to my training, I had a week long case study like I had 3 weeks of training. And of course I'm in cyber. So mine was more cyber related. But like I learned about every single part of cyber that you guys are probably learning about in this class, for example, like our 1st delivery or deliverable.

254
00:38:29.320 --> 00:38:38.200
Classroom 410: was where we should place like the physical routers and switches in a class in a room, not the classroom in an office room. My second one was like building. What was it?

255
00:38:39.230 --> 00:38:56.750
Classroom 410: It was conducting interviews with stakeholders to do like tabletop scenario. The 3rd was, it was building a business continuity plan, like, let's say, there was a breach. We built one out for what would happen after there was an incident. So I learned about every single part. Which, by the way, and this isn't.

256
00:38:57.100 --> 00:39:07.629
Classroom 410: This wasn't informed by that. Those are our 3 exams. They were just described, right? Figuring out how you guys have that network diagram where you had to place different things.

257
00:39:07.900 --> 00:39:13.939
Classroom 410: We are. We're gonna talk about cyber resilience plan. And then you're gonna build out a response plan.

258
00:39:14.160 --> 00:39:40.899
Classroom 410: Actually, it was really helpful. I sent those to my Pwc email and use them for deliverable. So it was actually nice to have that. But then, just looking at like what we do to help people, it's a lot of risk management. So like what you're learning about, and looking at all those different aspects, and how you can mitigate that for a company like I said, industry, specific solutions. So it's all tailored to different types of industries. I have friends working with like exercise companies where they

259
00:39:40.900 --> 00:39:52.441
Classroom 410: like major exercise companies, and they'll go and they get to wear leisure to work, and then they have, like team building events which are like group cycling classes. Or I have friends that works with banks, healthcare, major healthcare

260
00:39:52.730 --> 00:40:09.910
Classroom 410: companies, hospitals. So it's kind of interesting because everybody's learning about different regulations and compliance requirements. And every single thing is a different solution. So everyone's becoming subject matter experts in different places. Oh, and I didn't mention this. But it's all private side. So it's not government work. It's all working with companies.

261
00:40:10.641 --> 00:40:30.629
Classroom 410: And then kind of going to the last part. This kind of goes with what I said I learned in training but cyber defense and engineering. So it's a lot of learning how to just manage these risk defense mechanisms coming in and building out solutions for companies. So like, for example, the client. I'm on now. Pwc. Came in after they had a major breach in 2,019.

262
00:40:30.630 --> 00:40:41.149
Classroom 410: So from there we started building out their like risk management process because they didn't really have one in place for the whole company. And then from there, yeah, we've just been doing the risk assessments. And

263
00:40:41.160 --> 00:40:41.840
Classroom 410: it's

264
00:40:41.950 --> 00:40:44.950
Classroom 410: been a major project. But yeah.

265
00:40:45.110 --> 00:40:58.930
Classroom 410: so how much coding do you have to do? None. I don't know how to code. So I think I want to. This is a ballpark, but I've only heard of one team out of like 9 practice teams that are technical. So it's kind of nice. Everything is

266
00:40:59.020 --> 00:41:01.179
Classroom 410: like, I said, lined up with this class. There's

267
00:41:01.210 --> 00:41:18.710
Classroom 410: not much coding. There's no coding experience necessary, but it's been really cool to see cyber from a business lens, and I feel like a lot of it is pretty similar to it's just tech focused. So like tech consulting is a really cool place to be to deal with this type of stuff. But

268
00:41:18.780 --> 00:41:22.120
Classroom 410: yeah, not really digging the weeds of coding. Yeah.

269
00:41:22.240 --> 00:41:26.840
Classroom 410: So Kylie and I also went through your data set analysis. So there's some

270
00:41:26.950 --> 00:41:30.300
Classroom 410: a couple interesting things here.

271
00:41:31.020 --> 00:41:32.980
Classroom 410: because I'd like to talk. Thanks, Bryce.

272
00:41:35.220 --> 00:41:37.190
Classroom 410: Who do. I have 1st up

273
00:41:37.260 --> 00:41:39.360
Classroom 410: as well to talk about.

274
00:41:39.900 --> 00:41:51.080
Classroom 410: Maybe what I'll do. I'll come back to this. There's a couple of charts here that I wanted to show you that maybe we could have the Arthur. Authors of these charts kind of walk us through as well.

275
00:41:51.130 --> 00:42:15.090
Classroom 410: So, Sadi, we got you first.st I know I cut off the top of that chart just to kind of simplify it. So what did you look at here? Yeah, I was just looking at the click rates, and I kind of wanted to see it visually. So I put it through. R, and I just made like a stacked bar chart. So basically the blues the yes, so not much code, but just making seeing it in proportion. So.

276
00:42:15.462 --> 00:42:30.960
Classroom 410: yeah. So the blue is the yes, and the red is the no. And looking at the portions like you can obviously really easily see them, because one has the highest click rates and academic unit 2 has the lowest click rate. So it's just because they don't read their emails. Right?

277
00:42:31.240 --> 00:42:41.040
Classroom 410: So yeah, it's just interesting to see visually, definitely helped a lot more quick and dirty. This is what's going on. There's a lot of choices to make in this data set, you know.

278
00:42:41.300 --> 00:42:57.590
Classroom 410: You know, Kylie, Kylie and I are emailing is like this open thing. Seems messy right? It's like, yes, the open thing is messy, because a lot of your devices don't flag that it's been opened or not, so we don't know if opens the right thing. But we do know if you click.

279
00:42:58.140 --> 00:43:03.279
Classroom 410: we do know if you click. That is a definite type of yes

280
00:43:03.580 --> 00:43:17.260
Classroom 410: thing as well. So, Eleanor, I had. This is this is yours right here. Tell us what the approach you took. Yes, it's pretty, but I was just kind of looking at, like

281
00:43:17.390 --> 00:43:36.869
Classroom 410: how many people are clicking on links and opening the email. But then kind of from there, like, if they're actually submitting data to it and like reporting these incidents, and also like the trust that they have in it. As you can see, like most people, have low trust in it.

282
00:43:36.870 --> 00:43:59.560
Classroom 410: So I kind of. And not a lot of people were submitting kind of the emails that they were seeing. So that I just kind of took that to mean. Maybe it's more about like building the culture of people like having that trust in it, and actually like empowering them to submit. Things that are, they know are wrong. That's interesting. We call this actually the fishing funnel.

283
00:44:00.220 --> 00:44:08.219
Classroom 410: where at the top is kind of viewed here is opened, here is clicked and down here, submitted.

284
00:44:08.480 --> 00:44:11.219
Classroom 410: You all know what I'm meaning, right? That looks like my

285
00:44:11.360 --> 00:44:25.810
Classroom 410: 3rd grader. Did that? Yeah. Oh, yeah. The funnel in the case, of course, like, that's that's what we're talking about. Thank you. Of of doing this. So we have 2 more to show.

286
00:44:25.870 --> 00:44:28.750
Classroom 410: So I think this is Jesse's right? Yeah.

287
00:44:29.370 --> 00:44:37.879
Classroom 410: I did. These things looked at a bunch of different factors. How they affected like the average

288
00:44:38.180 --> 00:44:40.100
Classroom 410: number of

289
00:44:40.670 --> 00:44:43.279
Classroom 410: clicks, visual clicks that happen.

290
00:44:43.645 --> 00:44:55.379
Classroom 410: So like what was already mentioned. I looked at trust in it, and you can see that when employees have a higher trust that it will fix their problems for them. They tend to click links.

291
00:44:55.400 --> 00:44:57.330
Classroom 410: They're less cautious about it.

292
00:44:57.970 --> 00:45:11.430
Classroom 410: Mindfulness, which would be like familiarity with technology. The more employees were mindful of technology in general, like in a broader sense, they also clicked links. Less can you train for this?

293
00:45:12.880 --> 00:45:20.200
Classroom 410: it would probably be more difficult because it is more broad. But I was thinking, education programs could, yeah.

294
00:45:20.730 --> 00:45:23.220
Classroom 410: we can absolutely train for my boss.

295
00:45:23.390 --> 00:45:27.359
Classroom 410: Yeah. Yeah. And then, are we a very mindful organization?

296
00:45:28.990 --> 00:45:29.700
Classroom 410: No

297
00:45:29.860 --> 00:45:33.770
Classroom 410: super interesting. I'd call this a training opportunity. Right?

298
00:45:34.490 --> 00:45:43.499
Classroom 410: Sorry, I interrupted. You. Jesse. No go ahead. Yeah. And then oh, also an interesting one was help desk tickets in the bottom left

299
00:45:44.033 --> 00:45:49.979
Classroom 410: the more help desk tickets were submitted. Also, the click rate was higher, which I took kind of as meaning like

300
00:45:50.290 --> 00:45:54.660
Classroom 410: the employees there had not a lot of confidence in their own abilities. And

301
00:45:55.000 --> 00:45:56.569
Classroom 410: we're trying to get help.

302
00:45:56.850 --> 00:46:03.029
Classroom 410: Is that interesting? Like you think the people who reach out to the It help desk are going to be more secure.

303
00:46:03.150 --> 00:46:05.550
Classroom 410: You're telling me they're less secure. Right?

304
00:46:06.200 --> 00:46:11.360
Classroom 410: That's really interesting. So let's go back up and talk about.

305
00:46:12.070 --> 00:46:42.059
Classroom 410: You know what business unit was most susceptible, and what variables contributed, and how Kylie and I approached the data analysis for this particular one. Again. There's no right or wrong way to approach the data analysis, because we didn't provide you guidance. We wanted you to put on your critical thinking and really walk us through. This is my logic on how I did it. And as Kylie and I were talking about this morning, there's a lot of different paths of what people chose to do this. So it was interesting.

306
00:46:42.270 --> 00:46:48.717
Classroom 410: Aisha. I'd like to talk a little bit about when you talked about the most susceptible

307
00:46:49.170 --> 00:46:52.350
Classroom 410: and how you kind of approach that problem.

308
00:46:53.550 --> 00:46:54.710
Classroom 410: Let's see here.

309
00:46:56.080 --> 00:47:00.819
Classroom 410: she's usually right there. Yeah. So

310
00:47:02.200 --> 00:47:05.250
Classroom 410: I'm gonna skip her and I'll move.

311
00:47:05.560 --> 00:47:07.619
Classroom 410: Let's do, Carter Morris.

312
00:47:08.310 --> 00:47:11.311
Classroom 410: You got Lucky Carter Lloyd Carter Morris.

313
00:47:11.940 --> 00:47:21.249
Classroom 410: tell us a little bit about your approach to this data. Set analysis. Yeah, even both of because I think you built the case of in the first, st

314
00:47:21.370 --> 00:47:26.439
Classroom 410: the 1st data set here's what's going on, and that you actually use that a little thinking in a second.

315
00:47:26.540 --> 00:47:46.540
Classroom 410: Well, first, st I was a little confused because there was more submitted data than there was opening emails, yeah, which which I had a couple of emails about, too. And that was messy data. Because you're like, 1st off, there's a problem with the data set. Right? So yeah, so I first, st I thought we were fixing the data set, which wasn't the case. But I so I started off, saying, Hey.

316
00:47:46.610 --> 00:47:57.609
Classroom 410: maybe we want to fix it in that way. I just threw the opening and the sending numbers on top of each other. So I got it as a percentage. Yeah. So I got a percentage of

317
00:47:57.850 --> 00:48:00.789
Classroom 410: open clicks and submitted data for each of the units.

318
00:48:02.200 --> 00:48:15.440
Classroom 410: and we we've already looked at those numbers. So I saw which units were most susceptible to submitting data. Looks kind of like this. Yeah, yeah. For the data to set. I didn't make any

319
00:48:16.334 --> 00:48:26.580
Classroom 410: graphs, but the tables that I made. I kind of took a similar approach. By taking a percentage of clicks and received and forwards

320
00:48:27.298 --> 00:48:29.810
Classroom 410: for the degree level.

321
00:48:29.830 --> 00:48:33.309
Classroom 410: and I found that the associate degree was as troublesome.

322
00:48:33.320 --> 00:48:41.753
Classroom 410: And then I took good tables for the mindfulness and the fishing self efficacy, because I thought those were the 2 most

323
00:48:42.350 --> 00:48:43.050
Classroom 410: like

324
00:48:43.220 --> 00:48:44.080
Classroom 410: telling

325
00:48:45.063 --> 00:48:45.726
Classroom 410: those?

326
00:48:46.810 --> 00:48:52.490
Classroom 410: yeah, I think you did a good job with the descriptive data, seeing what's going through

327
00:48:52.590 --> 00:49:02.180
Classroom 410: Kylie. I've been picking on you this whole time. So let's I would love to hear your answer on how you approached your data analysis, because you had a similar approach when you're trying to connect these 2.

328
00:49:02.640 --> 00:49:06.469
Classroom 410: So walk us through your thinking for days at one. Yeah.

329
00:49:06.650 --> 00:49:12.460
Classroom 410: I was really confused. I spent a lot of time staring at it and trying to figure out why

330
00:49:12.710 --> 00:49:21.379
Classroom 410: so many more people had like submitted confidential data than open the fishing email. To begin with, I did a lot of work this summer

331
00:49:21.740 --> 00:49:32.629
Classroom 410: with email campaign marketing. So I knew that like, sometimes bots went through email domains, especially in spam filters and like clicked through all the links. So I maybe attributed

332
00:49:32.820 --> 00:49:41.770
Classroom 410: why, the click through rate was higher. But I was pretty confused about the submitted data, which is interesting, like, I think when you're thinking about.

333
00:49:41.830 --> 00:49:53.100
Classroom 410: Here's the reality of any security data sets, and Professor Lewis can tell you this as well. They're all not clean and perfect. None of them are clean and perfect. So you by saying, Hey.

334
00:49:53.120 --> 00:50:08.499
Classroom 410: this is a concern, and I think what I was reading between the lines you're like, should I just like discard the opens all the way and just focus on the clicks and submitted. Or does that actually mean something? So you actually had that thought process which I think was interesting.

335
00:50:08.766 --> 00:50:12.349
Classroom 410: And then take us through data set 2, which is a little more clean.

336
00:50:12.550 --> 00:50:17.719
Classroom 410: Yeah, for days at 2 I did a multiple session, just to see which

337
00:50:18.940 --> 00:50:20.540
Classroom 410: variables, where

338
00:50:20.690 --> 00:50:23.200
Classroom 410: significant, affecting the

339
00:50:23.590 --> 00:50:35.480
Classroom 410: phishing like self advocacy and trust in it were the ones that were significant. But in affecting the phishing click rate. So I just divided the percentage of phishing emails clicked out of the total received.

340
00:50:36.071 --> 00:50:49.069
Classroom 410: I found I did it only on 4 variables. I wanted it to be smaller and picked. A few that I thought would be most effective, and I found fishing. Self efficacy had a negative effect. So

341
00:50:49.110 --> 00:50:54.490
Classroom 410: employees who felt more confident in identifying push emails were less likely to click on them, which makes a lot of sense.

342
00:50:54.710 --> 00:50:59.010
Classroom 410: But trust in it had a positive effect, and was really significant

343
00:50:59.110 --> 00:51:01.590
Classroom 410: with a really small key value.

344
00:51:01.670 --> 00:51:09.880
Classroom 410: So employees who trusted it support more were actually more susceptible to fishing, leading to me to come back to our discussion of endemic.

345
00:51:10.240 --> 00:51:21.769
Classroom 410: Yeah, I think the analysis that you did is really similar. As well as to Tanya's data set as well

346
00:51:22.990 --> 00:51:24.480
Classroom 410: walk us through

347
00:51:27.240 --> 00:51:30.079
Classroom 410: the the data set that you have.

348
00:51:30.610 --> 00:51:58.180
Classroom 410: Yeah. So I went to tab Blue. And I did like a regression. I just wanted to see the correlation between the clicks and basically the different aspects of it. Right? So you're looking where you took a ratio which is interesting right between the clicks and the open. You just you use use the click as a definitive variable for this right? Yeah. Different ways of approaching this problem, which I thought were interesting as well.

349
00:51:58.180 --> 00:52:15.139
Classroom 410: And if you look at the significance here, you had helped us tickets trust and it and mindfulness right? We're all significant as well. I thought, this is interesting. This is an interesting thought exercise, because, like, what does it mean to have a ratio like? What does that number actually mean

350
00:52:15.629 --> 00:52:20.429
Classroom 410: as opposed to a direct measure. And how do you do these things?

351
00:52:20.500 --> 00:52:29.640
Classroom 410: And you know, one of the biggest things about Macintyre is our analytic and our critical skills. So these discussions are the right discussions to have in terms of the approach.

352
00:52:29.650 --> 00:52:39.040
Classroom 410: Maybe I'll turn it over to Kylie when we could talk about how our approach was, which is probably similar to both of yours as well. So

353
00:52:39.150 --> 00:53:05.349
Classroom 410: so like. We said he left it completely open, so no answer was wrong, but the way. But the way that I did it was the exact same that you did it. So I ran the same linear regression, with the same dependent variable of phishings, clicked, and I got the same exact answer as you, where help desk tickets, trust and help, desk and mindfulness, all had a significant effect.

354
00:53:05.380 --> 00:53:15.019
Classroom 410: So, and I think, like you had maybe mentioned, the 2 of them had a positive beta, and one of them had a negative which mean it had a detrimental.

355
00:53:15.270 --> 00:53:17.759
Classroom 410: so increased susceptibility.

356
00:53:17.810 --> 00:53:42.539
Classroom 410: But yeah, I kind of did the same exact thing. So we found that help desk tickets and trust and help tests. Both had positive correlations, so their influence on the dependent, variable, increased susceptibility. And then the last one mindfulness was negative, meaning that this variable decreases susceptibility. So, going back to everything we mentioned that mindfulness is really a great measure of figuring out who's susceptible and not and how to

357
00:53:42.660 --> 00:53:43.125
Classroom 410: and

358
00:53:43.880 --> 00:53:54.610
Classroom 410: like implementing trainings with mindfulness would have a significant effect if used. Yeah, we decided to do fishing clicks only. But here's the key difference.

359
00:53:55.039 --> 00:54:04.740
Classroom 410: As far as an analytic processes, we did logistic regression, because that is a binary, dependent, variable outcome. So if you're a little bit different than us.

360
00:54:04.880 --> 00:54:27.619
Classroom 410: that's probably why you ran a regression because it's a 0 or one. If you just do a multiple regression, it assumes that's a continuous variable. I know this isn't a stat class. I should have gave a trigger warning before this. I apologize. But if you just do a normal regression and assumes that Dv. Is continuous. And it's not so. You'll because of that, some of your beta weights will be biased

361
00:54:27.956 --> 00:54:35.369
Classroom 410: between these 2 things. Right? We're really when we look at the beta weights. And we look at the level of significance.

362
00:54:35.998 --> 00:54:39.070
Classroom 410: That beta weight, you know, 10%,

363
00:54:39.190 --> 00:54:45.969
Classroom 410: 17%, 12%. These are all in social sciences. This is all pretty hot.

364
00:54:46.650 --> 00:55:14.149
Classroom 410: In other words, I can account for 17% of the variance, and whether you open it or not by your trust in it and help desk right, etc. These are unstandardized, but the standardized weights are similar for this. So mindfulness, again, by your ability to apply a mindfulness technique in your work. You can decrease susceptibility, 12% that if you could tell a company that that would be.

365
00:55:14.300 --> 00:55:23.689
Classroom 410: and then you could train towards it. Like, here's here's our slot. In terms of mindfulness. I could. I could work with this 12%. I'm not going to solve all your problems.

366
00:55:23.690 --> 00:55:48.479
Classroom 410: trusted and help this. That's a thing. The more I trust the help desk the more susceptible I am. What does that mean for organizational design? Right? So these are really interesting points of view. When you're doing this kind of analysis, you always have to go back to the policies that you can influence and the strategy that you're trying to operationalize when you're doing the data analysis that informs this type of work.

367
00:55:48.750 --> 00:55:52.309
Classroom 410: We also learned that we have a rather old

368
00:55:52.560 --> 00:56:05.229
Classroom 410: workforce here at Uva, which we we knew about, we have. Yeah, we have 80 year olds walking around our hollow grounds is, etc, so as well as the standard deviation is

369
00:56:05.440 --> 00:56:06.809
Classroom 410: not that great?

370
00:56:06.990 --> 00:56:10.169
Classroom 410: And everybody sticks around right?

371
00:56:10.920 --> 00:56:16.090
Classroom 410: That's a that's a pretty good average of 17 years or 16 years. That's pretty

372
00:56:16.350 --> 00:56:20.990
Classroom 410: any questions about our interpretation of this data. Again.

373
00:56:21.150 --> 00:56:27.750
Classroom 410: Kylie's right. There's no wrong approach to to this particular thing. But when we're looking at an analytic.

374
00:56:27.790 --> 00:56:40.720
Classroom 410: we're thinking about. Okay, what's the right analysis with these variables? So the 1st step is like, who's most susceptible? And then, as you read in the case, they followed on, asked some questions like, based on that unit.

375
00:56:41.720 --> 00:56:43.199
Classroom 410: This is what we're seeing.

376
00:56:43.460 --> 00:56:47.180
Classroom 410: So let me pause here for any questions, and then we're gonna get to our last

377
00:56:48.170 --> 00:56:50.420
Classroom 410: step of lessons, learned

378
00:56:51.890 --> 00:56:53.439
Classroom 410: any questions about this

379
00:56:54.090 --> 00:56:56.169
Classroom 410: that makes sense what I'm talking about

380
00:56:56.230 --> 00:56:57.689
Classroom 410: kind of lines up

381
00:56:59.300 --> 00:57:02.000
Classroom 410: as well. So let's talk about lessons learned

382
00:57:03.440 --> 00:57:04.600
Classroom 410: as well.

383
00:57:04.690 --> 00:57:09.189
Classroom 410: So maybe we'll talk. We'll I'll start by asking Kylie.

384
00:57:10.330 --> 00:57:32.599
Classroom 410: would you learn from this case? And how are you applying it to your current work. Yeah, I learned a lot about how these types of attacks can happen and how common they are. I can't remember the exact percentage. But it's also really interesting how much spear phishing has an effect on any type of organization I can't remember. It was in the case, but it was like 66%.

385
00:57:32.900 --> 00:57:42.080
Classroom 410: Does anyone remember? Do you know, remember this? Yeah, it's like point 1% of attacks are spear phishing. But there's 66% of breaches. Yeah.

386
00:57:42.110 --> 00:58:06.169
Classroom 410: yeah. So it's really interesting, seeing that. And it's really important, because I think especially spear phishing is becoming more and more plausible. Someone had mentioned with like Linkedin and handshake. And that's a really good point, too, because you're an open target like you put your Linkedin or your email on your linkedin. So it's interesting to think about it from that perspective. And yeah, just learning how prevalent these breaches are. I didn't know about a lot of these breaches before I wrote the case.

387
00:58:06.579 --> 00:58:34.430
Classroom 410: So it's definitely interesting, seeing how much stolen data there is online as well, and then kind of bringing that to my career. Now it was really interesting, especially in training, because, like I mentioned the case, scenario was a breach. So I felt like I knew a lot about it from the perspective that this class gave me. I would say it's definitely interesting, being like in the real world in the company, because you notice how many more safeguards there are in place at like Pwc. Or my client like

388
00:58:34.570 --> 00:58:42.000
Classroom 410: just the data seems like a little bit more protected. And so you really realize how vulnerable higher education is

389
00:58:42.140 --> 00:58:44.860
Classroom 410: which yeah, we wrote about in the case.

390
00:58:45.050 --> 00:58:51.199
Classroom 410: maybe time for a couple more perspectives from maybe I'll invite folks that haven't had the opportunity

391
00:58:51.520 --> 00:58:52.789
Classroom 410: to speak yet.

392
00:58:53.320 --> 00:59:04.579
Classroom 410: So a couple more perspectives, general lessons learned. We all know that lessons learned can be the most important part of this. In fact, you want to share your story about how

393
00:59:05.110 --> 00:59:10.159
Classroom 410: you're seeing the lessons learned come back into the current practices at Pwc.

394
00:59:10.610 --> 00:59:19.659
Classroom 410: You know what I'm talking about. But the big bank about how they're changing their processes based on oh, yeah. Well, like the risk assessment process. Oh, yeah. So after the

395
00:59:19.690 --> 00:59:30.801
Classroom 410: the the client that I'm at. Currently there was a huge breach in 2019 and it affected almost all parts of the business, and it affected millions of customers.

396
00:59:31.640 --> 00:59:49.219
Classroom 410: yeah. So they brought in team, like hundreds of people from Pwc to assess their risk assessment process and go through every part of the business after the 1st part, was incident response. So I think you're going to talk about that later in the class, but just making sure that everything that was secured. Segmented? Everything was

397
00:59:49.260 --> 00:59:57.540
Classroom 410: protected, and then from there it was building out. How do we assess risk in the future to make sure that they're all mitigated. So they actually

398
00:59:57.640 --> 00:59:58.750
Classroom 410: launch like

399
00:59:58.890 --> 01:00:14.730
Classroom 410: a risk assessment process, specifically within the client called, let's all understand change. It's about like change management risk processes. So every single 3rd party vendor, every single project, has to go through this risk assessment process. And it's just really crazy to see

400
01:00:14.850 --> 01:00:16.239
Classroom 410: the scale that

401
01:00:16.300 --> 01:00:21.360
Classroom 410: these companies go through, and how many risks there are there are associated with every single project.

402
01:00:21.580 --> 01:00:24.710
Classroom 410: And that's an example of when we talk about.

403
01:00:25.260 --> 01:00:28.849
Classroom 410: You know, a lot of cyber security is done reactively.

404
01:00:28.980 --> 01:00:32.310
Classroom 410: Something bad happened. We gotta figure it out. We gotta fix it.

405
01:00:32.390 --> 01:00:45.759
Classroom 410: And the best companies are proactive on identifying these things before something happened. I think Pwc. And others are are moving companies into that mindset rather than a reactive mindset

406
01:00:45.780 --> 01:00:56.165
Classroom 410: as they go through maybe last bit. And I don't know why my quickness to stop working there we go. Talk about we. We dug into this a little bit. But

407
01:00:56.720 --> 01:01:14.500
Classroom 410: yeah, your career perspectives. Yeah, I feel like it's exactly like this class. I also feel bad. I keep saying it from Pwc, but this is just tech consulting in general, it's a lot less technical than you think, unless you choose to be in a technical space. And it's really interesting just getting to interact with

408
01:01:14.500 --> 01:01:28.560
Classroom 410: like my intern project. I was only interacting with the Ciso of another major bank. Actually, just because that was like the level of the project I was on. And it was really cool, because I mean, I was just interacting like the Ciso of a major bank

409
01:01:29.094 --> 01:01:30.950
Classroom 410: on a daily basis.

410
01:01:30.960 --> 01:01:33.019
Classroom 410: So that was cool. And then

411
01:01:33.160 --> 01:01:52.699
Classroom 410: I also just wanted to add, in like case interviews, if you ever did want to go into this are exactly like this class and database management like I interviewed at one place, and it was, Have you guys hit like Pci compliance and hipaa stuff like that? And we're going to dig in more. Brian Lewis loves that stuff. Okay, yeah.

412
01:01:52.700 --> 01:02:14.779
Classroom 410: Because one of my case interviews for another place that I've been interviewing for cyber consulting was specifically the answer was Pci. I hadn't taken this class yet, so I had no idea what Pci was, so I explained exactly like what Pci was, and then I was told that there was an acronym for that. So yeah, like, Pci is a huge compliant

413
01:02:14.780 --> 01:02:33.980
Classroom 410: part component of this. So like, I, just so, I saw that in this class, and then database management. My Pwc case interview was about upgrading database to like oracle or cloud. So it's just really similar to the type of work that you would see if you're in the it. Concentration here. Yeah, I don't.

414
01:02:34.390 --> 01:02:48.370
Classroom 410: I think that about covers it. See, Thomas, you missed out on all sorts of good stuff. I have to say, though, just to like tack on what Kylie is saying, like from an employer and outcome like in careers perspective.

415
01:02:48.370 --> 01:03:09.619
Classroom 410: What you guys are learning here where you are marrying like a very digital tech focus mindset, but also your business acumen. And like the commerce skills that you have. I think that is what sets you apart, because, candidly, in the job market, that's who you're up against. You're up against folks who have a lot of tech skills. Folks have a lot of business skills. But you're bringing them both to bear.

416
01:03:09.924 --> 01:03:16.989
Classroom 410: So I think that bodes really well for you all. So cut yourself on the back for signing up for this course. Yeah, absolutely.

417
01:03:17.010 --> 01:03:35.940
Classroom 410: Thank you as well. So let's open it up to a little bit of Q&A, and then I'm going to talk about the project and let out of here a little bit early. So I promised Kylie and Thomas some good questions from you folks about the case.

418
01:03:36.370 --> 01:03:46.270
Classroom 410: She wrote it. She lived it that whole thing, the career her sitting in that seat over there last year anything you want at this particular time.

419
01:03:46.440 --> 01:03:47.810
Classroom 410: So what questions do you have?

420
01:03:49.490 --> 01:03:56.089
Classroom 410: Yeah, Matt? I think something that was kind of seem contradictory in the data was like

421
01:03:56.300 --> 01:04:08.070
Classroom 410: the fact that and we talked about it last class of like, you want people to trust your it department at the same time you see some negative things that could come from that. So like, how would you balance like

422
01:04:08.150 --> 01:04:09.650
Classroom 410: having people to be

423
01:04:09.680 --> 01:04:12.480
Classroom 410: empowered enough to solve their own issues. But also

424
01:04:12.800 --> 01:04:20.669
Classroom 410: you want them to kind of still have trust in your it system as you don't want to take them. You don't want them to take too much liberties in a sense that might even compromise your overall.

425
01:04:20.920 --> 01:04:23.040
Classroom 410: Yeah, I gotta be careful

426
01:04:23.240 --> 01:04:25.479
Classroom 410: how I answer this question.

427
01:04:30.220 --> 01:04:32.649
Classroom 410: and I'm going to give you an unsatisfying answer.

428
01:04:32.710 --> 01:04:36.638
Classroom 410: Let's talk about this after your group. Exam.

429
01:04:37.180 --> 01:04:42.159
Classroom 410: I don't know how else to say that. Because then I don't want.

430
01:04:42.370 --> 01:05:02.289
Classroom 410: You know we got 9 groups in here. I don't want 9 answers. Showing up is like you, said the answer. To like I'm going to dig into that a little bit. It's not exactly, but let's come back to that. So I don't bias it. I'm sorry, madam, that being said good question, because I remember when I was reading your academic research, I had no idea why trust in it would be a bad actor. So yeah.

431
01:05:03.677 --> 01:05:08.319
Classroom 410: hint. And you can all credit Matt, for this. This is about culture.

432
01:05:09.000 --> 01:05:10.869
Classroom 410: right? The right culture.

433
01:05:11.860 --> 01:05:12.980
Classroom 410: Good question.

434
01:05:13.310 --> 01:05:16.829
Classroom 410: Such a good question that you're gonna probably see parts of it again.

435
01:05:18.200 --> 01:05:22.080
Classroom 410: Any other questions that you all have that would be helpful for today.

436
01:05:27.960 --> 01:05:33.809
Classroom 410: Yeah, go ahead. Why hasn't cyber security training made mandatory for students at Uk.

437
01:05:35.890 --> 01:05:45.310
Classroom 410: It kind of is, but it's not. They did try it for a while. Professor Lewis, you want to. You probably have a better memory of that whole.

438
01:05:46.888 --> 01:05:58.250
Classroom 410: Well, it is on the way in the tool aspects of it. But I think what they lack with you is that students are both

439
01:05:58.970 --> 01:06:01.470
Classroom 410: not boys, they're customers.

440
01:06:01.520 --> 01:06:05.780
Classroom 410: And so it's very hard to mandate things in some ways.

441
01:06:06.080 --> 01:06:10.579
Classroom 410: So making you redo things annually is a lot cheaper.

442
01:06:12.967 --> 01:06:18.220
Classroom 410: let alone get faculty to do anything. That's a different deal altogether.

443
01:06:18.590 --> 01:06:26.170
Classroom 410: It's a different environment. If I work for the Dod and I didn't do my cyber security training, my clearance would be stopped

444
01:06:26.440 --> 01:06:37.280
Classroom 410: right like there's just different. Different organizations have different mechanisms to do that. Do you think it should be mandatory? And if so, how often should everybody do it?

445
01:06:38.510 --> 01:06:42.110
Classroom 410: I don't know. Like off of this class just hearing all the

446
01:06:42.730 --> 01:06:51.409
Classroom 410: horror stories, I think. Yeah, like, I don't remember doing anything for coming into Uva. So that's how front of mind it was for me. Just another.

447
01:06:51.630 --> 01:06:54.370
Classroom 410: Yeah, just another check box. I think

448
01:06:54.380 --> 01:06:55.410
Classroom 410: the like

449
01:06:55.790 --> 01:07:07.359
Classroom 410: trainings where you have to do them to get like your Sis cleared so you can enroll like that's kind of annoying. But maybe like, during the semester like during October, during cyber security awareness month, like

450
01:07:07.420 --> 01:07:09.600
Classroom 410: Ashley making a friend of mine in a

451
01:07:09.710 --> 01:07:10.760
Classroom 410: more

452
01:07:10.890 --> 01:07:12.849
Classroom 410: relevant way to students.

453
01:07:13.310 --> 01:07:21.570
Classroom 410: would not even be like helpful for Uva. But just like students in general, like, how helpful this class has been. Just for, like my daily habits. Yeah.

454
01:07:22.040 --> 01:07:48.290
Classroom 410: yeah, anybody want to jump off in that comment. I'm just curious what your thoughts are. I think it should be mandatory in the way in the door. I'd like more information, whereas people from admissions and things think otherwise. But I kind of go off like the principles of marketing, where you hit people 6 or 7 times now, in a digital age, even more to have something fully sink in, so giving them a baseline that could even be more like based

455
01:07:48.681 --> 01:07:59.450
Classroom 410: to like. Look at this one like Tyler was saying, I think, is totally valid, and then backing that up with more consistent fishing tests, going to students and things like that throughout the year, could be

456
01:07:59.740 --> 01:08:01.229
Classroom 410: useful, in my opinion.

457
01:08:02.200 --> 01:08:03.350
Classroom 410: What else do you think?

458
01:08:03.600 --> 01:08:06.480
Classroom 410: Who else wants to chime in on this

459
01:08:08.990 --> 01:08:13.850
Classroom 410: you have a different point of view. After sitting through this for close to a semester. I understand that

460
01:08:13.890 --> 01:08:17.186
Classroom 410: it'd be interesting to ask you the 1st day and the last day

461
01:08:17.520 --> 01:08:30.900
Classroom 410: how you felt about this, because at the end of the day. We know, like, I think about phishing self-efficacy. If you understand truly understanding this vector of attack, you're probably going to be okay.

462
01:08:31.330 --> 01:08:33.030
Classroom 410: You're probably gonna be okay.

463
01:08:33.069 --> 01:08:48.180
Classroom 410: And even if you aren't okay, and you catch that weak moment which absolutely can happen to anybody, you also know that response is going to be the most important thing. Who do I tell? How quickly can I tell to help contain this particular threat? Right?

464
01:08:48.680 --> 01:08:50.829
Classroom 410: I would argue

465
01:08:51.170 --> 01:08:53.979
Classroom 410: that the majority of students don't have that perspective.

466
01:08:54.010 --> 01:08:55.200
Classroom 410: Is that fair

467
01:08:55.300 --> 01:09:13.539
Classroom 410: to say, like I clicked on something. I am never going to mention this again, and I'm going to forget about it and walk away like it never happened right like, which is the worst thing is same with organizations. And what to do. That's why the culture piece we talk about. That's why understanding the data is so important. It's like understanding organizations are so important

468
01:09:13.770 --> 01:09:16.149
Classroom 410: because all that kind of feeds into each other.

469
01:09:16.750 --> 01:09:21.960
Classroom 410: Okay, what are we doing on Wednesday? First? st Big round of applause for Kylie for coming back now.

470
01:09:22.170 --> 01:09:22.930
Classroom 410: yeah.

471
01:09:25.560 --> 01:09:41.549
Classroom 410: if you hated the case, it's my fault if you love the case. That was all of kylie as well. So we are going to do some simulations what they call tabletop exercises. This is a picture of doing a tabletop exercise

472
01:09:42.736 --> 01:09:44.650
Classroom 410: for the

473
01:09:45.210 --> 01:10:12.789
Classroom 410: critical infrastructure and utilities in the Western States as well. We did a study on how these are done and the effects of these as well. Why do we do these things? Because it's kind of like a way of responding without having the pain of responding to a real attack that identifies your gaps. It codifies your decision, making it helps you collaborate and communicate. And this is what we studied when we look at the infrastructure

474
01:10:12.790 --> 01:10:31.109
Classroom 410: piece this summer is we saw who talked to, who? How did they talk to each other? Can we build a robust social network understanding of these things. So we can then say, when you have an attack. This should be your communication plan also identifies your resources and

475
01:10:31.450 --> 01:10:36.459
Classroom 410: honestly, a lot of organizations. You have to do this to maintain your compliance.

476
01:10:37.340 --> 01:11:04.180
Classroom 410: So what you're going to do is you're going to come in here, and every single group will be handed a scenario, and in that scenario you're going to ask questions like, who should be looped in what is affected? What laws do I apply and go through that in the 75 min that you have to address this, your deliverable is going to be a single slide out of your group that you'll submit at the end of the 75 min

477
01:11:04.260 --> 01:11:08.669
Classroom 410: single slide, answering 3 questions.

478
01:11:09.310 --> 01:11:15.300
Classroom 410: What strategy to contain your attack? What additional tools and resources do you need? And what did you learn?

479
01:11:16.630 --> 01:11:39.990
Classroom 410: So those are what you can, any slide format that you want? You'll submit that on canvas as well. And then in 2 weeks we'll come back after we have a guest speaker, and we're going to talk about all your strategies when we're learning about response. At the same time, like, what did you all do? How did you think this? Through? What did you draw on a good experience

480
01:11:40.030 --> 01:12:06.629
Classroom 410: for everyone to do? You'll all have your individual breakout rooms. I'll be circulating as well as Professor Lewis will be circulating. I haven't asked him. By the way, are you okay with circulating around. Okay, him, too. Circulating to answer any questions that you have. You're going to be really unsatisfied, much as Matt is leaving this room. But a lot of our questions, because you'll ask us questions like, what about this or this we're like?

481
01:12:06.630 --> 01:12:18.230
Classroom 410: I don't know, you tell us is going to be the answers. We can help clarify some points. But direction is, I want to hear from you all what you think the right direction on how to address

482
01:12:18.230 --> 01:12:41.990
Classroom 410: these 9 different cybersecurity incidents. So you'll get it framework. I give you prompt questions like, talk about these things. I don't want you to talk. These are the only things you need to report back, and then we'll come back, and you'll have, like, literally 3 min to present your slide. This is our slide. Here's our strategy. Here's our thing. What did the groups learn? We'll do that in a following class.

483
01:12:42.010 --> 01:13:00.220
Classroom 410: So this class in the entirety, you'll be in the breakout room, and you'll submit a slide at the end of that, and then we'll talk about this, and then we'll build up this these frameworks for response and how to respond correctly based on this. And we'll talk about what you do differently now that you know kind of these response frameworks.

484
01:13:00.230 --> 01:13:05.810
Classroom 410: So any questions I'm going to pause here. We'll talk about this case, study, talk, talk later.

485
01:13:06.142 --> 01:13:12.569
Classroom 410: Any questions, comments, or concerns about 2 min ahead I was hoping to give you 5 min to huddle up as groups.

486
01:13:12.730 --> 01:13:18.779
Classroom 410: We have Thomas here that if you're interested to learn more about Pwc. I'm sure Kylie can pass that off.

487
01:13:18.860 --> 01:13:24.639
Classroom 410: Are we? Good? Come here, don't unpack anything. I'll kick you to a breakout room on Wednesday. Sound good.

488
01:13:24.840 --> 01:13:27.381
Classroom 410: Alright. Have a great Monday.

